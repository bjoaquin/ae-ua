```{r}
#| echo: FALSE
#| message: FALSE

library(tidyverse)

contador_ejemplos <- 0
```

# 4. ICs y Tests de hipótesis

## Introducción

Un día a principios de la década de 1920, Ronald Fisher, un reconocido estadístico, se encontró en una situación peculiar: le preparó una taza de té a una compañera de trabajo y ella la rechazó por haber servido la leche antes que el té. Fisher argumentó que el orden en el que se servían los líquidos no tenía importancia, pero ella estaba fuertemente en desacuerdo: de hecho, se jactaba de poder probar una taza de té y decir si se había servido primero la leche o el té.

Motivado por la curiosa situación y por su formación profesional, Fisher se propuso diseñar un experimento para poner a prueba la supuesta habilidad de su compañera. Preparó ocho tazas de té: cuatro donde se había servido primero la leche y cuatro donde se había servido primero el té. En orden aleatorio, le hizo probar las tazas a su compañera, una por una, mientras ella señalaba para cada una su predicción. Cuando el experimento terminó, la mujer había podido etiquetar las ocho tazas correctamente. [@fisher]

Fisher estaba sorprendido, pero aún había un pensamiento del que no podía desprenderse: existía la posibilidad de que la mujer estuviese adivinando cómo fue preparada cada taza, con la inesperada fortuna de haber acertado en todos los casos. ¿Cuál era la probabilidad de dicho caso? Aplicando la distribución hipergeométrica, puede demostrarse que dicha probabilidad es 1,4%. En otras palabras, era poco probable que la mujer estuviese adivinando: la evidencia muestral sugería que realmente podía percibir sabores distintos entre las preparaciones.

Este simple experimento sentó las bases para lo que hoy se conoce como "pruebas de hipótesis".

El contenido de esta unidad se basa en ese concepto: cómo usar la información muestral para tomar decisiones. Veremos dos manifestaciones de esta idea: intervalos de confianza y tests de hipótesis. Luego veremos las similitudes que comparten ambas herramientas y en qué casos son equivalentes.

## Intervalos de Confianza

La estimación puntual se basa en representar una característica de interés mediante los valores observados de una muestra aleatoria. Sin embargo, los estadísticos que usamos como estimadores son variables aleatorias: su valor varía de muestra en muestra. Por lo tanto, nunca tenemos certeza sobre si, para la muestra que obtuvimos, nuestra estimación está o no "cerca" del verdadero valor del parámetro de interés.

Afortunadamente, existe otro tipo de estimación: en lugar de tener un solo número como estimador, podemos tener un rango de valores. La ventaja de este método que permite cuantificar (usando probabilidades) el grado de certeza con el que se espera que el verdadero valor del parámetro se encuentre dentro de dicho rango. Estamos hablando de los *intervalos de confianza*.

Formalmente, una estimación por **intervalo de confianza** para un parámetro $\theta$ se construye a partir de dos funciones $L(\mathbf{x})$ y $U(\mathbf{x})$[^4_tdh-1] y de un valor $\alpha \in (0;1)$, y viene dado por $$IC_{1-\alpha}(\theta) = [L(\mathbf{x}) \,;\, U(\mathbf{x})] \text{ tal que } P(L(\mathbf{x}) \leq \theta \leq U(\mathbf{x})) = 1 - \alpha$$

[^4_tdh-1]: Nótese la negrita en la $\mathbf{x}$. Esto es para representar el vector de valores muestrales observados: $\mathbf{x} = (x_1, x_2, \cdots, x_n)$.

A la hora de realizar una estimación por IC, el valor $1-\alpha$ representará la **confianza** de nuestro intervalo y se puede interpretar como la probabilidad de que el intervalo $[L(\mathbf{x}) \,;\, U(\mathbf{x})]$ incluya al verdadero valor del parámetro *antes de extraer la muestra*.[^4_tdh-2] Otra interpretación posible es que, si se tomaran reiteradas muestras de la población bajo estudio y consecuentemente se construyeran múltiples intervalos de confianza, es de esperar que $\theta$ esté contenido en el $100(1-\alpha)\%$ de ellos.

[^4_tdh-2]: Una vez tomada la muestra, los extremos del intervalo ya no son variables aleatorias sino números fijos. Por lo tanto, cuando esto ocurre la proabbilidad de que el verdadero valor del parámetro esté contenido en el intervalo es 0 ó 1: el intervalo contiene al parámetro, o bien no lo contiene (aunque nunca sabremos en cuál caso nos encontramos).

Existen varios métodos para construir intervalos de confianza. El más utilizado (y el que veremos en este curso) consiste en proponer cuantiles como valores de $L(\mathbf{x})$ y $U(\mathbf{x})$. Dichos cuantiles provienen de la distribución muestral del estadístico que estamos usando para estimar el parámetro.

Por ejemplo, supongamos que queremos estimar la media poblacional mediante la media muestral (hasta ahora esto sería una estimación puntual, como en la unidad anterior). Sabemos que la distribución muestral de dicho estadístico es Normal (ya sea exacta o aproximadamente, dependiendo de si la variable original es Normal o si debemos recurrir al Teorema Central del Límite). La campana Normal correspondiente estaría centrada en $\mu$, pero este valor lo desconocemos. Sin embargo, si tomamos a la media muestral observada como nuestra mejor aproximación de $\mu$ (o sea, $\hat{\mu} = \overline{x}$) entonces podemos concebir una curva Normal empírica centrada en este valor. Si quisiéramos constuir un intervalo con una confianza del 95%, deberíamos tomar los cuantiles 2,5% y 97,5%, de modo que el intervalo esté compuesto por el 95% central de la campana.

![Ilustración de un intervalo de confianza del 95% para la media poblacional.](img/ci_mean.jpg){#fig-meanci}

::: callout-note
#### Nota

Nótese cómo el uso de las distribuciones muestrales se torna casi opuesto entre la teoría (Unidad 3) y la práctica (Unidad 4). En un entorno teórico, conocemos el valor del parámetro poblacional e hipotetizamos sobre qué ocurriría cuando eventualmente tomemos una muestra, calculando la probabilidad de que nuestro estimador tome un valor dentro de un cierto intervalo: $P(a \leq \hat{\theta} \leq b)$. En la práctica, sin embargo, el proceso es el inverso: el valor del estimador muestral es lo que se conoce, y se calcula la probabilidad de que el parámetro poblacional tome un valor dentro de un cierto intervalo.
:::

### IC para la media de una población Normal ($\mu$)

Sea $X_1, X_2, \cdots, X_n$ una muestra aleatoria de tamaño $n$ extraída de una población con distribución $N(\mu,\sigma)$. Sabemos que la media muestral también tiene distribución Normal. Entonces podemos utilizar lo siguiente:

$$\overline{X} \sim N\left( \mu, \frac{\sigma}{\sqrt{n}} \right) \implies Z = \frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)$$

Lo anterior es fácilmente demostrable. Para empezar, cualquier combinación lineal de una variable Normal es a su vez una variable Normal. Como $Z$ es una combinación lineal de $\overline{X}$ y $\overline{X}$ es Normal entonces $Z$ también es una variable Normal. ¿Cómo podríamos deducir la Esperanza y Variancia de esta nueva variable aleatoria? Utilizando propiedades de $E(X)$ y $V(X)$ para combinaciones lineales.

$E(Z) = E(\tfrac{\sqrt{n}}{\sigma}[\overline{X}-\mu]) = \tfrac{\sqrt{n}}{\sigma} E(\overline{X}-\mu) = \tfrac{\sqrt{n}}{\sigma} [E(\overline{X})-E(\mu)] = \tfrac{\sqrt{n}}{\sigma} [\mu-\mu] = 0$

$V(Z) = V(\tfrac{\sqrt{n}}{\sigma}[\overline{X}-\mu]) = \tfrac{n}{\sigma^2} V(\overline{X}-\mu) = \tfrac{n}{\sigma^2} V(\overline{X}) = \tfrac{n}{\sigma^2} \cdot \tfrac{\sigma^2}{n} = 1$

Hemos así demostrado que $Z \sim N(0,1)$. ¿De qué nos sirve esto? La distribución $N(0,1)$ se conoce como **distribución Normal estándar**. Es útil para obtener cuantiles sobre una distribución Normal. Sea $Z_p$ el cuantil que acumula un $100p\%$ del área bajo la curva Normal estándar. Bajo esta definición, resulta que $Z_p$ nos dice cuántos desvíos estándares debemos movernos respecto a la media para obtener el cuantil correspondiente en nuestra variable original: $\overline{X}_p$.

Por ejemplo, supongamos que queremos obtener un intervalo de confianza del 95% para la media poblacional. Como se mencionó anteriormente, debemos buscar los cuantiles 2,5% y 97,5%. Para esto podemos obtener $Z_{0.025} = -1,96$ y $Z_{0.975} = 1,96$. En otras palabras, deberemos movernos 1,96 desvíos estándares por debajo y por encima de la media para obtener el intervalo de confianza deseado.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Sea $X$ una v.a. Normal con media desconocida y desvío estándar igual a 10. Se extrae una muestra aleatoria de tamaño 25 y se obtiene una media muestral $\overline{x} = 18$. Construya un intervalo de confianza del 95% para la media poblacional.

**Solución:** Si $X \sim N(\mu, \sigma=10)$, luego $\overline{X} \sim N(\mu, \tfrac{10}{\sqrt{25}} = 2)$.

En base a cálculos anteriores sabemos que debemos movernos $\pm$ 1,96 desvíos estándares respecto a la media muestral observada. Recordemos que esos desvíos estándares no corresponden a la variable original sino al estadístico que estamos utilizando. Por lo tanto:

$$IC_{95\%}(\mu) = [18 - 1,96 \cdot 2 \,;\, 18 + 1,96 \cdot 2] = [14,08 \,;\, 21,92]$$

En términos del problema diríamos que: en base a la evidencia muestral, se tiene un 95% de confianza de que la verdadera media poblacional se encuentra entre 14,08 y 21,92.
:::

En líneas generales, la fórmula es la siguiente: $$IC_{100(1-\alpha)\%}(\mu) = \left[\overline{x} + Z_{\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \,;\, \overline{x} + Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \right] = \left[\overline{x} - Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \,;\, \overline{x} + Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \right]$$

$$IC_{100(1-\alpha)\%}(\mu) =  \overline{x} \pm Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}}$$

Este intervalo está sujeto a las distribuciones muestrales estudiadas en la unidad anterior, por lo que aplican los mismos criterios: si la variable original $X$ es Normal, entonces se puede usar la distribución Normal para calcular el intervalo de confianza, sin importar el tamaño muestral. Si $X$ no es Normal o su distribución es desconocida, ante una muestra grande se puede construir este IC *aproximado* empleando el Teorema Central del Límite.

::: callout-tip
#### Idea clave

Quizás hayan notado, a partir de la definición anterior, que $Z_{\tfrac{\alpha}{2}} = -Z_{1-\tfrac{\alpha}{2}}$. Esto se vio en el ejemplo anterior: $Z_{0.025} = -Z_{0.975} = -1,96$. Esta es una propiedad que cumple la distribución Normal estándar, y una de las razones por las que resulta cómoda para calcular cuantiles: sus cuantiles son simétricos respecto al centro (el percentil 50%).
:::

::: callout-tip
#### Idea clave

Para calcular percentiles de una distribución Normal estándar podemos usar una función de R: `qnorm(p)`, donde `p` es el percentil de interés.
:::

#### Margen de error

El término $e = Z_{1-\alpha/2} \tfrac{\sigma}{\sqrt{n}}$ es la *semiamplitud* del intervalo y se lo denomina **margen de error**. Naturalmente, un intervalo es más *preciso* mientras menor sea su margen de error.

¿Cómo podemos aumentar la precisión de nuestro intervalo? O, equivalentemente, ¿cómo podemos hacer que el término $e$ sea lo más pequeño posible? El margen de error se expresa en función de otros tres valores: $\alpha$, $\sigma$ y $n$. Podemos hacer las siguientes observaciones:

* $\alpha$: representa el complemento de la confianza del intervalo. Para disminuir $e$ en función de $\alpha$ habría que lograr que el factor $Z_{1-\alpha/2}$ sea lo más pequeño posible. En el caso extremo donde $\alpha=1$ se tiene que $1-\alpha/2 = 0.5$ y $Z_{0.5}=0$, porque el percentil 50% de la distribución Normal estándar es el punto medio de la campana, o sea, su Esperanza. En conclusión, aumentar el valor de $\alpha$ (o reducir el valor de $1-\alpha$) disminuye el margen de error.

* $\sigma$: representa la variabilidad de nuestra variable original $X$. Este número no lo elegimos: es intrínseco a la variable. Por lo tanto, no podemos utilizarlo para reducir el margen de error.

* $n$: representa el tamaño muestral. Se encuentra en el denominador del término $e$, por lo que, mientras mayor sea, menor será el error.

En conclusión, para aumentar la precisión de nuestro intervalo podemos:

* disminuir la confianza: $\downarrow \text{confianza} \implies \downarrow \text{error} \implies \uparrow \text{precisión}$.
* aumentar el tamaño muestral: $\uparrow n \implies \downarrow \text{error} \implies \uparrow \text{precisión}$.

La relación inversa entre confianza y precisión suele traer confusión. Una buena forma de recordarlo es la siguiente: si decimos algo como "Lionel Messi se encuentra actualmente en el continente americano", la ambigüedad de nuestra afirmación (o, en otras palabras, la poca precisión que estamos dando) nos permite tener una alta confianza de que sea cierta. En el otro extremo, si somos altamente específicos y decimos algo como "Lionel Messi está en la esquina de Zeballos y Ayacucho", estamos siendo muy precisos, pero la chance de que esto sea cierto es muy baja y por lo tanto nuestra confianza también lo sería.

#### Determinación del tamaño muestral

Como el error de nuestro intervalo es función de la confianza y el tamaño muestral, podríamos *a priori* optar por un tamaño muestral que nos dé una amplitud deseada: por ejemplo, $\pm$ 5. ¿Cómo calculamos dicho valor de $n$? Simplemente debemos tomar la fórmula del margen de error y despejar $n$.

$$e = Z_{1-\alpha/2} \frac{\sigma}{\sqrt{n}} \implies n = \left( Z_{1-\alpha/2} \frac{\sigma}{e} \right)^2$$

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Se pretende estimar por intervalo de confianza el tiempo medio de espera para el colectivo 103 rojo en la esquina de Paraguay e Ituzaingó. Se asume que dicha variable es Normal, con un desvío estándar de 11 minutos. Además, se pretende usar una confianza del 95%.

Para lograr dicha estimación, nuestra muestra estará conformada por $n$ personas que reclutaremos para que vayan a la esquina designada en un día y horario elegido al azar, registrando cada una de ellas el tiempo que transcurre entre que llegan a la parada y el colectivo aparece. ¿Cuántas personas debemos reclutar si pretendemos que nuestro intervalo tenga una amplitud de $\pm$ 5'?

**Solución:** Aplicando la fórmula dada, tenemos que $$n = \left( Z_{1-\alpha/2} \frac{\sigma}{e} \right)^2 = \left( Z_{0.975} \cdot \frac{11}{5} \right)^2 = (1.96 \times 2.2)^2 \approx 18.59$$

En conclusión, necesitamos reclutar al menos 19 personas para construir el intervalo deseado.
:::

::: callout-warning
#### Advertencia

En las determinaciones de tamaño de muestra siempre se debe redondear hacia arriba el valor de $n$ obtenido. Por ejemplo, si usando la fórmula obtenemos $n=7,1$ entonces debemos extraer una muestra de al menos 8 individuos.
:::

::: callout-note
#### Nota

Por fines didácticos, los conceptos de "margen de error" y "determinación de tamaño muestral" fueron presentados para el caso de la media de una población Normal, pero en realidad aplican a todas las distribuciones muestrales que estudiamos, como las que presentamos a continuación.
:::

Hasta ahora se presentó el caso de una población Normal con $\sigma$ conocido. ¿Qué pasa si este valor es **desconocido**? Podemos aplicar la distribución muestral estudiada en la unidad anterior, basada en la distribución t-Student.

$$IC_{100(1-\alpha)\%}(\mu) =  \overline{x} \pm t_{(n-1)\,;\, 1-\tfrac{\alpha}{2}} \cdot \tfrac{s}{\sqrt{n}}$$

Recordemos que el valor $s$ representa el desvío estándar muestral.

Para este caso, la función de R que utilizaremos para obtener el percentil $t_{(n-1)\,;\, p}$ será `qt(p, df = n-1)` siendo `n` nuestro tamaño muestral.

Cuando $\sigma$ es desconocido pero la muestra es lo suficientemente grande, usar la distribución t-Student es indistinto a usar la distribución Normal, por lo que podemos plantear:

$$IC_{100(1-\alpha)\%}(\mu) =  \overline{x} \pm Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{s}{\sqrt{n}}$$

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Supongamos que la duración de las clases de Análisis Estadístico es una variable con distribución Normal. En las 17 clases que hemos tenido hasta ahora, la duración promedio fue de 97 minutos, con un desvío estándar de 16 minutos.

Con una confianza del 90%, ¿entre qué valores se espera encontrar la verdadera duración media?

**Solución:** estamos ante una variable Normal con $\sigma$ desconocido y una muestra pequeña. Por lo tanto: $$IC_{90\%}(\mu) =  97 \pm t_{16\,;\, 0.95} \cdot \tfrac{16}{\sqrt{17}} = [90.2 \,;\, 103.8]$$

Con una confianza del 90% y en base a la evidencia muestral, se espera que la verdadera duración media de las clases de Análisis Estadístico se encuentre entre 90 y 104 minutos.
:::

### IC para la diferencia de medias ($\mu_1 - \mu_2$)

Para el caso de dos poblaciones no necesariamente Normales con desvíos estándares conocidos, se tiene que $$\overline{X}_1 - \overline{X}_2 \stackrel{TCL}{\sim} N \left( \mu_1 - \mu_2 \,;\, \frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2} \right)$$

(Nuevamente se recuerda que no es necesario obtener una muestra grande y aplicar el TCL si se sabe de antemano que ambas poblaciones son Normales.)

En consecuencia, el intervalo de confianza para la diferencia de medias está dado por $$IC_{100(1-\alpha)\%}(\mu_1-\mu_2) =  (\overline{x}_1 - \overline{x}_2) \pm Z_{1-\tfrac{\alpha}{2}} \cdot \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$$

Para el caso de $\sigma_1$ y $\sigma_2$ desconocidos, nos enfocaremos sólo en el escenario donde las muestras son suficientemente grandes ($n_1 \geq 30$ y $n_2 \geq 30$).[^4_tdh-3] En este caso, el intervalo está dado por $$IC_{100(1-\alpha)\%}(\mu_1-\mu_2) =  (\overline{x}_1 - \overline{x}_2) \pm Z_{1-\tfrac{\alpha}{2}} \cdot \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}$$

[^4_tdh-3]: Existen distribuciones muestrales para la diferencia de medias con poblaciones Normales, variancias desconocidas y muestras pequeñas. Hemos optado por excluirlas del contenido de esta materia, visto que traen aparejadas cierta complejidad matemática y corresponden a un escenario que no suele darse con frecuencia en la práctica.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Un fabricante de nafta hace pruebas para determinar el rendimiento relativo de los automóviles, empleando dos aditivos diferentes. Los promedios observados (expresados en kilómetros por litro) son 12,37 para el Aditivo 1 y 15,25 para el Aditivo 2. Los desvíos estándar muestrales fueron 1,6 y 4,8. Dichos valores fueron obtenidos de muestras de 40 y 35 automóviles, respectivamente.

Con una confianza del 95%, ¿considera usted que, en promedio, la nafta rinde menos kilómetros con el Aditivo 1?

**Solución:** No conocemos la distribución de la variable en las poblaciones, pero las muestras son grandes. Por lo tanto, $$IC_{95\%}(\mu_1-\mu_2) =  (12.37-15.25) \pm 1.96 \cdot \sqrt{\frac{1.6}{40} + \frac{4.8}{35}} = [-3.70 \,;\, -2.06]$$

Como el límite superior del intervalo es menor a cero, sería sensato asumir, con una confianza del 95%, que el Aditivo 1 rinde menos que el Aditivo 2.
:::

### IC para la proporción ($p$)

Para una variable binaria que sólo admite éxitos y fracasos, hemos visto que ante muestras grandes se tiene $$\hat{p} \stackrel{TCL}{\sim} N \left( p \,;\, \frac{p(1-p)}{n} \right)$$

Por lo tanto, para una confianza del $100(1-\alpha)\%$ se tiene que: $$IC_{100(1-\alpha)\%}(p) =  \hat{p} \pm Z_{1-\tfrac{\alpha}{2}} \cdot \sqrt{\frac{\hat{p} (1 - \hat{p})}{n}}$$

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

El sindicato que representa a los empleados de las casas de comida rápida de Rosario está considerando una propuesta de ajuste de salarios. De acuerdo con el reglamento del sindicato, por lo menos tres cuartas partes de los miembros del sindicato deben aprobar cualquier oferta para que ésta se lleve a cabo. Una muestra aleatoria de 1590 miembros actuales revela que 1283 de ellos planean aprobar la propuesta.

Determine el IC del 95% para la proporción de miembros a favor de la propuesta. En base a esta muestra, ¿podría concluir que la propuesta será eventualmente aprobada?

**Solución:** En primer lugar, la proporción muestral de aprobación es $\hat{p} = \tfrac{1283}{1590} \approx 0,807$. Luego, el IC está dado por $$IC_{95\%}(p) =  0.807 \pm 1.96 \cdot \sqrt{\frac{0.807 \cdot  0.193}{1590}} = 0.807 \pm 0.019 = [0.788 \,;\, 0.826]$$

Como el límite inferior del intervalo supera las tres cuartas partes, sería sensato asumir que la propuesta será aprobada.
:::

## Tests de Hipótesis

En la vida cotidiana es común asumir cosas. Asumimos que la moneda que tenemos en el bolsillo es equilibrada: tiene la misma probabilidad de caer en cara como en cruz. Asumimos que si ahora el cielo está despejado entonces no va a llover en la próxima hora. Asumimos que mañana la Tierra va a seguir girando alrededor del sol. Pero todo esto podría ser falso. ¿Cómo podemos evaluar la "solidez" de estas suposiciones?

### Hipótesis

Una **hipótesis** es un enunciado acerca de una característica poblacional. Esta característica con frecuencia es desconocida, por lo que nuestra hipótesis puede ser verdadera o falsa. En la teoría estadística se trabaja con dos tipos de hipótesis:

* **Hipótesis nula** ($H_0$): es la creencia convencional, el *status quo*, lo que se asume por defecto.
* **Hipótesis alternativa** ($H_1$): es aquel enunciado que desafía el *status quo*, planteando una realidad opuesta a la que propone la hipótesis nula.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Para cada par de hipótesis a continuación, determine cuál sería $H_0$ y cuál sería $H_1$.

* "Los peces vuelan" versus "los peces no vuelan".

* "Tomar agua es bueno para la salud" versus "tomar agua es perjudicial para la salud".

* "El paciente está sano" versus "el paciente está enfermo".

**Solución:**

* $H_0) \text{ Los peces no vuelan} \qquad H_1) \text{ Los peces vuelan}$

* $H_0) \text{ Tomar agua es bueno} \qquad H_1) \text{ Tomar agua es perjudicial}$

* $H_0) \text{ El paciente está sano} \qquad H_1) \text{ El paciente está enfermo}$
:::

En la práctica, las hipótesis suelen centrarse en un parámetro poblacional: el peso medio de las cajas de tornillos manufacturadas en cierta fábrica, la proporción de fumadores en Argentina, el tiempo medio de espera entre colectivos de la misma línea, etcétera. De este modo, las hipótesis pasan a ser redactadas con notación matemática.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Según el envase, el tubo de papas Pringles tiene un peso neto de 124 gramos. Sin embargo, experiencias previas nos han llevado a sospechar que dicho peso medio es falso: suponemos que en realidad es menor. ¿Cuáles son las hipótesis a probar en este caso?

**Solución:** Sea $X$ el peso de un tubo de papas Pringles y $\mu$ el verdadero peso medio de los tubos (en gramos). Luego: $$H_0) \; \mu \geq 124 \qquad H_1) \; \mu < 124$$
:::

¿Por qué el ejemplo anterior considera el caso $\mu > 124$ como parte de $H_0$ si el envase afirma que es exactamente igual a 124 gramos? Recordemos que las hipótesis deben ser *exhaustivas y mutuamente excluyentes*; es decir, su unión debe ser el total de casos posibles y su intersección debe ser vacía. Por lo tanto, el caso $\mu > 124$ debe ser parte de alguna de las dos hipótesis. Como en el ejemplo se sospecha ($H_1$) que el peso medio es menor al estipulado, entonces el caso en cuestión no puede pertenecer a $H_1$ y debe ir a $H_0$. En otras palabras, un peso medio superior a 124 gramos también se consideraría parte del status quo.

Dicho esto, hemos visto en cursos anteriores que es posible definir un test donde $H_0$ sólo incluye una igualdad, y todo lo demás está contenido en $H_1$. Efectivamente existen situaciones prácticas que ameritan esta alternativa.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Se tiene una moneda que se sospecha que no es equilibrada. ¿Cómo pueden formularse hipótesis que pongan a prueba esta sospecha?

**Solución:** Sea $X$ una variable binaria cuyo éxito es "la moneda cae en cruz" y cuyo fracaso es "la moneda cae en cara". Sea $p$ la verdadera proporción de veces que la moneda cae en cruz. Una moneda equilibrada verifica $p=0,5$. Por lo tanto: $$H_0) \; p = 0,5 \qquad H_1) \; p \neq 0,5$$
:::

Cualquiera sea el caso, debe seguirse la siguiente regla: **la igualdad siempre forma parte de $H_0$**.

Cuando existe una competencia entre estas dos teorías, porque algunas personas creen en la hipótesis nula y otras en la hipótesis alternativa, es común realizar una **prueba de hipótesis**: se utiliza información muestral para intentar decidir cuál es la verdadera. La estadística adopta en estos casos la **presunción de inocencia**: se optará por creer que la hipótesis nula es cierta, a menos que se tenga suficiente información para demostrar lo contrario. Pero ¿cómo podemos demostrar lo que ocurre en una población a través de una muestra? ¿Es infalible este método?

### Error

Si lanzamos una moneda al aire diez veces y registramos la cara superior, obteniendo 7 caras y 3 cruces, ¿podríamos sospechar que la moneda no está equilibrada? Después de todo, si lo estuviese, sería de esperar que se obtenga "cara" el 50% de las veces, no el 70%. El problema está en que la práctica no refleja fielmente la teoría. Recordemos la definición frecuencial de probabilidad: nos dice que la frecuencia relativa de un evento aleatorio $A$ tenderá a acercarse a $P(A)$ a medida que el número de repeticiones tiende a infinito.

En la práctica nunca tenemos un número infinito de repeticiones o un tamaño muestral infinito. Debemos inferir mediante un número limitado de observaciones. Por lo tanto, debemos acostumbrarnos al hecho de que el valor de nuestra estimación probablemente no sea una réplica exacta del verdadero parámetro de interés.

La pregunta del millón es entonces: ¿qué tamaño muestral es suficientemente grande como para saber con certeza si nuestros datos avalan o refutan la hipótesis planteada inicialmente? Lamentablemente, la respuesta es "ninguno": no hay tamaño muestral que nos dé certeza.[^4_tdh-4] Sin importar cuán fuerte parezca ser la evidencia muestral (a favor o en contra de una hipótesis), siempre existe la posibilidad de que dicha "evidencia" sea azarosa.

[^4_tdh-4]: Acá estamos asumiendo que nuestra población es infinita. En el caso de una población finita (por ejemplo: los habitantes de Argentina) podemos tener certeza si el tamaño muestral es igual al tamaño poblacional: $n=N$. Esto sería equivalente a un censo en el que todos los individuos responden y nadie miente al responder (dos condiciones que difícilmente se dén en la práctica).

* Podemos entrevistar a mil rosarinos adultos y observar que el 80% de ellos no tiene licencia de conducir, cuando en realidad la verdadera proporción de rosarinos sin licencia de conducir podría ser 10%.[^4_tdh-5]

[^4_tdh-5]: Esto podría darse por falta de representatividad, pero incluso con una muestra perfectamente representativa puede darse este escenario simplemente por mala suerte.

* Si de una caja opaca que contiene cinco canicas azules y una roja extraemos cien canicas con reposición, existe la posibilidad de que saquemos cien veces la canica roja y nos convenzamos de que la caja contiene sólo canicas rojas.

En otras palabras, al hacer inferencia estadística siempre existe la posibilidad de cometer un **error**.

### Tipos de error

Existe una dicotomía en la teoría y otra en la práctica: nuestra suposición inicial ($H_0$) será cierta o no lo será; y nuestra información muestral respaldará la hipótesis nula o no lo hará. Hay dos posibilidades en la teoría y dos posibilidades en la práctica: en total existen cuatro escenarios posibles en los que podríamos estar parados.

::: {.flexcenter data-latex=""}
::: {.half .blackborder data-latex=""}
| Evidencia muestral | $H_0$ cierta | $H_1$ cierta  |
|--------------------|--------------|---------------|
| Avala $H_0$        | Ok           | Error tipo II |
| Avala $H_1$        | Error tipo I | Ok            |
:::
:::

* **Error tipo I** ($e_I$): sucede cuando rechazamos la hipótesis nula (en base a la evidencia muestral) pero en realidad ésta es verdadera.

* **Error tipo II** ($e_{II}$): sucede cuando no rechazamos la hipótesis nula pero en realidad deberíamos.

Dependiendo del problema, un error puede ser más peligroso de cometer que el otro.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Para cada par de hipótesis a continuación, determine cuál error es más peligroso de cometer.

* $H_0) \text{ El paracaídas abre} \qquad H_1) \text{ El paracaídas no abre}$

* $H_0) \text{ El acusado es inocente} \qquad H_1) \text{ El acusado es culpable}$

* $H_0) \text{ El fármaco no tiene efectos colaterales} \quad H_1) \text{ El fármaco tiene efectos colaterales}$

* $H_0) \text{ No va a llover} \qquad H_1) \text{ Va a llover}$

**Solución:**

* $e_{II}$: decir que abre cuando en realidad no abre.

* $e_I$: decir que es culpable cuando en realidad es inocente.

* $e_{II}$: decir que no tiene efectos colaterales cuando en realidad los tiene.

* $e_{II}$: decir que no va a llover cuando en realidad va a llover.
:::

Generalmente se desea defender el punto de vista predominante (es decir, el status quo: $H_0$) porque introducir cambios en algún proceso suele ser una tarea costosa en tiempo, dinero y recursos. Estadísticamente, una manera de "proteger" la hipótesis nula es mediante un procedimiento que asegure una pequeña probabilidad de cometer un error tipo I: $P(e_I)$.

::: callout-warning
#### Advertencia

Dado que tanto $P(e_I)$ como $P(e_{II})$ representan chances de cometer errores, idealmente deseamos que ambas probabilidades sean lo más pequeñas posibles. Desafortunadamente, cuando el número de observaciones $n$ es fijo, no podemos controlar ambas probabilidades. Por eso nos centramos en $P(e_I)$.

La única forma de reducir ambos errores es aumentando el tamaño muestral.
:::

Sabiendo que no podemos anular la probabilidad de cometer un error, debemos definir un umbral o cota superior para $P(e_I)$, de forma tal que estemos cómodos sabiendo que la probabilidad de cometer un error tipo I será menor o a lo sumo igual a la cota. Dicho valor se denomina **nivel de significación**: $\alpha \in (0 \,;\, 1)$. Este valor es definido por el/la investigador/a *antes* de obtener los datos y llevar a cabo el análisis correspondiente. Valores usuales para $\alpha$ son 0,01; 0,05 y 0,10.

De esta manera se tiene: $$P(e_I) = P(\text{rechazar }H_0 \;|\; H_0 \text{ cierta}) \leq \alpha$$

Una vez impuesta esa condición, existen múltiples metodologías que podrían proponerse para poner a prueba las hipótesis de interés. Los tests de hipótesis tradicionales (que estudiaremos en este curso) son aquellos que, dada la restricción anterior, maximizan la **potencia del test**: $1-\beta = 1-P(e_{II})$.[^4_tdh-6]

[^4_tdh-6]: Nótese lo que implica esta definición: la potencia del test es la probabilidad de rechazar $H_0$ sin error.

### p-value

Hasta ahora hemos definido las reglas teóricas bajo las cuales se construyen los tests de hipótesis que emplearemos en esta unidad. Todavía falta contestar una pregunta importante: ¿qué criterio emplear en la práctica para aceptar una hipótesis y rechazar la otra?

Como ya se dijo, al aplicar un test se implementa como principio la presunción de inocencia: se toma el status quo ($H_0$) como realidad hasta que se demuestre lo contrario. Este *mindset* nos conduce a una estrategia matemática para abordar la prueba de hipótesis: si nuestra muestra resulta en un valor que sería muy improbable de observar bajo $H_0$,[^4_tdh-7] entonces sería sensato suponer que estamos bajo $H_1$.

[^4_tdh-7]: La expresión "bajo $H_0$" denota el hecho de estar ante un escenario donde la hipótesis $H_0$ es cierta.

Podemos usar este resultado para proponer la siguiente regla de decisión:

* **Propuesta inicial:** en base a la muestra, si $P(\text{observar lo observado} \;|\; H_0 \text{ cierta}) \leq \alpha$ entonces se rechaza $H_0$.

⚠️ La conclusión anterior es un paso en la dirección correcta. Pero aún presenta un problema, como se ve en el ejemplo siguiente.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Se tiene una moneda y se quiere probar si es equilibrada. Para ello se la arroja al aire un total de 1000 veces, cayendo 500 veces sobre cara y 500 veces sobre cruz. Suponiendo que la moneda es equilibrada, ¿cuál sería la probabilidad de observar este resultado?

**Solución:** Sea $X$ el número de cruces obtenidas tras 1000 lanzamientos de la moneda. Es fácil ver que la variable sigue una distribución Binomial, con parámetro $n=1000$. ¿Cuál es el valor del parámetro $p$? Si suponemos que la moneda es equilibrada, entonces sería $p=0,5$. ¿Cuál es, entonces, la probabilidad de obtener 500 cruces?

$$X \sim Bi(n=1000 \;,\; p=0,5) \implies P(X=500) = \binom{1000}{500} \left(\frac{1}{2}\right)^{1000} \approx 0,0252 = 2,52\%$$
:::

Cuando una variable puede tomar muchos valores distintos, la probabilidad de cada uno de ellos tiende a ser baja. Esto puede llevar a un resultado que desafía la intuición: incluso teniendo una moneda equilibrada, la probabilidad de observar un resultado perfecto tras $n=1000$ réplicas es muy bajo. Para el ejemplo dado, nótese que rechazaríamos la hipótesis nula en todos los resultados posibles. ¡Incluso el que la refleja a la perfección! Para las variables continuas es incluso peor, porque se tendría $P(X=x)=0$ en todos los casos, independientemente del tamaño de la muestra y los valores observados.

Claramente no podemos basar nuestra decisión en la probabilidad puntual del evento observado. Algo que hemos aprendido de trabajar con variables aleatorias continuas es que a veces tiene más sentido calcular la probabilidad de un *intervalo* o conjunto de valores. Surge entonces la siguiente regla:

* **Propuesta nueva:** si $P(\text{observar lo observado o algo más extremo} \;|\; H_0 \text{ cierta}) \leq \alpha$ entonces se rechaza $H_0$.

¿Qué significa "algo más extremo"? Nos referimos a cualquier resultado que, respecto a lo observado, se encuentre en dirección a la hipótesis alternativa $H_1$. Esto depende de la *lateralidad* del test.

* $H_1) \; \theta < \theta_0 \iff$ test unilateral por izquierda

* $H_1) \; \theta > \theta_0 \iff$ test unilateral por derecha

* $H_1) \; \theta \neq \theta_0 \iff$ test bilateral

Entonces:

* Si el test es **unilateral por izquierda**, se calcula $P(\hat{\theta} \leq \hat{\theta}_o \;|\; H_0 \text{ cierta}) = P(\hat{\theta} \leq \hat{\theta}_o \;|\; \theta = \theta_0)$.[^4_tdh-8]

* Si es **unilateral por derecha**, se calcula $P(\hat{\theta} \geq \hat{\theta}_o \;|\; H_0 \text{ cierta}) = P(\hat{\theta} \geq \hat{\theta}_o \;|\; \theta = \theta_0)$.

* Si es **bilateral**, se calcula $P[(|\hat{\theta} - \theta| \geq |\hat{\theta}_o - \theta|) \;|\; H_0 \text{ cierta}] = P[(|\hat{\theta} - \theta| \geq |\hat{\theta}_o - \theta|) \;|\; \theta=\theta_0]$.

[^4_tdh-8]: Se utiliza la notación $\hat{\theta}_o$ para referirse al valor observado del estimador, mientras que $\theta_0$ refiere al valor del parámetro propuesto en la hipótesis nula.

::: callout-warning
#### Advertencia

Nótese que en los tests unilaterales la probabilidad condicional se calcula asumiendo $\theta = \theta_0$ cuando en realidad la hipótesis nula plantea $\theta \geq \theta_0$ ó $\theta \leq \theta_0$ según el caso. Esto es una convención de los tests de hipótesis: se usa la igualdad para calcular la probabilidad, si bien la hipótesis original puede contemplar más valores.
:::

En el siguiente ejemplo se ilustran todos estos casos en simultáneo.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Se arroja una moneda al aire un total de 100 veces, cayendo 63 veces sobre cara y 37 veces sobre cruz. Para cada test que podría plantearse (unilateral por izquierda, por derecha y bilateral) determine si rechazaría o no la hipótesis nula, utilizando un nivel de significación $\alpha = 0,05$.

**Solución:** Sabemos por el ejemplo anterior que la variable bajo estudio (digamos que es "número de cruces") es Binomial. A continuación se plantea la probabilidad de observar lo observado *o algo más extremo* para cada test posible.

* **Caso 1:** test unilateral por izquierda ($H_0)\; p \geq 0,5$ versus $H_1)\; p < 0,5$)

$$P(\hat{p} \leq \tfrac{37}{100} \;|\; p = 0,5) = \sum_{x=0}^{37} \binom{100}{x} \left(\frac{1}{2}\right)^{100} \approx 0,006 < \alpha \implies \text{Rechazo } H_0$$

* **Caso 2:** test unilateral por derecha ($H_0)\; p \leq 0,5$ versus $H_1)\; p > 0,5$)

$$P(\hat{p} \geq \tfrac{37}{100} \;|\; p = 0,5) = \sum_{x=37}^{100} \binom{100}{x} \left(\frac{1}{2}\right)^{100} \approx 0,997 > \alpha \implies \text{No rechazo } H_0$$

* **Caso 3:** test bilateral ($H_0)\; p = 0,5$ versus $H_1)\; p \neq 0,5$)

$$P(|\hat{p} - \tfrac{50}{100}| \geq |\tfrac{37}{100} - \tfrac{50}{100}|) = P(|X - 50| \geq 13) = P(X \leq 37) + P(X \geq 63) \approx$$

$$ \approx 0,006 + 0,006 = 0,012 < \alpha \implies \text{Rechazo } H_0$$
:::

La probabilidad calculada funciona como esperábamos: rechaza o acepta la hipótesis nula de forma sensata en base a la información muestral. Esta herramienta es ampliamente utilizada en Estadística y se la conoce como **p-value**.

$$\text{p-value} = P(\text{observar lo observado o algo más extremo} \;|\; H_0 \text{ cierta})$$
Así, la regla de decisión se reduce a: $\text{p-value} \leq \alpha \implies \text{ Rechazo } H_0$.

### Tests basados en observaciones individuales

Si conocemos la distribución de la variable bajo estudio podemos llevar a cabo un test de hipótesis con una sola observación, equivalente a una muestra de tamaño $n=1$. Esto podemos aplicarlo a cualquiera de las distribuciones de probabilidad que conocemos.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Un hombre apareció muerto de un disparo mientras cazaba en una zona boscosa de Chubut. Se hizo pasar como un accidente, pero la policía interrogó a otro cazador que, según se supo, tuvo un altercado con la víctima. Ellos encontraron una hoja de pino en el saco del sospechoso. El acusado afirmó que estuvo cazando en Salta el día del incidente.

El bosque de Chubut tiene sólo pinos de la especie A y Salta sólo pinos de la especie B. Las hojas tipo aguja de la especie A tienen longitudes distribuidas Normalmente con una media de 5,4 cm y un desvío de 0,4 cm; mientras que las de la especie B también se distribuyen Normalmente pero con una media de 6,4 cm y un desvío de 0,5 cm.

El acusador lo contrata a usted como experto estadístico. La hoja de pino hallada en el saco del sospechoso mide 5,42 cm. En base a esto, ¿qué concluiría? Utilice $\alpha = 0,05$.

**Solución:** El primer paso es postular las hipótesis, a partir de la presunción de inocencia. Sea $X$ la longitud (en centímetros) de la hoja en el saco del sospechoso. Sabemos que la distribución de la variable es Normal, pero no sabemos si sus parámetros corresponden a la especie A o a la especie B.

Si el hombre fuese inocente, la hoja pertenecería a la especie B, cuyas longitudes son mayores. En cambio, si fuese culpable, la hoja pertenecería a la especie A, cuyas longitudes son menores. Por lo tanto planteamos:

$$H_0)\; \mu \geq \mu_B = 6,4 \quad\text{ versus }\quad H_1)\; \mu < \mu_B = 6,4$$

Luego, bajo la hipótesis nula se tiene que: $$X \sim_{H_0} N(\mu = 6,4 \;;\; \sigma = 0,5)$$

Por lo tanto: $P(X \leq 5,42) =$ `pnorm(5.42, mean = 6.4, sd = 0.5)` $\approx 0,025 < 0,05 = \alpha$.

En base a la evidencia muestral, y con un nivel de significación $\alpha=0,05$, se puede concluir que la hoja encontrada en el saco del sospechoso no pertenece a la especie B.
:::

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Tras escribir el borrador de nuestra primera novela, decidimos contactar a un traductor para que convierta el texto a inglés. La persona que contratamos es muy veloz pero nos advierte que suele cometer errores tipográficos, y que el número de errores por página sigue una distribución Poisson con parámetro $\lambda = 1,5$.

Tras terminar la traducción, nos envía el borrador en inglés. Nosotros abrimos una página al azar y rápidamente detectamos 4 errores tipográficos. ¿Es esto evidencia suficiente para reclamar al traductor que está cometiendo más errores de los que admite? Utilice $\alpha = 0,05$.

**Solución:** Sea $X$ el número de errores tipográficos en una hoja. En base a la honestidad o no honestidad del traductor, podemos plantear:

$$H_0)\; \lambda \leq 1,5 \quad\text{ versus }\quad H_1)\; \lambda > 1,5$$

Luego, bajo la hipótesis nula se tiene que: $$X \sim_{H_0} Po(\lambda = 1,5)$$

Por lo tanto: $P(X \geq 4) =$ `1 - ppois(3, lambda = 1.5)` $\approx 0,066 > 0,05 = \alpha$.

En base a la evidencia muestral, y con un nivel de significación $\alpha=0,05$, no se puede rechazar la hipótesis de que el traductor está siendo honesto.
:::

Por otro lado, cuando contamos no con una única observación sino con una muestra, debemos hacer uso de las distribuciones muestrales.

### Test para la media ($\mu$)

En base a lo visto en la unidad anterior y en la sección sobre intervalos de confianza, hay esencialmente 3 casos distintos en los que podemos plantear un test de hipótesis para la media poblacional.

* **Caso 1 (distribución Normal, $\sigma$ conocido):** lo siguiente se cumple para cualquier tamaño muestral.

$$\overline{X} \sim N\left( \mu_0, \frac{\sigma_0}{\sqrt{n}} \right)$$

En esta notación, $\mu_0$ y $\sigma_0$ son los valores de los parámetros propuestos bajo la hipótesis nula.

* **Caso 2 (distribución Normal, $\sigma$ desconocido):** lo siguiente se cumple para cualquier tamaño muestral.
$$T = \frac{\overline{X} - \mu_0}{S / \sqrt{n}} \sim t_{n-1}$$

* **Caso 3 (distribución desconocida):** lo siguiente se cumple para muestras grandes ($n \geq 30$).[^4_tdh-9]

$$\overline{X} \stackrel{TCL}{\sim} N\left( \mu_0, \frac{\sigma_0}{\sqrt{n}} \right)$$

[^4_tdh-9]: En este caso, si se desconoce el valor de $\sigma$ se usa este mismo resultado pero reemplazando el valor por $s$: el desvío estándar muestral.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Ramón sospecha que los profesores de su escuela técnica tienen, en promedio, menos de 5 años de experiencia. Para poner a prueba su sospecha toma una muestra aleatoria de 25 profesores. La media de su muestra fue de 4 años y el desvío estándar fue de 2 años. Suponiendo que la variable en cuestión es Normal y utilizando $\alpha=0,05$, ¿qué debería concluir?

**Solución:** Se plantean las hipótesis:

$$H_0)\; \mu \geq 5 \quad\text{ versus }\quad H_1)\; \mu < 5$$

Luego, bajo la hipótesis nula se tiene que: $$T = \frac{\overline{X} - 5}{S / \sqrt{25}} \sim_{H_0} t_{24}$$

Por lo tanto: $P(T \leq \tfrac{4-5}{2/5}) = P(T \leq -2,5) =$ `pt(-2.5, df=24)` $\approx 0,0098 < \alpha$

En base a la evidencia muestral, y con un nivel de significación $\alpha=0,05$, se rechaza la hipótesis de que la experiencia media en la escuela técnica es, al menos, 5 años.
:::

### Test para la diferencia de medias ($\mu_1 - \mu_2$)

* **Caso 1 (distribución Normal):** lo siguiente se cumple para cualquier tamaño muestral.

$$\overline{X}_1 - \overline{X}_2 \sim N \left( \mu_1 - \mu_2 \,;\, \frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2} \right)$$

Aunque no se vea reflejado en la notación, los valores de los parámetros son los propuestos bajo $H_0$.

* **Caso 2 (distribución desconocida ó $\sigma$ desconocido):** aplica para muestras grandes ($n \geq 30$).

$$\overline{X}_1 - \overline{X}_2 \stackrel{TCL}{\sim} N \left( \mu_1 - \mu_2 \,;\, \frac{s^2_1}{n_1} + \frac{s^2_2}{n_2} \right)$$

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Carla sospecha que, mientras más ejercicio hacen las personas, mayor temperatura toma su cuerpo. Asignó aleatoriamente a unas personas para que ejercitaran durante media hora y otras durante una hora.

Las 54 personas que ejercitaron durante media hora tuvieron una temperatura media de 38,3 °C con un desvío estándar de 0,97 °C. Las 72 personas que entrenaron durante una hora tuvieron una temperatura media de 38,9 °C con un desvío estándar de 1,09 °C.

Utilizando $\alpha=0,05$, ¿concluiría que las temperaturas difieren según el tiempo de ejercicio?

**Solución:** Se plantean las hipótesis:

$$H_0)\; \mu_{30'} = \mu_{60'} \quad\text{ versus }\quad H_1)\; \mu_{30'} \neq \mu_{60'}$$

Luego, bajo la hipótesis nula se tiene que: $$\overline{X}_{30'} - \overline{X}_{60'} \sim_{H_0} N \left( 0 \,;\, \sqrt{\frac{0,97^2}{54} + \frac{1,09^2}{72}} \right)$$

Por lo tanto: $\text{p-value} = P(\overline{X}_{30'} - \overline{X}_{60'} \leq -0,6) + P(\overline{X}_{30'} - \overline{X}_{60'} \leq -0,6)$.

* $P(\overline{X}_{30'} - \overline{X}_{60'} \leq -0,6) =$ `pnorm(-0.6, sd = sqrt(0.97**2/54 + 1.09**2/72))` $\approx 0,00056$

* $P(\overline{X}_{30'} - \overline{X}_{60'} \geq 0,6) =$ `1-pnorm(0.6, sd = sqrt(0.97**2/54 + 1.09**2/72))` $\approx 0,00056$

Finalmente: $\text{p-value} = 0,00056 + 0,00056 = 0,00112 < \alpha$

En base a la evidencia muestral, y con un nivel de significación $\alpha=0,05$, se rechaza la hipótesis de que el tiempo de entrenamiento no afecta la temperatura corporal.
:::

### Test para la proporción ($p$)

Para muestras grandes se tiene $$\hat{p} \stackrel{TCL}{\sim} N \left( p_0 \,;\, \frac{p_0(1-p_0)}{n} \right)$$ donde $p_0$ es el valor de $p$ postulado bajo $H_0$.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

El alcalde de una ciudad leyó un artículo que afirmaba que la tasa de desempleo a nivel nacional es del 8%. Para determinar si esto también se aplica en su ciudad tomó una muestra de 200 residentes. La muestra incluyó 22 residentes desempleados. Utilizando $\alpha=0,05$, ¿qué debería concluir?

**Solución:** Se plantean las hipótesis:

$$H_0)\; p = 0,08 \quad\text{ versus }\quad H_1)\; p \neq 0,08$$

Luego, bajo la hipótesis nula se tiene que: $$\hat{p} \sim_{H_0} N \left( \mu=0,08 \,;\, \sigma^2=\frac{0,08 \cdot 0,92}{200} \right)$$

El valor del estimador fue $\hat{p}_o = 22/200 = 0,11$.

Por lo tanto: $P(\hat{p} \geq 0,11) + P(\hat{p} \leq 0,05)$. Luego:

* $P(\hat{p} \geq 0,11) =$ `1 - pnorm(0.11, mean = 0.08, sd = sqrt(0.08*0.92/200))` $\approx 0,059$

* $P(\hat{p} \leq 0,05) =$ `pnorm(0.05, mean = 0.08, sd = sqrt(0.08*0.92/200))` $\approx 0,059$

Finalmente: $\text{p-value} = 0,059 + 0,059 = 0,118 > \alpha$

En base a la evidencia muestral, y con un nivel de significación $\alpha=0,05$, no se puede rechazar la hipótesis de que la tasa de desempleo en la ciudad es del 8%.
:::

## ¿IC = Test de hipótesis?

Llegado este punto, es probable que hayan detectado muchas similitudes entre la construcción de un intervalo de confianza y la de un test de hipótesis. De hecho, la teoría detrás de cada uno es la misma: se definen a partir de las distribuciones muestrales del estimador de interés.

Más aún, existe una relación entre la determinación de una confianza $1-\alpha$ para un intervalo y la de un nivel de significación $\alpha$ para un test. La relación es la siguiente: 

::: callout-tip
#### Relación entre ICs y tests de hipótesis

Supóngase un test de hipótesis bilateral: $H_0)\; \theta = \theta_0$ versus $H_1)\; \theta \neq \theta_0$. Para un cierto nivel de significación $\alpha \in (0 \;;\; 1)$, si se construye un intervalo de confianza del $100(1-\alpha)\%$ para el parámetro $\theta$ y éste no contiene al valor $\theta_0$, esto es equivalente a un rechazo de la hipótesis nula.

En otras palabras, podemos plantear un test de hipótesis **bilateral** mediante un intervalo de confianza.
:::

Recordemos que una de las interpretaciones de "confianza" es la probabilidad de que el intervalo incluya al verdadero valor del parámetro. Por ejemplo, se tiene un 95% de confianza de que el intervalo $[a;b]$ contiene al verdadero valor de $\theta$. Si el valor $\theta_0$ postulado por la hipótesis nula no está contenido en el intervalo, esto implica que probablemente la muestra no haya provenido de una distribución con $\theta=\theta_0$, y por lo tanto habría que rechazar esa hipótesis nula.
