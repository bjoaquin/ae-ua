```{r}
#| echo: FALSE
#| message: FALSE

library(tidyverse)

contador_ejemplos <- 0
```

# 4. ICs y Tests de hip칩tesis

## Introducci칩n

[Pr칩ximamente. Perd칩n por la demora. 游똂]

## Intervalos de Confianza

La estimaci칩n puntual se basa en representar una caracter칤stica de inter칠s mediante los valores observados de una muestra aleatoria. Sin embargo, los estad칤sticos que usamos como estimadores son variables aleatorias: su valor var칤a de muestra en muestra. Por lo tanto, nunca tenemos certeza sobre si, para la muestra que obtuvimos, nuestra estimaci칩n est치 o no "cerca" del verdadero valor del par치metro de inter칠s.

Afortunadamente, existe otro tipo de estimaci칩n: en lugar de tener un solo n칰mero como estimador, podemos tener un rango de valores. La ventaja de este m칠todo que permite cuantificar (usando probabilidades) el grado de certeza con el que se espera que el verdadero valor del par치metro se encuentre dentro de dicho rango. Estamos hablando de los *intervalos de confianza*.

Formalmente, una estimaci칩n por **intervalo de confianza** para un par치metro $\theta$ se construye a partir de dos funciones $L(\mathbf{x})$ y $U(\mathbf{x})$[^4_tdh-1] y de un valor $\alpha \in (0;1)$, y viene dado por $$IC_{1-\alpha}(\theta) = [L(\mathbf{x}) \,;\, U(\mathbf{x})] \text{ tal que } P(L(\mathbf{x}) \leq \theta \leq U(\mathbf{x})) = 1 - \alpha$$

[^4_tdh-1]: N칩tese la negrita en la $\mathbf{x}$. Esto es para representar el vector de valores muestrales observados: $\mathbf{x} = (x_1, x_2, \cdots, x_n)$.

A la hora de realizar una estimaci칩n por IC, el valor $1-\alpha$ representar치 la **confianza** de nuestro intervalo y se puede interpretar como la probabilidad de que el intervalo $[L(\mathbf{x}) \,;\, U(\mathbf{x})]$ incluya al verdadero valor del par치metro *antes de extraer la muestra*.[^4_tdh-2] Otra interpretaci칩n posible es que, si se tomaran reiteradas muestras de la poblaci칩n bajo estudio y consecuentemente se construyeran m칰ltiples intervalos de confianza, es de esperar que $\theta$ est칠 contenido en el $100(1-\alpha)\%$ de ellos.

[^4_tdh-2]: Una vez tomada la muestra, los extremos del intervalo ya no son variables aleatorias sino n칰meros fijos. Por lo tanto, cuando esto ocurre la proabbilidad de que el verdadero valor del par치metro est칠 contenido en el intervalo es 0 칩 1: el intervalo contiene al par치metro, o bien no lo contiene (aunque nunca sabremos en cu치l caso nos encontramos).

Existen varios m칠todos para construir intervalos de confianza. El m치s utilizado (y el que veremos en este curso) consiste en proponer cuantiles como valores de $L(\mathbf{x})$ y $U(\mathbf{x})$. Dichos cuantiles provienen de la distribuci칩n muestral del estad칤stico que estamos usando para estimar el par치metro.

Por ejemplo, supongamos que queremos estimar la media poblacional mediante la media muestral (hasta ahora esto ser칤a una estimaci칩n puntual, como en la unidad anterior). Sabemos que la distribuci칩n muestral de dicho estad칤stico es Normal (ya sea exacta o aproximadamente, dependiendo de si la variable original es Normal o si debemos recurrir al Teorema Central del L칤mite). La campana Normal correspondiente estar칤a centrada en $\mu$, pero este valor lo desconocemos. Sin embargo, si tomamos a la media muestral observada como nuestra mejor aproximaci칩n de $\mu$ (o sea, $\hat{\mu} = \overline{x}$) entonces podemos concebir una curva Normal emp칤rica centrada en este valor. Si quisi칠ramos constuir un intervalo con una confianza del 95%, deber칤amos tomar los cuantiles 2,5% y 97,5%, de modo que el intervalo est칠 compuesto por el 95% central de la campana.

![Ilustraci칩n de un intervalo de confianza del 95% para la media poblacional.](img/ci_mean.jpg){#fig-meanci}

::: callout-note
#### Nota

N칩tese c칩mo el uso de las distribuciones muestrales se torna casi opuesto entre la teor칤a (Unidad 3) y la pr치ctica (Unidad 4). En un entorno te칩rico, conocemos el valor del par치metro poblacional e hipotetizamos sobre qu칠 ocurrir칤a cuando eventualmente tomemos una muestra, calculando la probabilidad de que nuestro estimador tome un valor dentro de un cierto intervalo: $P(a \leq \hat{\theta} \leq b)$. En la pr치ctica, sin embargo, el proceso es el inverso: el valor del estimador muestral es lo que se conoce, y se calcula la probabilidad de que el par치metro poblacional tome un valor dentro de un cierto intervalo.
:::

### IC para la media de una poblaci칩n Normal ($\mu$)

Sea $X_1, X_2, \cdots, X_n$ una muestra aleatoria de tama침o $n$ extra칤da de una poblaci칩n con distribuci칩n $N(\mu,\sigma)$. Sabemos que la media muestral tambi칠n tiene distribuci칩n Normal. Entonces podemos utilizar lo siguiente:

$$\overline{X} \sim N\left( \mu, \frac{\sigma}{\sqrt{n}} \right) \implies Z = \frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)$$

Lo anterior es f치cilmente demostrable. Para empezar, cualquier combinaci칩n lineal de una variable Normal es a su vez una variable Normal. Como $Z$ es una combinaci칩n lineal de $\overline{X}$ y $\overline{X}$ es Normal entonces $Z$ tambi칠n es una variable Normal. 쮺칩mo podr칤amos deducir la Esperanza y Variancia de esta nueva variable aleatoria? Utilizando propiedades de $E(X)$ y $V(X)$ para combinaciones lineales.

$E(Z) = E(\tfrac{\sqrt{n}}{\sigma}[\overline{X}-\mu]) = \tfrac{\sqrt{n}}{\sigma} E(\overline{X}-\mu) = \tfrac{\sqrt{n}}{\sigma} [E(\overline{X})-E(\mu)] = \tfrac{\sqrt{n}}{\sigma} [\mu-\mu] = 0$

$V(Z) = V(\tfrac{\sqrt{n}}{\sigma}[\overline{X}-\mu]) = \tfrac{n}{\sigma^2} V(\overline{X}-\mu) = \tfrac{n}{\sigma^2} V(\overline{X}) = \tfrac{n}{\sigma^2} \cdot \tfrac{\sigma^2}{n} = 1$

Hemos as칤 demostrado que $Z \sim N(0,1)$. 쮻e qu칠 nos sirve esto? La distribuci칩n $N(0,1)$ se conoce como **distribuci칩n Normal est치ndar**. Es 칰til para obtener cuantiles sobre una distribuci칩n Normal. Sea $Z_p$ el cuantil que acumula un $100p\%$ del 치rea bajo la curva Normal est치ndar. Bajo esta definici칩n, resulta que $Z_p$ nos dice cu치ntos desv칤os est치ndares debemos movernos respecto a la media para obtener el cuantil correspondiente en nuestra variable original: $\overline{X}_p$.

Por ejemplo, supongamos que queremos obtener un intervalo de confianza del 95% para la media poblacional. Como se mencion칩 anteriormente, debemos buscar los cuantiles 2,5% y 97,5%. Para esto podemos obtener $Z_{0.025} = -1,96$ y $Z_{0.975} = 1,96$. En otras palabras, deberemos movernos 1,96 desv칤os est치ndares por debajo y por encima de la media para obtener el intervalo de confianza deseado.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Sea $X$ una v.a. Normal con media desconocida y desv칤o est치ndar igual a 10. Se extrae una muestra aleatoria de tama침o 25 y se obtiene una media muestral $\overline{x} = 18$. Construya un intervalo de confianza del 95% para la media poblacional.

**Soluci칩n:** Si $X \sim N(\mu, \sigma=10)$, luego $\overline{X} \sim N(\mu, \tfrac{10}{\sqrt{25}} = 2)$.

En base a c치lculos anteriores sabemos que debemos movernos $\pm$ 1,96 desv칤os est치ndares respecto a la media muestral observada. Recordemos que esos desv칤os est치ndares no corresponden a la variable original sino al estad칤stico que estamos utilizando. Por lo tanto:

$$IC_{95\%}(\mu) = [18 - 1,96 \cdot 2 \,;\, 18 + 1,96 \cdot 2] = [14,08 \,;\, 21,92]$$

En t칠rminos del problema dir칤amos que: en base a la evidencia muestral, se tiene un 95% de confianza de que la verdadera media poblacional se encuentra entre 14,08 y 21,92.
:::

En l칤neas generales, la f칩rmula es la siguiente:
$$IC_{100(1-\alpha)\%}(\theta) = \left[\overline{x} + Z_{\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \,;\, \overline{x} + Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \right] = \left[\overline{x} - Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \,;\, \overline{x} + Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \right]$$

Este intervalo est치 sujeto a las distribuciones muestrales estudiadas en la unidad anterior, por lo que aplican los mismos criterios: si la variable original $X$ es Normal, entonces se puede usar la distribuci칩n Normal para calcular el intervalo de confianza, sin importar el tama침o muestral. Si $X$ no es Normal o su distribuci칩n es desconocida, ante una muestra grande se puede construir este IC *aproximado* empleando el Teorema Central del L칤mite.

::: callout-tip
#### Idea clave

Quiz치s hayan notado, a partir de la definici칩n anterior, que $Z_{\tfrac{\alpha}{2}} = -Z_{1-\tfrac{\alpha}{2}}$. Esto se vio en el ejemplo anterior: $Z_{0.025} = -Z_{0.975} = -1,96$. Esta es una propiedad que cumple la distribuci칩n Normal est치ndar, y una de las razones por las que resulta c칩moda para calcular cuantiles: sus cuantiles son sim칠tricos respecto al centro (el percentil 50%).
:::

::: callout-tip
#### Idea clave

Para calcular percentiles de una distribuci칩n Normal est치ndar podemos usar una funci칩n de R: `qnorm(p)`, donde `p` es el percentil de inter칠s.
:::
