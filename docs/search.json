[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis Estadístico (UA)",
    "section": "",
    "text": "Prefacio\nDesde la cátedra de Análisis Estadístico, les damos una cálida bienvenida a este nuevo curso, donde nos sumergiremos nuevamente en el fascinante mundo de los datos, la toma de decisiones y, sobre todas las cosas, el apasionante proceso de aprendizaje.\n¿Alguna vez se han preguntado cómo las empresas líderes toman decisiones cruciales basadas en datos? ¿O cómo pueden prever tendencias económicas que transforman industrias enteras? A lo largo de este curso, exploraremos técnicas y conceptos fundamentales que nos permitirán descubrir el valioso conocimiento que los datos pueden brindarnos. Desde los conceptos básicos de la teoría de probabilidad hasta métodos gráficos e inferenciales, aprenderemos a resolver problemas y ofrecer soluciones basadas en un análisis riguroso.\n¡Esperamos que tomen este recorrido como un desafío, como una oportunidad para poner a prueba sus habilidades y construir un espacio interactivo donde tanto ustedes como nosotros enriquezcamos nuestros conocimientos!"
  },
  {
    "objectID": "0_conteo.html#introducción",
    "href": "0_conteo.html#introducción",
    "title": "0. Herramientas de conteo",
    "section": "Introducción",
    "text": "Introducción\nLas herramientas de conteo sirven para contar el número de maneras distintas de obtener un cierto resultado, incluso bajo algunas condiciones o restricciones. Algunos ejemplos son:\n\nconociendo a los 3 ganadores de una competencia pero sin saber el orden en que ganaron, determinar de cuántas formas distintas podría haberse formado un podio entre esos 3 participantes.\ncontar el número de formas en el que 5 personas pueden viajar en un auto de 5 asientos, considerando que sólo dos de ellas tienen licencia de conducir.\ncontar el número de partidas de ajedrez que pueden jugarse en un torneo con 32 participantes, bajo la condición de que cada par de participantes se enfrenten una y sólo una vez.\ncontar el número de estados posibles en los que puede hallarse un cubo de Rubik.\ncontar el número de formas en el que 200 invitados a una fiesta pueden organizarse en mesas de 6 personas. Considerar cómo este número se vería afectado si a la fiesta asisten dos personas que se detestan y no quieren sentarse en la misma mesa.\nsabiendo que en WhatsApp se recibieron 23 mensajes de 5 chats, contar el número de formas en que estos 23 mensajes podrían encontrarse repartidos entre esos 5 chats."
  },
  {
    "objectID": "0_conteo.html#herramientas-de-conteo-simples",
    "href": "0_conteo.html#herramientas-de-conteo-simples",
    "title": "0. Herramientas de conteo",
    "section": "Herramientas de conteo simples",
    "text": "Herramientas de conteo simples\n\nFactoriales\nEl caso más simple para contar resultados posibles, del cual se desprenden todos los demás, consiste en contar de cuántas maneras puede reordenarse un conjunto de \\(n\\) elementos, siendo \\(n\\) un número natural (es decir, \\(n \\in \\mathbb{N}\\)).\n\n\nEjemplo 1\n\nTres personas (las llamaremos \\(A\\), \\(B\\) y \\(C\\)) quieren sentarse en un sofá de tres asientos. ¿De cuántas formas distintas pueden hacerlo?\nSolución: Este caso es lo suficientemente sencillo como para resolverlo por enumeración exhaustiva: se pueden listar todos los resultados posibles y después contar el tamaño de dicha lista.\nLos posibles reordenamientos de un grupo de 3 personas son:\n\n\n\n\n\n\\(ABC\\)\n\\(BAC\\)\n\\(CAB\\)\n\n\n\\(ACB\\)\n\\(BCA\\)\n\\(CBA\\)\n\n\n\n\n\nPor lo tanto, existen 6 formas de que tres personas se sienten en un sillón de tres asientos.\n\nEl problema con la enumeración exhaustiva es que el número de reordenamientos crece rápidamente a medida que el tamaño del conjunto (o sea, \\(n\\)) aumenta. Si logramos hallar un patrón o una fórmula en la forma de contar el número de reordenamientos posibles, entonces podremos calcular el número de reordenamientos para cualquier \\(n\\), sin tener que enumerar todos los casos posibles.\n\n\n\n\n\n\nIdea clave\n\n\n\nLas herramientas de conteo nos permiten contar elementos sin necesidad de enumerarlos.\n\n\nVolvamos al ejemplo con \\(n=3\\). Para empezar: ¿cuántas personas distintas pueden sentarse en el primer asiento del sofá? Es evidente que cualquiera de las tres personas en cuestión (\\(A\\), \\(B\\) y \\(C\\)) pueden ocupar este lugar y por lo tanto la respuesta es 3. Ahora bien, ¿cuántas personas pueden sentarse en el segundo asiento, si consideramos que ya hay una persona sentada en el primero? Las opciones se ven reducidas. Si bien no sabemos quién, una de las personas ya está sentada en el primer asiento y por lo tanto no es elegible para sentarse en el segundo asiento. Sólo las dos personas restantes pueden ocupar dicho lugar y en consecuencia la respuesta es 2. Por último, ¿cuántas personas pueden sentarse en el tercer asiento si los dos primeros ya están ocupados? En este caso la respuesta es trivial: si dos de las tres personas ya se encuentran sentadas, entonces sólo queda una persona para sentarse en el tercer asiento y en consecuencia la respuesta es 1.\nEn resumen, existen 3 posibilidades distintas para el primer asiento; por cada una de ellas se tienen 2 posibilidades distintas para el segundo asiento; a su vez, por cada una de las combinaciones anteriores (una persona en el primer asiento y otra en el segundo asiento) se tiene, por descarte, una sola posibilidad para el tercer asiento.\nEn total se tienen \\[3 \\times 2 \\times 1 = 6 \\;\\text{resultados posibles.}\\]\n¿Qué pasaría si fuesen \\(n=4\\) personas en un sofá de 4 asientos? Si llamamos \\(D\\) a la cuarta persona, la tabla de resultados posibles para esta situación es:\n\n\n\n\n\n\\(ABCD\\)\n\\(BACD\\)\n\\(CABD\\)\n\\(DABC\\)\n\n\n\\(ABDC\\)\n\\(BADC\\)\n\\(CADB\\)\n\\(DACB\\)\n\n\n\\(ACBD\\)\n\\(BCAD\\)\n\\(CBAD\\)\n\\(DBAC\\)\n\n\n\\(ACDB\\)\n\\(BCDA\\)\n\\(CBDA\\)\n\\(DBCA\\)\n\n\n\\(ADBC\\)\n\\(BDAC\\)\n\\(CDAB\\)\n\\(DCAB\\)\n\n\n\\(ADCB\\)\n\\(BDCA\\)\n\\(CDBA\\)\n\\(DCBA\\)\n\n\n\n\n\nNuevamente, por enumeración exhaustiva podemos ver que hay 24 resultados posibles para esta situación. ¿Cómo podríamos haberlo deducido sin tener que listar cada resultado? Afortunadamente, el razonamiento para el caso \\(n=4\\) es análogo al caso \\(n=3\\).\nCualquier persona puede sentarse en el primer asiento y por lo tanto hay 4 formas distintas en las que este lugar puede ser ocupado. Para cada uno de esos escenarios, cualquiera de las tres personas restantes puede ocupar el segundo asiento, resultando en 3 formas posibles de ocuparlo. A su vez, para cada una de las combinaciones anteriores (una persona en el primer asiento y otra persona en el segundo asiento) cualquiera de las dos personas restantes puede ocupar el tercer asiento y por lo tanto se tienen 2 formas posibles de ocuparlo. Finalmente, si tres de las cuatro personas ya se encuentran sentadas en los primeros tres asientos del sofá, entonces sólo queda un escenario posible para el cuarto asiento: que sea ocupado por la persona restante.\nEn total se tienen \\[4 \\times 3 \\times 2 \\times 1 = 24 \\;\\text{resultados posibles.}\\]\nEs fácil ver que este razonamiento es aplicable a cualquier número de personas y asientos. En general, si se tienen \\(n\\) personas queriendo sentarse en un sofá de \\(n\\) asientos, existen \\[n \\times (n-1) \\times (n-2) \\times \\cdots \\times 3 \\times 2 \\times 1\\] formas distintas de lograrlo.\nEl procedimiento anterior es utilizado con frecuencia en combinatoria1 y por lo tanto tiene su propio símbolo y nombre.\nSea \\(n \\in \\mathbb{N}\\), se llama factorial de \\(\\mathbf{n}\\) a \\[n! = n \\times (n-1)  \\times (n-2) \\times \\cdots \\times 3 \\times 2 \\times 1\\]\nExisten dos formas alternativas de definir el factorial de \\(n\\): en forma iterativa y en forma recursiva.\nForma iterativa: \\[n = \\prod_{i=1}^n i = 1 \\times 2 \\times 3 \\times \\cdots \\times (n-1) \\times n\\]\nForma recursiva: \\[n! = n \\times (n-1)! \\qquad \\forall \\; n \\in \\mathbb{N}\\]\nUn detalle a tener en cuenta con la forma recursiva es que para \\(n=1\\) se tiene que \\(1! = 1 \\times 0!\\). Por convención, se considera que \\(0! = 1\\).\n\n\nEjemplo 2\n\nUna lista de reproducción de Spotify está compuesta por 9 canciones. ¿En cuántos órdenes distintos pueden escucharse todas las canciones de la lista?\nSolución: El problema consiste en averiguar cuántos reordenamientos son posibles para la lista de 9 canciones. Como ya vimos, esto equivale a \\[9! = 9 \\times 8 \\times 7 \\times 6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1 = 362\\,880 \\text{ órdenes distintos.}\\]\n\nNótese el gran número de reordenamientos que resulta de un número tan pequeño de elementos. Este número es tan grande que sería inviable resolver el problema por enumeración exhaustiva. Incluso para una lista de 5 canciones se tendrían \\(5!=120\\) posibles reordenamientos, los cuales ya son muchos como para escribirlos uno por uno. En líneas generales, el número factorial crece muy rápidamente, incluso más que el número exponencial.\n\n\n\n\n\nFigura 2.1: Comparación de las funciones exponencial y factorial.\n\n\n\n\nComo ya se dijo, el factorial es la base de las herramientas de conteo, pero no es la única. Es una forma práctica de contar el número de reordenamientos de \\(n\\) elementos. Por ejemplo, en una carrera de Fórmula 1, donde compiten 20 autos, podemos usar el factorial para contar el número de resultados distintos para dicha carrera. Pero ¿qué pasaría si sólo nos interesara el resultado del podio, es decir, de las primeras 3 posiciones? Dicho de otro modo, dado un conjunto de \\(n\\) elementos, ¿cómo podemos contar el número de subconjuntos ordenados de \\(r&lt;n\\) elementos?\n\n\nPermutaciones\nIntentemos resolver el problema propuesto en la sección anterior aplicando la misma lógica que nos llevó a descubrir el número factorial.\n\n\nEjemplo 3\n\nEn una carrera de Fórmula 1 compiten 20 vehículos. ¿De cuántas formas distintas puede establecerse un podio en dicha carrera?\nSolución: Cualquiera de los 20 conductores es elegible para ocupar el primer puesto. A su vez, por cada una de estas posibilidades, quedan 19 conductores que podrían tomar el segundo puesto. Finalmente, teniendo ya un conductor en el primer puesto y otro conductor en el segundo puesto, cualquiera de los 18 conductores restantes pueden ocupar el tercer puesto.\nEn conclusión, existen \\[20 \\times 19 \\times 18 = 6\\,840 \\text{ podios posibles.}\\]\n\nIgnorando el contexto del problema, acabamos de deducir la forma de contar el número de subconjuntos ordenados de tamaño \\(r=3\\) obtenidos a partir de un conjunto de tamaño \\(n=20\\).\nPara resolver este ejemplo empleamos la misma técnica de “multiplicación descendente” que dedujimos para el factorial, pero esta vez nos detuvimos después de \\(r\\) factores en lugar de multiplicar los \\(n\\) primeros números naturales. ¿Cómo podríamos generalizar este procedimiento en una fórmula?\nPara valores \\(n\\) y \\(r\\) cualesquiera (con \\(r&lt;n\\)), el cálculo realizado es \\[n \\times (n-1) \\times (n-2) \\times \\cdots \\times (n-r+2) \\times (n-r+1)\\]\nAl ser un producto, multiplicar el valor anterior por 1 no lo modifica en absoluto. Pero si escribimos ese 1 como \\(\\textstyle\\frac{(n-r)!}{(n-r)!}\\) entonces se obtendría \\[n \\times (n-1) \\times \\cdots \\times (n-r+1) \\times \\frac{(n-r)!}{(n-r)!} = \\frac{n \\times (n-1) \\times \\cdots \\times (n-r+1) \\times (n-r)!}{(n-r)!}\\]\nUtilizando la definición recursiva del número factorial, el producto de los dos últimos factores del numerador equivale a \\((n-r+1)!\\) y por lo tanto la expresión anterior equivale a \\[\\frac{n \\times (n-1) \\times \\cdots \\times (n-r+2) \\times (n-r+1)!}{(n-r)!}\\]\nA su vez, el producto de los dos últimos factores del numerador en esta nueva expresión equivale a \\((n-r+2)!\\). Aplicando sucesivamente este procedimiento se llega a que el numerador es igual a \\(n!\\). Es decir, la expresión anterior equivale a \\[\\frac{n!}{(n-r)!}\\]\nHemos deducido otra herramienta de conteo importante.\nSean \\(n \\in \\mathbb{N}_0, \\; r \\in \\mathbb{N}_0\\) 2 tales que \\(r \\leq n\\), se llama permutación de \\(\\mathbf{n}\\) elementos en \\(\\mathbf{r}\\) a \\[_nP_r = \\frac{n!}{(n-r)!}\\]\nNótese que cuando \\(r=n\\) se tiene \\[_nP_n = \\frac{n!}{(n-n)!} = \\frac{n!}{0!} = \\frac{n!}{1} = n!\\]\nEsto tiene sentido, visto que lo que estamos contando a través de este número es el número de subconjuntos ordenados de tamaño \\(n\\) obtenidos a partir de un conjunto de tamaño \\(n\\). Esto no es más que el número de reordenamientos entre \\(n\\) elementos, lo cual (por lo visto en la sección anterior) sabemos que equivale a \\(n!\\). En otras palabras, el número de reordenamientos de un conjunto de \\(n\\) elementos no es más que un caso particular de una permutación. Es por ello que el número de reordenamientos de conjuntos de tamaño \\(n\\) suele denominarse permutación de \\(\\mathbf{n}\\) elementos y simbolizarse como \\(P_n\\).\n\n\nEjemplo 4\n\nSe tienen 8 franjas de tela, cada una de un color diferente. Se pretende utilizar tres de ellas para armar una bandera compuesta por una franja superior, una franja media y una franja inferior. ¿Cuántas banderas distintas son posibles?\nSolución: Partiendo de un conjunto de \\(n=8\\) elementos, debemos calcular el número de subconjuntos ordenados de tamaño \\(r=3\\). Es decir, debemos calcular una permutación de 8 en 3. \\[_8P_3 = \\frac{8!}{5!} = 8 \\times 7 \\times 6 = 336 \\text{ banderas posibles.}\\]\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nMás allá de que una permutación se defina como un cociente de factoriales, en la práctica no es aconsejable calcular dicho cociente. Esto es porque los factoriales tienden a ser números muy grandes; tanto es así que es muy fácil encontrarse con números cuyo factorial es imposible de calcular con la tecnología de la que hoy disponemos.3 Incluso si pudiésemos calcular los números factoriales que componen el cociente, éstos podrían ser extremadamente grandes, dificultando considerablemente los cálculos. 4 Es por esto que, de hacerse los cálculos a mano, se recomienda seguir el proceso de multiplicación descendente.\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nSi bien hablamos de subconjuntos ordenados, al calcular permutaciones no es importante que exista una verdadera ordinalidad entre los elementos (en el sentido de que uno de ellos anteceda o suceda a otro), sino en realidad que estos sean distinguibles entre sí. Claramente la ordinalidad es una condición suficiente para lograr lo anterior, pero no es una condición necesaria, como veremos en el ejemplo siguiente.\n\n\n\n\nEjemplo 5\n\nEl club de debate de una escuela secundaria cuenta con nueve miembros. La semana próxima se realizará un torneo de debate que tomará lugar en cuatro ciudades diferentes: Seattle, Baltimore, Washington y Denver. El director de la escuela debe elegir a un participante para enviar a cada ciudad. ¿De cuántas formas distintas puede hacer esto?\nSolución: Nótese que en este ejemplo importa no sólo cuáles de los 9 miembros del club son seleccionados, sino también a qué ciudad es enviado cada uno. Se fija entonces el orden de las ciudades tal como fueron enumeradas en el enunciado, de modo que el primer participante será enviado a Seattle; el segundo, a Baltimore; el tercero, a Washington y el cuarto, a Denver. Nótese que el orden elegido para las ciudades no afecta los cálculos. Efectivamente, para cualquier orden arbitrario entre las 4 ciudades se obtendría el mismo resultado.\nHay 9 posibles participantes para ser enviados al torneo en Seattle. Por cada uno de ellos, cualquiera de los 8 restantes puede ser enviado a Baltimore. A su vez, por cada par de participantes elegidos para Seattle y Baltimore respectivamente, cualquiera de los 7 restantes puede ser asignado a Washington. Por último, para cualquier terna ordenada de tres alumnos, cualquiera de los 6 restantes puede ser enviado a Denver.\nPor lo tanto, se tienen \\[_9P_5 = 9 \\times 8 \\times 7 \\times 6 = 3\\,024 \\text{ formas posibles.}\\]\n\nEste ejemplo plantea un escenario donde cada uno de los participantes seleccionados es asignado a una ciudad diferente y por lo tanto los cuatro roles son distinguibles entre sí. Supongamos ahora que el torneo de debate se lleva a cabo en un solo lugar, y por lo tanto los cuatro roles son equivalentes e intercambiables. Ciertamente esto llevaría a una reducción en el número de formas distintas de elegir los participantes, porque soluciones que anteriormente podían considerarse distintas (por ejemplo, el conjunto de alumnos \\([A, B, C, D]\\) y el conjunto \\([B, D, A, C]\\)) ahora deberían contarse como una única solución.\nLa pregunta es: ¿cuál es entonces el número de formas distintas de elegir los participantes?\n\n\nCombinaciones\n\n\nEjemplo 6\n\nUn club de debate de con nueve miembros debe elegir a cuatro de ellos para representar a su escuela en un torneo nacional. ¿De cuántas formas distintas puede hacerse esto?\nSolución: Por lo visto en el Ejemplo 5 sabemos que, si cada uno de los cuatro puestos a ocupar fuese diferenciable de los otros tres, habría \\(_9P_4 = 3\\,024\\) formas distintas de lograr el objetivo. Pero ahora estos puestos son todos iguales y por lo tanto sólo importa cuáles de los nueve alumnos ingresan en la selección, sin importar el orden en que se los elige. Esto implica que el resultado será menor al del Ejemplo 5. Procedamos a calcular este valor.\nSupongamos que el conjunto total de alumnos es \\(\\{ A,B,C,D,E,F,G,H,I \\}\\). Un subconjunto posible de tamaño \\(r=4\\) es \\(\\{ B, E, G, H \\}\\). El valor \\(_9P_4\\) cuenta este mismo subconjunto varias veces, porque permuta sus elementos y considera dichas permutaciones como resultados distintos. En particular ¿cuántas veces cuenta cada uno? Sabemos que la cantidad de permutaciones entre 4 elementos es igual a \\(P_4 = 4! = 24\\). Es decir que por cada 24 subconjuntos enumerados por el valor \\(_9P_4\\), ahora sólo nos interesa uno.\nEn conclusión, se tienen \\[\\frac{_9P_4}{4!} = \\frac{3024}{24} = 126 \\text{ formas posibles.}\\]\n\nEn general, dado un conjunto de \\(n\\) elementos, hay \\(\\textstyle\\frac{_nP_r}{r!}\\) formas distintas de elegir subconjuntos no ordenados de \\(r \\leq n\\) elementos. Este cálculo corresponde a nuestra tercer herramienta de conteo.\nSean \\(n \\in \\mathbb{N}_0, \\; r \\in \\mathbb{N}_0\\) tales que \\(r \\leq n\\), se llama combinación de \\(\\mathbf{n}\\) elementos en \\(\\mathbf{r}\\) a \\[_nC_r = \\frac{_nP_r}{r!} = \\frac{n!}{r! \\, (n-r)!}\\]\nNótese que \\(_nC_r \\leq \\; _nP_r \\quad \\forall \\; n, r \\in \\mathbb{N}_0\\) tales que \\(r \\leq n\\).\nEn otras palabras, cuando queramos contar el número de “grupos” (de tamaño fijo) que pueden formarse a partir de un conjunto, utilizaremos combinaciones. Si adicionalmente nos interesa establecer “roles” dentro de dicho grupo, utilizaremos permutaciones.\n\n\nEjemplo 7a\n\nUn comité de 3 personas debe formarse a partir de un grupo de 20 personas. ¿De cuántas formas distintas puede hacerse esto?\nSolución: Tenemos un conjunto de tamaño \\(n=20\\) y nos interesa armar un grupo de tamaño \\(r=3\\), pero sin asignar roles dentro del grupo (es decir, los 3 cargos a ocupar son indistinguibles entre sí). En conclusión, debemos usar una combinación: \\[_{20}C_3 = \\frac{20!}{3!\\;17!} = \\frac{20 \\times 19 \\times 18}{3 \\times 2 \\times 1} = 1\\,140 \\text{ comités posibles.}\\]\n\n\nEjemplo 7b\n\nSupongamos ahora que los 3 cargos a ocupar en el comité son presidente, vicepresidente y secretario. ¿Cómo afecta esto el número de posibles comités?\nSolución: Como ahora los cargos son distinguibles entre sí, ya no importa únicamente quiénes son las 3 personas seleccionadas sino también el rol que ocupa cada una de ellas. Debemos usar entonces una permutación: \\[_{20}P_3 = \\frac{20!}{17!} = 20 \\times 19 \\times 18 = 6\\,840 \\text{ comités posibles.}\\]"
  },
  {
    "objectID": "0_conteo.html#herramientas-de-conteo-con-repetición",
    "href": "0_conteo.html#herramientas-de-conteo-con-repetición",
    "title": "0. Herramientas de conteo",
    "section": "Herramientas de conteo con repetición",
    "text": "Herramientas de conteo con repetición\nLas herramientas presentadas hasta ahora tienen una importante limitación: asumen que cada elemento de nuestro conjunto original sólo puede ser seleccionado una única vez. En los ejemplos vistos hasta ahora esta suposición es adecuada: si necesitamos llenar 3 cupos para formar un comité, no tendría sentido darle 2 cargos a la misma persona (por ejemplo: que sea presidente y vicepresidente simultáneamente). Estos son casos donde la selección se realiza sin repetición o sin reposición. Es análogo al bingo: cada vez que se saca una bola, ésta no vuelve al bolillero y por lo tanto su correspondiente número no puede ser seleccionado otra vez.\nPero existen casos donde amerita realizar una selección con repetición o con reposición. En la analogía del bingo, esto sería equivalente a extraer una bola, anotar su número correspondiente y volver a meterla en el bolillero, de modo que dicha bola podría volver a ser seleccionada en extracciones posteriores.\nCuando la selección es con repetición, las fórmulas que vimos hasta ahora ya no sirven. Esto es porque el número de subconjuntos posibles aumenta cuando pasamos de una selección sin repetición a una con repetición. Veámoslo con un ejemplo.\n\n\nEjemplo 8\n\nTenemos una bolsa con tres bolas enumeradas del 1 al 3. Se procede a hacer una selección con repetición de dos bolas; es decir, se selecciona una primera bola, se anota su número, se la vuelve a introducir en la bolsa y se selecciona una segunda bola. Si nos interesa distinguir la primera bola de la segunda, ¿cuántas extracciones distintas son posibles?\nSolución: Si la selección fuese sin repetición, habría \\(_3P_2 = 6\\) formas posibles de seleccionar dos bolas. Estas son:\n\n\n\n\n\n\\((1,2)\\)\n\\((2,1)\\)\n\\((3,1)\\)\n\n\n\\((1,3)\\)\n\\((2,3)\\)\n\\((3,2)\\)\n\n\n\n\n\nPero como la selección es con repetición, también debemos contar los casos donde se selecciona dos veces la misma bola. Estos son 3 casos en total: \\((1,1)\\), \\((2,2)\\) y \\((3,3)\\). Por lo tanto, en total se tienen: \\[_3P_2 + 3 = 6 + 3 = 9 \\text{ extracciones posibles.}\\]\n\nEn conclusión, debemos deducir nuevas fórmulas para las permutaciones y combinaciones en los casos donde se selecciona con repetición.\n\nPermutaciones con repetición\nSupongamos que tenemos una bolsa con \\(n=7\\) canicas y debemos seleccionar \\(r=3\\) de ellas. Anteriormente, bajo el paradigma de una selección sin repetición, nuestra lógica era la siguiente: hay 7 formas de seleccionar la primera canica, luego 6 formas de seleccionar la segunda (porque la primera que seleccionamos ya no está disponible) y por último 5 formas de seleccionar la tercera (porque tanto la primera como la segunda canica seleccionada ya no están disponibles). En total, existen \\(7 \\times 6 \\times 5 = 210\\) formas distintas de realizar esta selección.\nAhora bien, bajo una selección con repetición, esta falta de disponibilidad que considerábamos luego de cada selección ya no existe, porque la reposición actúa como un reset y entonces todas las canicas están disponibles en todas las extracciones. ¿Cómo afecta esto los cálculos? Hay 7 formas de seleccionar la primera canica, luego 7 formas de seleccionar la segunda y 7 formas de seleccionar la tercera. En total tenemos \\(7 \\times 7 \\times 7 = 7^3 = 343\\) formas distintas de realizar esta selección.\n¿Cómo se generaliza está lógica para valores arbitrarios de \\(n\\) y \\(r\\)? Si tenemos \\(n\\) canicas y debemos seleccionar \\(r\\) de ellas con reposición, entonces hay \\(n\\) formas de seleccionar la primera canica, \\(n\\) formas de seleccionar la segunda canica, y así sucesivamente para las \\(r\\) canicas. O sea, en total tenemos: \\[ \\underbrace{n \\times n \\times \\cdots \\times n}_\\text{$r$ veces} = n^r \\text{ selecciones distintas.} \\]\nEsto nos da una fórmula para calcular permutaciones.\nSean \\(n \\in \\mathbb{N}_0, \\; r \\in \\mathbb{N}_0\\), se llama permutación con repetición de \\(\\mathbf{n}\\) elementos en \\(\\mathbf{r}\\) a \\[_nP'_r = n^r.\\]\n\n\nEjemplo 9\n\nUn candado numérico tiene 3 rotores, donde cada de ellos puede estar seteado en un dígito del 0 al 9. ¿Cuántas claves distintas son posibles?\nSolución: Se tienen \\(n=10\\) posibles dígitos a ser seleccionados (con repetición) un total de \\(r=3\\) veces, una por rotor. Utilizando la ecuación que acabamos de deducir: \\[_{10}P'_3 = 10^3 = 1\\,000 \\text{ claves posibles.}\\]\n\nEn las herramientas con repetición, a diferencia de las herramientas simples, no es necesario que se verifique \\(r \\leq n\\). Es decir, podemos tener una bolsa con \\(n=3\\) canicas y seleccionar \\(r=100\\) de ellas con repetición. Esto es porque, al reponerlas tras cada extracción, las canicas actúan como si fuesen infinitas y por lo tanto podemos realizar tantas extracciones como queramos.\n\n\nEjemplo 10\n\nSe tienen 3 lamparitas en fila. Cada una de ellas puede estar apagada o encendida. ¿Cuántas configuraciones de on/off son posibles?\nSolución: Una forma de pensar en este problema es como si contásemos con \\(n=2\\) estados (apagado y encendido) que se seleccionan con repetición para cada una de las \\(r=3\\) lamparitas. Por lo tanto, el número de permutaciones con repetición nos lleva a: \\[_2P'_3 = 2^3 = 8 \\text{ configuraciones posibles.}\\] Estas configuraciones son:\n\n\n\n\n\n❌❌❌\n❌❌✅\n❌✅❌\n❌✅✅\n\n\n✅❌❌\n✅❌✅\n✅✅❌\n✅✅✅\n\n\n\n\n\ndonde ❌ representa una lamparita apagada y ✅ representa una encendida.\n\nA veces debemos ser creativos al pensar cuáles son los \\(n\\) elementos y cuáles son los \\(r\\) cupos en nuestro problema. Con frecuencia se piensa en la entidad más tangible como los elementos y la menos tangible como los cupos (por ejemplo: la entidad tangible son las personas y la entidad intangible son los cargos a ocupar en un comité). Esto no siempre funciona: si pensáramos en las \\(n=3\\) lamparitas como los elementos y los \\(r=2\\) estados (“on” y “off”) como los cupos, tendríamos que existen \\(_3P'_2 = 3^2 = 9\\) resultados posibles, lo cual es incorrecto.\n¿Cómo podemos evitar este error? Visto que estamos contando el número de resultados posibles de un cierto evento, a veces resulta de mucha ayuda escribir uno de esos posibles resultados a modo ilustrativo. La “longitud” de tal resultado será igual a \\(r\\). Veámoslo con los dos ejemplos anteriores:\n\n\n\n\n\n\n\n\n\n\n\nProblema\nEjemplo de solución\nLongitud de solución\n\\(r\\)\n\n\n\n\nCandado numérico\n\\(2\\quad 5\\quad 6\\)\n3 elementos\n\\(r=3\\)\n\n\nLamparitas\n✅❌✅\n3 elementos\n\\(r=3\\)\n\n\n\n\n\n\n\nCombinaciones con repetición\nLas combinaciones también pueden usarse ante una selección con repetición. La deducción de su fórmula quizás sea la más compleja de todas las herramientas, pero vale la pena, porque nos brinda una forma alternativa de pensar algunos ejercicios de combinatoria.\n\n\nEjemplo 11\n\nEn una bolsa se tienen dos canicas: una azul y una roja. Se seleccionan dos de ellas al azar y con reposición. ¿Cuántas extracciones distintas son posibles?\nSolución: Llamemos \\(A\\) a la canica azul y \\(R\\) a la canica roja. Tras la primera extracción, la canica es devuelta a la bolsa y en la segunda extracción es posible repetirla. Podemos pensar en la canica repetida como un elemento adicional, como si nuestra bolsa contuviera 3 canicas: una roja, una azul, y una del mismo color de la primera canica que seleccionemos. Como aún no sabemos de qué color será, podemos simbolizarla con una estrella, como si fuera un comodín.\n\\[\\{ \\; A, \\; R, \\; \\star \\; \\}\\]\nDe este modo consideramos la repetición mediante comodines en nuestro conjunto de elementos (la bolsa de canicas). Este nuevo problema puede resolverse utilizando una combinación simple. Ahora tengo 3 elementos, pero sigo teniendo que extraer 2 de ellos.\nPor lo tanto, el número de combinaciones con repetición resulta: \\[_2C'_2 \\;=\\; _3C_2 = 3 \\text{ extracciones posibles.}\\]\n\nEl resultado anterior es fácilmente verificable por enumeración exhaustiva. Las tres selecciones posibles son: extraer dos veces la canica azul, extraer dos veces la canica roja, o extraer una vez cada canica. Matemáticamente, estos resultados pueden expresarse como \\(\\{A, A\\}, \\{R, R\\}, \\{A, R\\}\\). ¿Cómo se ven estos resultados bajo el enfoque del comodín?\n\n\n\n\n\nOriginal\n\nAlternativo\n\n\n\n\n\\(\\{A,A\\}\\)\n\\(\\longrightarrow\\)\n\\(\\{A,\\star\\}\\)\n\n\n\\(\\{R,R\\}\\)\n\\(\\longrightarrow\\)\n\\(\\{R,\\star\\}\\)\n\n\n\\(\\{A,R\\}\\)\n\\(\\longrightarrow\\)\n\\(\\{A,R\\}\\)\n\n\n\n\n\nNótese que, bajo el enfoque de las 3 canicas, podría ocurrir que el comodín se seleccione en la primera extracción. ¿Cómo se interpretaría eso? Para tal caso cambiamos la definición del comodín: esta canica adicional repetirá el color de la canica que se seleccione en la segunda extracción. Aunque pueda parecer arbitrario, veremos en ejemplos posteriores que existe una forma sistemática de definir el valor que toma nuestro comodín.\nSigamos construyendo una solución mediante otro ejemplo.\n\n\nEjemplo 12\n\nEn una bolsa se tienen dos canicas: una azul y una roja. Se seleccionan tres de ellas al azar y con reposición. ¿Cuántas extracciones distintas son posibles?\nSolución: Llamemos \\(A\\) a la canica azul y \\(R\\) a la canica roja. En este caso no alcanza con incorporar un único comodín porque, al ser tres extracciones y no dos, puede ocurrir que extraigamos la misma canica un total de tres veces: una extracción original + dos repeticiones. Por lo tanto es necesario contar con dos comodines. Usaremos un subíndice para diferenciarlos.\n\\[\\{\\; A, \\; R, \\; \\star_1, \\; \\star_2 \\;\\}\\]\nBajo una combinación simple, esto resultaría en un total de \\(_4C_3 = 4\\) selecciones distintas. ¿Cómo podríamos trazar una equivalencia entre los resultados del enfoque de comodines y el enfoque original del problema? Para lograr esto conviene escribir los posibles resultados en forma ordenada: primero las canicas de colores (en orden alfabético) y luego los comodines (en orden ascendiente de subíndices).\nUna vez expresados de esta manera, las estrellas toman la siguiente definición: la estrella \\(i\\)-ésima, \\(\\star_i\\), asume el valor del \\(i\\)-ésimo elemento del resultado.\n\n\n\n\n\nOriginal\n\nAlternativo\n\n\n\n\n\\(\\{A,A,A\\}\\)\n\\(\\longrightarrow\\)\n\\(\\{A,\\star_1,\\star_2\\}\\)\n\n\n\\(\\{A,A,R\\}\\)\n\\(\\longrightarrow\\)\n\\(\\{A,R,\\star_1\\}\\)\n\n\n\\(\\{A,R,R\\}\\)\n\\(\\longrightarrow\\)\n\\(\\{A,R,\\star_2\\}\\)\n\n\n\\(\\{R,R,R\\}\\)\n\\(\\longrightarrow\\)\n\\(\\{R,\\star_1,\\star_2\\}\\)\n\n\n\n\n\nNótese cómo funciona la primera equivalencia: \\(\\star_1\\) toma el valor del primer elemento en ese conjunto, o sea, \\(A\\) (azul). A su vez, \\(\\star_2\\) toma el valor del segundo elemento, o sea, \\(\\star_1\\), que ya dijimos que es una canica azul. Por lo tanto, ese resultado es equivalente a seleccionar una canica azul en las tres extracciones. El segundo resultado, por otra parte, se traduce como \\(\\{A,R,\\star_1\\} \\equiv \\{A,R,A\\} \\equiv \\{A,A,R\\}\\) (recordemos que no importa el orden de las extracciones y por eso los dos últimos conjuntos son equivalentes).\nEn conclusión, se tienen: \\[_2C'_3 \\;=\\; _4C_3 = 4 \\text{ extracciones posibles.}\\]\n\nA partir de este ejemplo podemos ver que las combinaciones con repetición cuentan con la misma propiedad que las permutaciones con repetición: \\(n\\) puede ser menor, igual o mayor a \\(r\\).\nYa estamos en condiciones de deducir la fórmula para las combinaciones con repetición. Hemos visto que pueden calcularse a través de una combinación simple, la cual considera el mismo número de \\(r\\) cupos pero un número mayor de elementos. ¿Cuántos, exactamente? Hay que sumarle el número de comodines, el cual siempre es igual al número de extracciones exceptuando la primera, o sea, \\(r-1\\).\nSean \\(n \\in \\mathbb{N}_0, \\; r \\in \\mathbb{N}_0\\), se llama combinación con repetición de \\(\\mathbf{n}\\) elementos en \\(\\mathbf{r}\\) a \\[_nC'_r \\; = \\; _{(n+r-1)}C_r = \\dfrac{(n+r-1)!}{r! \\; (n-1)!}.\\]\n\n\nEjemplo 13\n\nUna biblioteca tiene únicamente libros de contabilidad, de finanzas y de marketing. Seleccionando cinco de ellos al azar, ¿cuántos grupos de libros son posibles?\nSolución: Llamemos \\(C\\) a los libros de contabilidad, \\(F\\) a los de finanzas y \\(M\\) a los de marketing. Un grupo posible sería \\(\\{C,F,F,M,M\\}\\), ya que sólo nos interesa el género de cada libro.\nUtilizando la fórmula que acabamos de deducir: \\[_3C'_5 \\;=\\; _{(3+5-1)}C_5 \\;=\\; _7C_5 = 21 \\text{ grupos de libros posibles.}\\]\n\nEl ejemplo anterior muestra algo interesante: a veces las “reposiciones” son simbólicas, no reales. En este caso no teníamos canicas en una bolsa sino libros en una biblioteca. Más aún, los libros que seleccionamos no eran siempre los mismos sino que pertenecían a una gran colección.\n¿Por qué, entonces, hablamos de combinaciones con repetición? Esto es porque lo que nos interesa de cada libro, lo que los identifica, es su género, y esa característica sí se repite entre elementos distintos. Matemáticamente, esto es equivalente a tener un solo libro de cada género (contabilidad, finanzas y marketing), ponerlos en una caja y realizar cinco extracciones con reposición, de modo que cada libro pueda ser seleccionado en más de una ocasión.\nSi estos casos generan confusión, se recomienda nuevamente visualizar cómo sería un posible resultado, tal como se hizo en el ejemplo anterior y como se muestra en detalle en el siguiente.\n\n\nEjemplo 14\n\nUn local de empanadas tiene sólo 4 sabores disponibles: carne, humita, pollo y verdura. Pidiendo 3 empanadas, ¿cuántos pedidos distintos son posibles?\nSolución: Llamemos \\(C\\), \\(H\\), \\(P\\) y \\(V\\) a los sabores. Por enumeración exhaustiva, los posibles pedidos de 3 empanadas son:\n\n\n\n\n\n1 sabor\n2 sabores\n\n3 sabores\n\n\n\n\n\\(\\{C,C,C\\}\\)\n\\(\\{C,C,H\\}\\)\n\\(\\{C,H,H\\}\\)\n\\(\\{C,H,P\\}\\)\n\n\n\\(\\{H,H,H\\}\\)\n\\(\\{C,C,P\\}\\)\n\\(\\{C,P,P\\}\\)\n\\(\\{C,H,V\\}\\)\n\n\n\\(\\{P,P,P\\}\\)\n\\(\\{C,C,V\\}\\)\n\\(\\{C,V,V\\}\\)\n\\(\\{C,P,V\\}\\)\n\n\n\\(\\{V,V,V\\}\\)\n\\(\\{H,H,P\\}\\)\n\\(\\{H,P,P\\}\\)\n\\(\\{H,P,V\\}\\)\n\n\n\n\\(\\{H,H,V\\}\\)\n\\(\\{H,V,V\\}\\)\n\n\n\n\n\\(\\{P,P,V\\}\\)\n\\(\\{P,V,V\\}\\)\n\n\n\n\n\n\nEsto nos da un total de 20 pedidos posibles. Verifiquemos que la fórmula para combinaciones con repetición nos devuelve el mismo resultado.\n\\[_4C'_3 = \\; _{(4+3-1)}C_3 \\; = \\; _6C_3 = \\dfrac{6!}{3! \\; 3!} = 20\\]\nPor lo tanto: \\[_4C'_3 = 20 \\text{ pedidos posibles.}\\]"
  },
  {
    "objectID": "0_conteo.html#reglas-de-conteo",
    "href": "0_conteo.html#reglas-de-conteo",
    "title": "0. Herramientas de conteo",
    "section": "Reglas de conteo",
    "text": "Reglas de conteo\nLo que vimos hasta ahora son herramientas de conteo: artificios matemáticos para calcular en forma relativamente sencilla el número de formas posibles de hacer algo. Estas herramientas respetan ciertos lineamientos llamados reglas de conteo, las cuales veremos a continuación. Bajo ciertos escenarios simples, estas reglas son útiles por sí mismas para calcular el número de formas posibles de resolver una tarea.\n\nRegla de la multiplicidad\nLa primera regla de conteo es la regla de la multiplicidad:\nConsidérese un proceso que consiste en \\(k\\) etapas, donde cada una de ellas puede realizarse de \\(n_1\\), \\(n_2\\), \\(\\cdots\\), \\(n_k\\) maneras diferentes, y donde cada una de las maneras de realizar una etapa puede combinarse con todas las maneras de las demás etapas. Entonces el procedimiento total puede realizarse de \\[\\prod_{i=1}^k n_i = n_1 \\times n_2 \\times \\cdots \\times n_k\\] maneras diferentes.\n\n\nEjemplo 15\n\nSi en mi armario tengo 5 camisas, 3 pantalones y 2 pares de zapatos, ¿de cuántas formas distintas puedo vestirme?\nSolución: El proceso “vestirse” consta de \\(k=3\\) etapas: ponerse una camisa, ponerse un pantalón y ponerse un par de zapatos. Existen \\(n_1=5\\) formas de elegir una camisa, \\(n_2=3\\) formas de elegir un pantalón y \\(n_3=2\\) formas de elegir un par de zapatos.\nAsumiendo que cada prenda de ropa puede combinarse con cualquier otra, esto resulta en un total de: \\[n_1 \\times n_2 \\times n_3 = 5 \\times 3 \\times 2 = 30 \\text{ vestuarios posibles.}\\]\n\n\n\nRegla de la adición\nLa segunda regla de conteo es la regla de la adición:\nConsidérese un proceso que admite \\(k\\) enfoques posibles, donde para cada uno de ellos existen \\(n_1\\), \\(n_2\\), \\(\\cdots\\), \\(n_k\\) formas distintas de ponerlo en práctica, pero donde elegir uno de los enfoques implica descartar todos los demás. Entonces el procedimiento total puede realizarse de \\[\\sum_{i=1}^k n_i = n_1 + n_2 + \\cdots + n_k\\] maneras diferentes.\n\n\nEjemplo 16\n\nPara viajar hoy de Rosario a Buenos Aires hay disponibles 2 horarios de tren, 14 de colectivo y 3 de avión. ¿Cuántas opciones disponibles hay para viajar?\nSolución: El proceso “viajar de Rosario a Buenos Aires” admite \\(k=3\\) enfoques: viajar en tren, viajar en colectivo o viajar en avión. Existen \\(n_1=2\\) formas de viajar en tren, \\(n_2=14\\) formas de viajar en colectivo y \\(n_3=3\\) formas de viajar en avión. Naturalmente, elegir uno de los enfoques implica descartar los demás (es decir, si viajo en avión no voy a viajar en tren).\nEsto resulta en un total de: \\[n_1 + n_2 + n_3 = 2 + 14 + 3 = 19 \\text{ viajes posibles.}\\]\n\nEsta propiedad a través de la cual elegir un enfoque implica no poder elegir ninguno de los demás es lo que se conoce como exclusividad mutua. Dos elementos vinculados de este modo se denominan mutuamente excluyentes. Por ejemplo, nacer en Argentina y nacer en Turquía son condiciones mutuamente excluyentes porque, si una es cierta, la otra no puede serlo."
  },
  {
    "objectID": "0_conteo.html#mezclando-reglas-y-herramientas",
    "href": "0_conteo.html#mezclando-reglas-y-herramientas",
    "title": "0. Herramientas de conteo",
    "section": "Mezclando reglas y herramientas",
    "text": "Mezclando reglas y herramientas\nOcasionalmente nos encontramos con escenarios complejos, para los cuales no nos alcanza con una sola herramienta de conteo para contar todas las alternativas posibles. Cuando esto ocurre, debemos hacer uso de una mezcla de herramientas, las cuales se unen haciendo uso de las reglas de conteo.\n\n\nEjemplo 17\n\nLas matrículas de vehículos en China están compuestas por dos letras, seguidas por cuatro dígitos. ¿Cuántas matrículas distintas son posibles bajo este sistema?\nSolución: El proceso de generación de una matrícula puede visualizarse como compuesto por dos etapas: selección de letras y selección de dígitos. Visto que cualquier conjunto de letras puede combinarse con cualquier conjunto de dígitos, estos dos sub-resultados deberán ser posteriormente multiplicados entre sí (regla de la multiplicidad).\nEn cuanto a las letras, sabemos que importa el orden en que las escribimos y que pueden repetirse, por lo que existen \\(_{26}P'_2 = 26^2\\) formas de elegirlas.\nEn cuanto a los dígitos, también importa su orden y también pueden repetirse, por lo que existen \\(_{10}P'_4 = 10^4\\) formas de elegirlos.\nEsto resulta en un total de: \\[26^2 \\times 10^4 = 676 \\times 10\\,000 = 6\\,760\\,000 \\text{ matrículas distintas.}\\]\n\n\n\nEjemplo 18\n\nEn la base de datos de una empresa nacional, los empleados diurnos son identificados con un número de legajo compuesto por dos letras seguidas por dos dígitos, mientras que el número de legajo de los empleados nocturnos consiste en una letra seguida por tres dígitos. ¿Cuántos empleados distintos admite este sistema?\nSolución: Podemos pensar en la obtención de un número de legajo como un proceso que admite dos versiones: una para empleados diurnos y otra para empleados nocturnos. Estas versiones son mutuamente excluyentes y por lo tanto los números de legajos distintos de cada versión deben sumarse (regla de la adición).\nUsando lo visto en el ejemplo anterior, podemos deducir que existen \\(_{27}P'_2 \\,\\times\\, _{10}P'_2\\) legajos posibles para los empleados diurnos y que existen \\(_{27}P'_1 \\,\\times\\, _{10}P'_3\\) legajos posibles para los nocturnos.\nEsto resulta en un total de: \\[(27^2 \\times 10^2) + (27 \\times 10^3) = 72\\,900 + 27\\,000 = 99\\,900 \\text{ empleados distintos.}\\]\n\n\n\nEjemplo 19\n\nSe tiene un total de 14 libros: 5 de química, 4 de física, 3 de astronomía y 2 de botánica. ¿De cuántas formas distintas pueden ser ordenados en una repisa?\nSolución: Nótese que cuando la consigna habla de “ordenar los libros”, esto es respecto al tema de cada uno; es decir, intercambiar de lugar dos libros de física no se considera un nuevo ordenamiento, pero uno de física y uno de botánica sí. Como tal, una posible solución tendría la forma: \\[\\{Q,A,F,F,Q,A,F,Q,Q,Q,B,A,B,F\\}\\]\nUna buena estrategia sería pensar, uno por uno, cómo los libros de cada tema podrían ser posicionados en la repisa. Tomemos, en primer lugar, los 5 libros de química. Estos podrían posicionarse en cualquiera de los 14 espacios vacíos de la repisa. ¿De cuántas maneras? Para calcular esto podríamos pensar en los 14 espacios como “elementos” y en los 5 libros como “cupos” a seleccionar. Esto nos da un total de \\(_{14}C_5 = 2\\,002\\) formas de ordenar los 5 libros de química entre los 14 espacios de una repisa.\nQuedan aún 9 espacios vacíos. ¿De cuántas maneras podemos llenar 4 de ellos con libros de física? En forma análoga a lo anterior, serían en total \\(_9C_4 = 126\\) formas distintas. Para combinar ambos resultados, nótese que cualquiera de los ordenamientos de los libros de química puede combinarse con cualquiera de los ordenamientos de los de física. Aplicando la regla de la multiplicidad, estos valores deberían ser multiplicados entre sí. Del mismo modo se considerarían los libros de astronomía y de botánica.\nEsto resulta en un total de: \\[_{14}C_5 \\;\\times\\; _9C_4 \\;\\times\\; _5C_3 \\;\\times\\; _2C_2 = 2\\,002 \\times 126 \\times 10 \\times 1 = 2\\,522\\,520 \\text{ órdenes distintos.}\\]\n\nEl ejemplo anterior introduce una herramienta muy útil en la combinatoria, que surge de mezclar herramientas y reglas de conteo.\nSea un conjunto de \\(n\\) elementos, los cuales pueden clasificarse en \\(k\\) grupos mutuamente excluyentes. Si hay \\(n_1\\) elementos en el primer grupo, \\(n_2\\) en el segundo, \\(\\cdots\\), \\(n_k\\) en el \\(k\\)-ésimo, se denomina coeficiente multinomial, calculado como \\[\\dfrac{n!}{n_1! \\; n_2! \\; \\cdots \\; n_k!}\\] al número de formas de ordenar los elementos según su grupo. Nótese que debe verificarse \\(n_1+n_2+\\cdots+n_k=n\\). Nótese también que para el caso de \\(k=2\\) grupos este coeficiente equivale a una combinación simple."
  },
  {
    "objectID": "0_conteo.html#un-caso-real-mccombinaciones",
    "href": "0_conteo.html#un-caso-real-mccombinaciones",
    "title": "0. Herramientas de conteo",
    "section": "Un caso real: McCombinaciones",
    "text": "Un caso real: McCombinaciones\nEn 2002, McDonald’s lanzó una campaña para publicitar el menú McChoice: un menú compuesto por ocho ítems (gaseosa, hamburguesa, papas fritas, batido, pancho, entre otros). Cada cliente podía elegir si quería o no incluir cada uno de los ítems en su pedido, lo cual abría la posibilidad a ordenar un menú McChoice de muchas maneras distintas. ¿Cuántas, exactamente? En su campaña publicitaria, McDonald’s afirmaba que habían \\(40\\,312\\) formas posibles de ordenar un menú, lo cual es un gran error.\n\n\n\nFigura 2.2: Una valla publicitaria anunciando el lanzamiento del menú McChoice.\n\n\nLa elección de un menú específico surge de contestar “sí” o “no” a ocho preguntas específicas: ¿quiere una gaseosa?, ¿quiere un pancho?, ¿quiere un helado?, etcétera. Como cada uno de los ítems son distinguibles entre sí, la herramienta de conteo adecuada para este problema es una permutación con repetición, porque se repite ocho veces la pregunta de sí/no pero, dependiendo del orden en que se pregunta, cada respuesta está asociada a un ítem diferente. En otras palabras, se tiene un total de \\(2^8 = 256\\) menúes posibles, aunque lo correcto sería excluir el caso del “menú vacío”, donde el cliente contesta “no” a todas las preguntas (no tendría sentido). En ese caso el resultado es: \\[2^8 - 1 = 256 - 1 = 255 \\text{ menúes posibles.}\\]\n¿Cómo McDonald’s arribó a un número tan distinto? Se desconoce el cálculo que realizaron, visto que públicamente negaron haber cometido un error (Parker 2019), pero es fácil observar que \\(40\\,312 = 8! - 8.\\) Dada la similitud entre la estructura de este cálculo y la respuesta correcta, es sensato suponer que McDonald’s intentó seguir la misma lógica. El mayor error que cometieron fue usar un número factorial, el cual sirve para contar el número de formas de ordenar los ocho ítems del menú. Es decir, asumieron que los clientes pedirían todos los ítems del menú y las “diferencias” entre ellos surgirían del orden en que estos alimentos fuesen consumidos (si bien esto es ilógico porque, por ejemplo, la gaseosa suele consumirse al mismo tiempo que la hamburguesa, en vez de antes o después).\nUn total de 154 personas presentaron una queja oficial a la Advertising Standards Authority de Reino Unido. A pesar de estar publicitando un número que resultó ser más de cien veces mayor al real, la agencia falló a favor de McDonald’s (Parker 2019). Desde entonces, se le llaman McCombinaciones5 a los números del tipo \\(n!-n\\), donde para \\(n=8\\) se tiene el número utilizado en la publicidad.\n\n\n\n\nParker, M. 2019. Humble Pi: A Comedy of Maths Errors. Penguin Books Limited. https://books.google.com.ar/books?id=qYlZDwAAQBAJ."
  },
  {
    "objectID": "0_conteo.html#footnotes",
    "href": "0_conteo.html#footnotes",
    "title": "0. Herramientas de conteo",
    "section": "",
    "text": "La combinatoria es la rama de las matemáticas que estudia la enumeración de configuraciones que satisfacen ciertas condiciones.↩︎\nEl conjunto \\(\\mathbb{N}_0\\) equivale al conjunto de números naturales y el número 0, es decir que \\(\\mathbb{N}_0 = \\{0\\} \\cup \\mathbb{N} = \\{ 0,1,2,3,4,\\cdots \\}\\). Si bien los casos donde \\(n=0\\) y/o \\(r=0\\) son triviales y poco frecuentes en la práctica, estos son posibles desde el punto de vista matemático y por lo tanto se los incluye. Esto no significa que no tienen sentido práctico: el caso \\(r=0\\), por ejemplo, refiere al número de formas de elegir subconjuntos de cero elementos; se considera que sólo hay una forma posible de hacer esto (no elegir ningún elemento).↩︎\nEn las calculadoras convencionales el mayor número factorial que puede calcularse es \\(69!\\), mientras que en las computadoras actuales dicho número es \\(170!\\).↩︎\nhttps://www.youtube.com/watch?v=flqC3c2wsNI↩︎\nSecuencia A005096 de la OEIS.↩︎"
  },
  {
    "objectID": "1_prob.html#introducción",
    "href": "1_prob.html#introducción",
    "title": "1. Probabilidad",
    "section": "Introducción",
    "text": "Introducción\nSupongamos que abre una heladería nueva en la ciudad. Esta heladería sólo tiene ocho sabores distintos, pero se rumorea que son muy buenos. Un amigo nuestro quiere probar sus helados, por lo que propone ir a comprar un pote de un kilogramo, en el que entran cuatro sabores distintos. Nosotros accedemos con gusto. Nuestro amigo sale rumbo a la heladería y nosotros nos quedamos en el departamento esperando su regreso. De repente caemos en la cuenta de que nunca decidimos qué sabores pedir. Sabemos que uno de los ocho sabores de la heladería es limón, el cual nuestro amigo adora pero nosotros detestamos. Lo detestamos a tal punto que, si uno de los cuatro sabores del pote fuese limón, no comeríamos ninguno de ellos. Entonces nos hacemos una pregunta.\n¿Cuál es la probabilidad de que nuestro amigo traiga helado de limón?"
  },
  {
    "objectID": "1_prob.html#definiciones-importantes",
    "href": "1_prob.html#definiciones-importantes",
    "title": "1. Probabilidad",
    "section": "Definiciones importantes",
    "text": "Definiciones importantes\nAntes de calcular una probabilidad debemos generar el ambiente propicio: definir matemáticamente los elementos básicos que componen la situación sobre la cual queremos obtener probabilidades. Esto se hace para evitar ambigüedades y ordenar nuestro pensamiento.\n\nExperimento aleatorio\nEl experimento aleatorio es aquella situación en la que no es posible saber de antemano el resultado a obtener, incluso repitiéndola varias veces bajo las mismas condiciones.\nEn el ejemplo propuesto, el experimento aleatorio es “elegir 4 sabores de helado entre 8 posibles”.\n\n\n\n\n\n\nNota\n\n\n\nEs costumbre definir el experimento aleatorio partiendo de un verbo en infinitivo: en este caso, “elegir”. Nótese que esto no refleja quién es la persona que lleva a cabo la acción. La idea es despojarse de toda información innecesaria y centrarse en la acción cuyo resultado genera incertidumbre.\n\n\nLos experimentos aleatorios gozan de una propiedad llamada regularidad estadística, la cual refiere a una estabilidad a largo plazo en la frecuencia de aparición de los resultados obtenidos. Por ejemplo: si arrojo muchas veces una moneda (llamémosle “cara” y “cruz” a sus dos lados), es de esperar que a largo plazo el porcentaje de caras obtenidas sea aproximadamente 50%.\n\n\nEspacio muestral\nEl espacio muestral es el conjunto de todos los resultados posibles e imaginables del experimento aleatorio. Se lo suele simbolizar con la letra \\(S\\).\nEn el ejemplo, supongamos que los ocho sabores de la heladería son:\n\nSabores = { Chocolate, Vainilla, Frutilla, Limón, Menta, Dulce de Leche, Americana, Sambayón }\n\nPor lo tanto, un posible resultado del experimento sería \\(s\\) = {Menta, Vainilla, Americana, Limón}.\n¿Cuántos resultados distintos existen? Para responder a esta pregunta podemos hacer uso de las herramientas de conteo estudiadas en la unidad anterior. Como no nos importa el orden y no se admite una repetición de los sabores, usamos una combinación simple: \\(_8C_4 = 70\\) posibles elecciones de 4 sabores. Este es el tamaño del conjunto \\(S\\). En notación matemática se dice que \\(\\#S = 70\\).\n\\[S = \\{ s_1, s_2, s_3, \\cdots, s_{69}, s_{70} \\}\\]\nSi quisiéramos definir al conjunto \\(S\\) en forma exhaustiva 1, se vería algo así como:\n\\(S\\) = {\n\n{Chocolate, Vainilla, Frutilla, Limón},\n{Chocolate, Vainilla, Frutilla, Menta},\n{Chocolate, Vainilla, Frutilla, Dulce de Leche},\n\\(\\cdots\\)\n{Menta, Dulce de Leche, Americana, Sambayón}\n\n}\n\n\nSuceso aleatorio\nSe denomina suceso o evento aleatorio a cualquier subconjunto del espacio muestral.\nVolviendo al ejemplo, un evento podría ser “elegir chocolate”. Este evento equivale a un subconjunto de \\(S\\) que contiene todas aquellas elecciones donde uno de los 4 sabores es Chocolate, sin importar cuáles son los 3 sabores restantes. ¿Qué tamaño tiene este subconjunto? En total contiene \\(_7C_3 = 35\\) elementos.\nSuele usarse una letra mayúscula para definir un suceso. En este caso:\n\n\\(A\\): elegir Chocolate\n\nOtros ejemplos de eventos sobre este mismo experimento podrían ser:\n\n\\(B\\): no elegir Frutilla\n\\(C\\): elegir Limón y Chocolate\n\\(D\\): elegir un sabor frutal\n\\(E\\): no elegir ningún sabor"
  },
  {
    "objectID": "1_prob.html#operaciones-entre-sucesos",
    "href": "1_prob.html#operaciones-entre-sucesos",
    "title": "1. Probabilidad",
    "section": "Operaciones entre sucesos",
    "text": "Operaciones entre sucesos\nLos eventos aleatorios son conjuntos matemáticos y, por lo tanto, admiten las mismas operaciones que suelen utilizarse para manipular conjuntos.\nSean \\(A\\) y \\(B\\) eventos definidos sobre un espacio muestral \\(S\\).\n\nSuceso unión (\\(A \\cup B\\)): elementos de \\(S\\) que pertenecen a \\(A\\), a \\(B\\) o a ambos.\nSuceso intersección (\\(A \\cap B\\)): elementos de \\(S\\) que pertenecen a \\(A\\) y a \\(B\\) simultáneamente.\nSuceso complemento (\\(\\overline{A}\\) ó \\(A^c\\)): elementos de \\(S\\) que no pertenecen a \\(A\\).\n\nSobre estas definiciones se desprende que \\(A\\) y \\(B\\) son sucesos mutuamente excluyentes si y sólo si \\(A \\cap B = \\emptyset\\) (conjunto vacío).\n\n\n\nFigura 3.1: Operaciones entre conjuntos, visualizadas mediante diagramas de Venn. (Arriba a la izquierda: unión; arriba a la derecha: intersección; abajo a la izquierda: complemento; abajo a la derecha: exclusividad mutua.)\n\n\nPensar en operaciones entre sucesos puede ser útil porque a veces un suceso complejo puede descomponerse en múltiples sucesos simples, los cuales se conectan mediante estas operaciones. Por ejemplo, supóngase el evento:\n\\(A\\): “elegir Chocolate y Menta, o bien Frutilla y Sambayón”.\nEste evento puede descomponerse como \\[A = (C \\cap M) \\cup (F \\cap S),\\] donde\n\n\\(C\\): elegir Chocolate.\n\\(M\\): elegir Menta.\n\\(F\\): elegir Frutilla.\n\\(S\\): elegir Sambayón.\n\n\nLeyes de De Morgan\nAl combinar complementos con intersecciones o uniones es importante tener en cuenta las siguientes reglas, atribuidas a Augustus De Morgan:\n\nEl complemento de una unión es igual a la intersección de los complementos. \\[\\overline{A \\cup B} = \\overline{A} \\cap \\overline{B}\\]\nEl complemento de una intersección es igual a la unión de los complementos. \\[\\overline{A \\cap B} = \\overline{A} \\cup \\overline{B}\\]\n\nEstas reglas aplican no sólo entre dos eventos, sino para un número arbitrario de ellos."
  },
  {
    "objectID": "1_prob.html#definiciones-de-probabilidad",
    "href": "1_prob.html#definiciones-de-probabilidad",
    "title": "1. Probabilidad",
    "section": "Definiciones de probabilidad",
    "text": "Definiciones de probabilidad\n\nDefinición clásica (a priori)\nEsta definición establece que la probabilidad de que, al realizar un experimento, se obtenga un cierto resultado, es igual al cociente entre el número de casos favorables al resultado y el número total de casos posibles.\n\\[\\frac{\\#\\text{casos favorables}}{\\#\\text{casos posibles}}\\]\n¿A qué nos referimos con casos favorables y casos posibles? Supongamos un evento aleatorio sobre el que se define un espacio muestral \\(S\\), y sea \\(A\\) un evento de interés para el cual queremos calcular su probabilidad de ocurrencia. Usaremos las siguientes definiciones:\n\nCasos favorables: todos los elementos pertenecientes al conjunto \\(A\\).\nCasos posibles: todos los elementos pertenecientes al conjunto \\(S\\).\n\nSiendo \\(A\\) un subconjunto de \\(S\\), resulta evidente que todo caso favorable es, a su vez, posible.\nBajo esta definición, entonces, podemos calcular la probabilidad de \\(A\\), simbolizada \\(P(A)\\), como: \\[P(A) = \\dfrac{\\#A}{\\#S},\\] o sea, el tamaño del conjunto \\(A\\) dividido por el tamaño del espacio muestral.\nEsta definición es la razón por la que estudiamos herramientas de conteo: calcular una probabilidad implica conocer el tamaño de los conjuntos \\(A\\) y \\(S\\), lo cual a su vez requiere una metodología para contar sus respectivos elementos.\nHabiendo definido todos estos conceptos, finalmente nos encontramos en condiciones de resolver el ejemplo introductorio.\n\n\nEjemplo 1\n\nUna heladería ofrece 8 sabores distintos. Si enviamos a un amigo a comprar un pote de 1kg (el cual contiene 4 sabores distintos), ¿cuál es la probabilidad de que uno de los sabores elegidos sea limón?\nSolución: Definimos, en primer lugar, todas las nociones que componen el marco del ejercicio.\n\nExperimento aleatorio: elegir 4 sabores de helado entre 8 posibles.\nEspacio muestral: \\(S\\) = {todos los subconjuntos posibles de 4 sabores distintos}.\nEjemplo de resultado: \\(s\\) = {Sambayón, Chocolate, Limón, Menta}.\nCasos posibles: \\(\\#S = _8C_4 = 70\\).\nEvento de interés: \\(A\\): elegir Limón.\nCasos favorables: \\(\\#A = _7C_3 = 35\\).\n\nPor lo tanto, el resultado final es \\[P(A) = \\dfrac{\\#A}{\\#S} = \\dfrac{35}{70} = \\dfrac{1}{2} = 0,5 = 50\\%\\]\n\nLas probabilidades no son siempre intuitivas. ¿Hubieran esperado que el resultado fuese un número tan alto?\nLa definición clásica de probabilidad, lamentablemente, sólo aplica a experimentos con un número finito de resultados posibles y donde todos ellos son equiprobables.2 Cuando un experimento no cumple con estas condiciones es necesario recurrir a otra definición de probabilidad.\n\n\nDefinición frecuencial (a posteriori)\nLa regularidad estadística de la que gozan los experimentos aleatorios permite definir a la probabilidad de un suceso como el límite, cuando el número de repeticiones del experimento tiende a infinito, de la frecuencia relativa del suceso.\nSupongamos que repetimos el mismo experimento un total de \\(n\\) veces. Sea \\(I_n(A)\\) una variable que cuenta el número de veces que el resultado del experimento cumplió con lo establecido en el evento \\(A\\). La definición frecuencial establece que, aumentando arbitrariamente el número de repeticiones, la probabilidad resulta igual a:\n\\[P(A) = \\lim_{n \\to \\infty} \\frac{I_n(A)}{n}\\]\nEsta definición es puramente teórica, en el sentido de que en la práctica nunca pueden hacerse infinitas repeticiones de un experimento: deberá bastarnos con hacer un número suficientemente grande de repeticiones y tomar el resultado final como una aproximación del verdadero resultado.\nAfortunadamente, no siempre es necesario hacer una verdadera repetición del experimento. Para ciertos experimentos existen teoremas y propiedades matemáticas que permiten deducir la frecuencia relativa exacta de un suceso, sin necesidad de llevar a cabo siquiera una ejecución real del experimento. En otras ocasiones, el experimento puede ser realizado mediante simulaciones computacionales, lo cual permite repetirlos muchas veces en poco tiempo."
  },
  {
    "objectID": "1_prob.html#algunos-ejemplos",
    "href": "1_prob.html#algunos-ejemplos",
    "title": "1. Probabilidad",
    "section": "Algunos ejemplos",
    "text": "Algunos ejemplos\n\n\nEjemplo 2\n\nSe arroja un dado y se observa la cara superior. ¿Cuál es la probabilidad de obtener un número mayor a 4? ¿Cuál es la probabilidad de obtener un número mayor a 6?\nSolución:\n\nExperimento aleatorio: arrojar un dado y observar la cara superior.\nEspacio muestral: \\(S\\) = {1, 2, 3, 4, 5, 6}.\nEjemplo de resultado: \\(s\\) = 3.\nCasos posibles: \\(\\#S = 6\\).\nEvento de interés:\n\n\\(A\\): obtener un número mayor a 4.\n\\(B\\): obtener un número mayor a 6.\n\nCasos favorables:\n\n\\(A = \\{5, 6\\} \\implies \\#A = 2\\).\n\\(B = \\emptyset \\implies \\#B = 0\\).\n\n\nPor lo tanto, los resultados son \\[P(A) = \\dfrac{\\#A}{\\#S} = \\dfrac{2}{6} = \\dfrac{1}{3} = 0,\\overline{3} = 33,\\overline{3}\\%\\] \\[P(B) = \\dfrac{\\#B}{\\#S} = \\dfrac{0}{6} = 0 = 0\\%\\]\n\n\n\nEjemplo 3\n\nLos organizadores de un seminario de tres días de duración están considerando qué almuerzo servir en cada uno de los días: pescado o carne. ¿Cuál es la probabilidad de que no sirvan el mismo almuerzo dos días consecutivos?\nSolución:\n\nExperimento aleatorio: elegir tres menúes de almuerzos, siendo pescado y carne las opciones para cada día.\nEspacio muestral: \\(S\\) = {todas las ternas posibles a partir de los elementos “Pescado” y “Carne”}.\nEjemplo de resultado: \\(s\\) = (Carne, Carne, Pescado).\nCasos posibles: \\(\\#S = _2P'_3 = 2^3 = 8\\).\nEvento de interés: \\(A\\): no servir el mismo almuerzo dos días consecutivos.\nCasos favorables: \\(A\\) = {(Carne, Pescado, Carne), (Pescado, Carne, Pescado)} \\(\\implies \\#A = 2\\).\n\nPor lo tanto, el resultado final es \\[P(A) = \\dfrac{\\#A}{\\#S} = \\dfrac{2}{8} = \\dfrac{1}{4} = 0,25 = 25\\%\\]"
  },
  {
    "objectID": "1_prob.html#axiomas-de-probabilidad",
    "href": "1_prob.html#axiomas-de-probabilidad",
    "title": "1. Probabilidad",
    "section": "Axiomas de probabilidad",
    "text": "Axiomas de probabilidad\nSea un experimento aleatorio sobre el que se define un espacio muestral \\(S\\). La probabilidad de un evento \\(A\\) cumple con los siguientes axiomas:\n\n\\(P(A) \\geq 0\\) para todo suceso \\(A\\).\n\\(P(S) = 1\\).\n\\(A\\) y \\(B\\) son m.e. \\(\\implies P(A \\cup B) = P(A) + P(B)\\).\n\nA partir de los axiomas de probabilidad se desprenden las siguientes propiedades:\n\n\\(P(\\overline{A}) = 1 - P(A)\\) para todo suceso \\(A\\).\n\\(P(\\emptyset) = 0\\).\n\\(P(A) \\leq 1\\).\n\\(B \\subseteq A \\implies P(B) \\leq P(A)\\).\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)."
  },
  {
    "objectID": "1_prob.html#probabilidad-condicional",
    "href": "1_prob.html#probabilidad-condicional",
    "title": "1. Probabilidad",
    "section": "Probabilidad condicional",
    "text": "Probabilidad condicional\nSupongamos que tenemos un mazo de cartas francesas (las de póker), el cual tiene 52 cartas. Lo mezclamos, lo apoyamos en la mesa boca abajo y tomamos las dos cartas superiores, de a una a la vez. ¿Cuál es la probabilidad de que la segunda carta seleccionada sea un as?\nEs posible que su respuesta sea “depende”, visto que la probabilidad para la segunda carta depende de cuál fue la primera carta seleccionada. Esta apreciación es en parte correcta y en parte errónea: ciertamente debemos considerar lo que ocurrió con la primera carta, pero, como veremos más adelante, podemos obtener una probabilidad para la segunda carta sin saber el resultado de la primera.\nSupongamos un experimento aleatorio sobre el que se definen dos eventos \\(A\\) y \\(B\\). Más aún, sea \\(A\\) un evento tal que \\(P(A) \\neq 0\\). Se define la probabilidad condicional de \\(B\\) dado \\(A\\) como \\[P(B|A) = \\dfrac{P(B \\cap A)}{P(A)}.\\]\nComo muestra la ecuación, calcular la probabilidad del evento \\(B\\) condicionada a la ocurrencia del evento \\(A\\) equivale a calcular la probabilidad de \\(B\\) dentro del espacio muestral restringido por \\(A\\).\n\n\n\nFigura 3.2: Representación visual de la probabilidad condicional. En el diagrama, la probabilidad condicional \\(P(B|A)\\) tiene por numerador la parte de \\(B\\) que está contenida en \\(A\\), y por denominador la totalidad de \\(A\\).\n\n\nPongámoslo en práctica con un ejemplo simple:\n\n\nEjemplo 4\n\nSe arroja un dado y se observa la cara superior. Considérense los siguientes eventos:\n\n\\(A\\): obtener un 1.\n\\(B\\): obtener un número par.\n\\(C\\): obtener un número mayor a 3.\n\nCalcular las probabilidades: \\(P(B|C)\\), \\(P(C|B)\\) y \\(P(A|C)\\).\nSolución:\n\nExperimento aleatorio: arrojar un dado y observar la cara superior.\nEspacio muestral: \\(S\\) = {1, 2, 3, 4, 5, 6}.\nEjemplo de resultado: \\(s\\) = 3.\n\nLas probabilidades a calcular son:\n\n\\(P(B|C) = \\dfrac{P(B \\cap C)}{P(C)} = \\dfrac{\\frac{\\#(B \\cap C)}{\\#S}}{\\frac{\\#C}{\\#S}} = \\dfrac{\\#(B \\cap C)}{\\#C}\\)\n\\(P(C|B) = \\dfrac{P(B \\cap C)}{P(B)} = \\dfrac{\\frac{\\#(B \\cap C)}{\\#S}}{\\frac{\\#B}{\\#S}} = \\dfrac{\\#(B \\cap C)}{\\#B}\\)\n\\(P(A|C) = \\dfrac{P(A \\cap C)}{P(C)} = \\dfrac{\\frac{\\#(A \\cap C)}{\\#S}}{\\frac{\\#C}{\\#S}} = \\dfrac{\\#(A \\cap C)}{\\#C}\\)\n\nPor lo tanto:\n\nCasos posibles: \\(\\#S =6\\).\nCasos de interés:\n\n\\(B = \\{2,4,6\\} \\implies \\#B = 3\\).\n\\(C = \\{4,5,6\\} \\implies \\#C = 3\\).\n\\(B \\cap C = \\{4,6\\} \\implies \\#(B \\cap C) = 2\\).\n\\(A \\cap C = \\emptyset \\implies \\#(A \\cap C) = 0\\).\n\n\nFinalmente:\n\n\\(P(B|C) = \\frac{2/6}{3/6} = \\frac{2}{3} = 0,\\overline{6} = 66,\\overline{6}\\%\\)\n\\(P(C|B) = \\frac{2/6}{3/6} = \\frac{2}{3} = 0,\\overline{6} = 66,\\overline{6}\\%\\)\n\\(P(A|C) = \\frac{0/6}{3/6} = \\frac{0}{3} = 0 = 0\\%\\)\n\n\nEs importante notar que las probabilidades condicionales también verifican los axiomas de probabilidad y las propiedades que de ellas se desprenden. Algunas que pueden resultar útiles son:\n\n\\(P(\\overline{B}|A) = 1 - P(B|A)\\)\n\\(P(A\\cup B|C) = P(A|C) + P(B|C) - P(A \\cap B|C)\\)\n\n\nTeorema de la multiplicación\nEs una regla para el cálculo de probabilidades que se desprende directamente de la definición de probabilidad condicional.\nSiendo \\(A\\) y \\(B\\) dos sucesos definidos sobre un experimento aleatorio, se tiene: \\[P(A \\cap B) = P(A|B) \\cdot P(B) = P(B|A) \\cdot P(A)\\]\n\n\nEjemplo 5\n\nSe tiene un frasco lleno de canicas. No se sabe con exactitud cuántas tiene, pero se sabe que el 23% de ellas son verdes, mientras que las demás son blancas. Además, se sabe que el 15% de las canicas verdes brilla en la oscuridad. Si se extrae una canica al azar, ¿cuál es la probabilidad de que sea verde y brille en la oscuridad?\nSolución:\n\nExperimento aleatorio: extraer al azar una canica del frasco.\nEspacio muestral: \\(S\\) = {cada canica del frasco}.\nEjemplo de resultado: \\(s = v^*\\) (canica verde que brilla).\nEventos de interés:\n\n\\(V\\): se extrae una canica verde.\n\\(B\\): se extrae una canica que brilla.\n\n\nAsí: \\[P(V \\cap B) = P(B|V) \\cdot P(V) = 0,15 \\cdot 0,23 = 0,0345 = 3,45\\%\\]\n\n\n\nIndependencia\nSiendo \\(A\\) y \\(B\\) dos eventos aleatorios, se dice que éstos son eventos independientes si y sólo si \\[P(A \\cap B) = P(A) \\cdot P(B)\\]\nPor un lado, nótese que esta ecuación es simétrica respecto a \\(A\\) y \\(B\\); es decir, si \\(A\\) es independiente de \\(B\\), etnonces \\(B\\) es a su vez independiente de \\(A\\). Por otro lado, nótese que la ecuación anterior resulta en \\[A \\text{ y } B \\text{ independientes} \\iff P(A|B) = P(A)  \\;\\wedge\\; P(B|A) = P(B).\\]\n\n\n\n\n\n\nAdvertencia\n\n\n\nLa independencia no puede representarse gráficamente mediante un diagrama de Venn.\n\n\n\n\nTeorema de Bayes\nSean dos eventos \\(A\\) y \\(B\\) tales que \\(P(A) \\neq 0\\). Luego: \\[P(B|A) = \\dfrac{P(A|B) \\cdot P(B)}{P(A)}\\]\nEste teorema nos provee una forma alternativa de calcular probabilidades condicionales.\n\n\nEjemplo 6\n\nEl 2% de la población mundial está contagiada con una nueva enfermedad, y existen pruebas para su diagnóstico, con una sensibilidad de 98% y una especificidad del 95%. Una persona sospecha estar enferma y, al hacerse el test, obtiene un resultado positivo. ¿Cuál es la probabilidad de que esté realmente enferma?\nSolución:\n\nExperimento aleatorio: seleccionar una persona, la cual puede estar o no enferma, y realizarle el test, el cual puede dar un resultado positivo o negativo.\nEspacio muestral: \\(S = \\{(\\overline{E}, -),\\; (\\overline{E}, +),\\; (E, -),\\; (E, +)\\}\\).\nEjemplo de resultado: \\(s = (E, -)\\).\nEventos de interés:\n\n\\(E\\): la persona está enferma.\n\\(+\\): la persona tiene un resultado positivo del test.\n\\(- (= +^c)\\): la persona tiene un resultado negativo del test.\n\n\nSegún el enunciado:\n\n\\(P(E) = 2\\% = 0,02\\)\n\\(P(+|E) = 98\\% = 0,98\\)\n\\(P(-|\\overline{E}) = 95\\% = 0,95\\)\n\nPor lo tanto, aplicando el teorema de Bayes: \\[P(E|+) = \\dfrac{P(+|E) \\; P(E)}{P(+)} = \\dfrac{P(+|E) \\; P(E)}{P(+|E)\\;P(E) + P(+|\\overline{E})\\;P(\\overline{E})}\\]\nLo cual resulta en: \\[P(E|+) = \\dfrac{0,98 \\times 0,02}{0,98 \\times 0,02 + 0,05 \\times 0,98} = \\dfrac{2}{7} \\approx 0,2857 = 28,57\\%\\]\n\nComo aclaración, el ejemplo anterior hace uso de un artificio matemático que a simple vista puede resultar extraño. Nótese como, luego de aplicar el teorema de Bayes, el denominador se expresa de una forma alternativa. Generalizando para dos eventos \\(A\\) y \\(B\\), la igualdad empleada es \\[P(A) = P(A|B) \\; P(B) + P(A|\\overline{B}) \\; P(\\overline{B}).\\]\n¿De dónde sale esto? En primer lugar, considérese la siguiente sucesión de igualdades.\n\\[A \\underset{(1)}{=} A \\cap S \\underset{(2)}{=} A \\cap (B \\cup \\overline{B}) \\underset{(3)}{=} (A \\cap B) \\cup (A \\cap \\overline{B})\\]\n\nLa intersección de cualquier evento con el espacio muestral es igual al evento original.\nLa unión de cualquier evento con su complemento equivale al espacio muestral.\nPropiedad distributiva de conjuntos.\n\nLuego, los eventos \\(A \\cap B\\) y \\(A \\cap \\overline{B}\\) son mutuamente excluyentes, visto que uno está contenido en \\(B\\) y el otro en \\(\\overline{B}\\). Por lo tanto, aplicando el tercer axioma de probabilidad, se tiene que \\[P(A) = P[(A \\cap B) \\cup (A \\cap \\overline{B})] = P(A \\cap B) + P(A \\cap \\overline{B}).\\]\nFinalmente, por el teorema de la multiplicación, los sumandos anteriores pueden redefinirse como: \\[P(A) = P(A \\cap B) + P(A \\cap \\overline{B}) = P(A|B) \\; P(B) + P(A|\\overline{B}) \\; P(\\overline{B}).\\]"
  },
  {
    "objectID": "1_prob.html#un-caso-real-el-caso-sally-clark",
    "href": "1_prob.html#un-caso-real-el-caso-sally-clark",
    "title": "1. Probabilidad",
    "section": "Un caso real: el caso Sally Clark",
    "text": "Un caso real: el caso Sally Clark\nEl 23 de febrero de 1998 Sally Clark, una mujer inglesa de 33 años, fue arrestada bajo la sospecha de haber asesinado a sus dos hijos. (Wikipedia 2024)\nSu primer hijo había nacido en 1996 y fallecido tres meses más tarde bajo un diagnóstico de muerte súbita infantil. Para una familia promedio la probabilidad de este fenómeno es de 1 en 8543, lo cual es inusual pero no lo suficientemente llamativo como para levantar sospechas. Lo que alertó a las autoridades fue cuando, tras ocho semanas de nacer, el segundo hijo de la familia Clark también falleció por muerte súbita infantil.\nSally Clark fue llevada a juicio, donde el fiscal argumentó que, si la probabilidad de que un hijo fallezca por muerte súbita infantil es de 1 en 8543, entonces la probabilidad de que dos hijos sufran ese fenómeno es de 1 en 73 millones (porque \\(8543 \\times 8543 = 72.982.849\\)). Estos números fueron suficientes para convencer al jurado de que el diagnóstico de muerte súbita infantil era muy poco probable. Sally Clark perdió el juicio y fue condenada a prisión.\nEn octubre de 2001, dos meses luego del juicio, la Royal Statistical Society emitió un comunicado público alegando un mal uso de la estadística en el juicio. El cálculo empleado por el fiscal asumía que dos muertes súbitas infantiles dentro de una misma familia serían eventos independientes, cuando en realidad esto difícilmente sea cierto: dado un primer hijo fallecido por muerte súbita infantil, es posible que exista en la familia alguna predisposición genética hacia dicha condición, y por lo tanto no sería raro que un segundo hijo también la padeciera.\nDesde entonces, este caso ha sido citado innumerables veces como ejemplo de los peligros que surgen de no comprender adecuadamente cómo funcionan las probabilidades.\n\n\n\n\nWikipedia. 2024. «Sally Clark - Wikipedia, The Free Encyclopedia». https://en.wikipedia.org/wiki/Sally_Clark."
  },
  {
    "objectID": "1_prob.html#footnotes",
    "href": "1_prob.html#footnotes",
    "title": "1. Probabilidad",
    "section": "",
    "text": "En matemáticas, existen dos formas de definir un conjunto: por extensión y por comprensión. La primera implica listar uno por uno los elementos del conjunto; por ejemplo: {2, 4, 6, 8}. La segunda implica usar palabras para definir el contenido; por ejemplo: {los números pares entre 1 y 9}.↩︎\nExperimentos de este estilo se denominan “laplacianos”, en honor a Pierre-Simon Laplace.↩︎"
  },
  {
    "objectID": "2_va.html#introducción",
    "href": "2_va.html#introducción",
    "title": "2. Variable aleatoria",
    "section": "Introducción",
    "text": "Introducción\nUn basquetbolista tiene una tasa de encestos del 60%. Esto implica que en un tiro al aro tiene un 60% de probabilidad de encestar y un 40% de fallar. ¿Cuál es la probabilidad de que deba lanzar dos veces para eventualmente encestar? Suponiendo que los tiros son independientes entre sí, la probabilidad de fallar el primer tiro y acertar el segundo es \\(0,4 \\times 0,6 = 0,24\\). ¿Cuál es la probabilidad de que deba lanzar tres veces para finalmente encestar? Siguiendo la misma lógica obtenemos \\(0,4 \\times 0,4 \\times 0,6 = 0,096\\).\nPodríamos seguir este procedimiento infinitamente: para cualquier número natural \\(n\\) es posible calcular la probabilidad de que el basquetbolista falle los primeros \\(n-1\\) tiros y finalmente enceste el último. De hecho, definiendo la variable\n\\[X: \\text{ número de tiros que realiza el basquetbolista hasta encestar}\\]\nes fácil ver que la probabilidad de encestar en el \\(n\\)-ésimo tiro está dada por\n\\[P(X = n) = (0,4)^{n-1} \\times 0,6 \\qquad \\forall \\quad n \\in \\mathbb{N}.\\]\nEsta ecuación comprime de forma eficiente la información necesaria para calcular la chance de ocurrencia de cualquier resultado posible. De no tenerla, tendríamos que definir un evento para cada resultado.\n\n\\(A\\): el basquetbolista encesta al primer tiro \\(\\implies A = \\{(Si)\\}\\)\n\\(B\\): el basquetbolista encesta al segundo tiro \\(\\implies B = \\{(No, Si)\\}\\)\n\\(C\\): el basquetbolista encesta al tercer tiro \\(\\implies C = \\{(No, No, Si)\\}\\)\n\n\\(\\cdots\\)\nEs por ello que surgen las variables aleatorias."
  },
  {
    "objectID": "2_va.html#variable-aleatoria",
    "href": "2_va.html#variable-aleatoria",
    "title": "2. Variable aleatoria",
    "section": "Variable aleatoria",
    "text": "Variable aleatoria\nSupóngase un experimento aleatorio sobre el que se define un espacio muestral \\(S\\). Se llama variable aleatoria a la función \\(X\\) que asigna a cada uno de los elementos \\(s \\in S\\) un número real \\(X(s)\\).\nEn el ejemplo introductorio, el experimento aleatorio es “lanzar al aro hasta encestar” y el espacio muestral es \\(S=\\){(Sí), (No, Sí), (No, No, Sí), \\(\\cdots\\)}. Bajo la definición ya dada para la variable aleatoria \\(X\\), esta función no hace más que contar el número de tiros en cada resultado:\n\\[s = (Si) \\implies X(s) = 1\\] \\[s = (No, Si) \\implies X(s) = 2\\] \\[s = (No, No, Si) \\implies X(s) = 3\\]\n\n\n\n\n\n\nNota\n\n\n\nEn el ejemplo introductorio se define \\(X\\) como el “número de tiros hasta encestar”. Nótese la diferencia entre una variable aleatoria y un evento aleatorio. El evento suele escribirse como una afirmación, valiéndose de un verbo (por ejemplo, “el dado arrojado resulta en un número par”). Como tal, un evento sólo admite dos resultados posibles: ocurrir o no ocurrir. En cambio, una variable es un atributo, el cual puede tomar múltiples valores.\n\n\n\n\n\n\n\n\nNota\n\n\n\nOtra convención de la que hacemos uso es la distinción entre letras mayúsculas y minúsculas. Nótese cómo hemos usado la letra \\(S\\) para referirnos al espacio muestral y la letra \\(s\\) para referirnos a un elemento particular perteneciente a tal conjunto. Del mismo modo, reservaremos letras mayúsculas como \\(X\\) para definir variables aleatorias y letras minúsculas como \\(x\\) para referirnos a valores puntuales que éstas podrían asumir.\n\n\nComo a cada elemento del espacio muestral le corresponde un número real, es sensato preguntarse cuáles son todos los posibles números reales que podrían obtenerse en un cierto experimento. Dicho de otro modo, podríamos preguntarnos cuáles son todos los valores que puede tomar la variable \\(X\\). Este conjunto se conoce como recorrido de \\(X\\) y se simboliza con \\(R_X\\).\n\\[R_X = \\{x \\in \\mathbb{R} : X(s) = x \\;;\\; s \\in S\\}\\]\nPor ejemplo, para un experimento con sólo tres resultados posibles se tiene \\(S=\\{s_1, s_2 ,s_3\\}\\) y por lo tanto \\(R_X = \\{X(s_1), X(s_2), X(s_3)\\}\\). En el ejemplo del basquetbolista se tiene que \\(R_X = \\mathbb{N}\\), o sea que el número de tiros hasta encestar puede ser cualquier número natural. Algo interesante de este último caso es que el conjunto tiene infinitos elementos. En general, \\(R_X\\) puede ser un conjunto:\n\nfinito.\ninfinito numerable.1\ninfinito no numerable.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEl tamaño de \\(S\\) no siempre es igual al tamaño de \\(R_X\\). Tómese como ejemplo el experimento de arrojar dos monedas al aire en simultáneo. El espacio muestral tiene cuatro elementos, porque \\(S=\\{(C,C), (C,X), (X,C), (X,X)\\}\\), pero si definimos una variable aletoria \\(X\\) que cuenta el número de cruces, se tiene que \\(R_X = \\{0, 1, 2\\}\\). Esto es porque se tienen dos resultados del espacio muestral que bajo la función \\(X\\) devuelven el mismo número real."
  },
  {
    "objectID": "2_va.html#tipos-de-variable-aleatoria",
    "href": "2_va.html#tipos-de-variable-aleatoria",
    "title": "2. Variable aleatoria",
    "section": "Tipos de variable aleatoria",
    "text": "Tipos de variable aleatoria\nSegún la cardinalidad del recorrido de \\(X\\) (es decir, según si \\(R_X\\) es un conjunto finito, infinito numerable o infinito no numerable), una variable aleatoria puede clasificarse en uno de dos tipos: discreta o continua.\n\nVariable aleatoria discreta\nSea \\(X\\) una v.a.2 definida sobre un espacio muestral \\(S\\). Se dice que \\(X\\) es una variable aleatoria discreta si su recorrido es un conjunto finito o infinito numerable.\nEjemplos de variables aleatorias discretas son los siguientes:\n\nDemanda de un cierto producto.\nNúmero de aces en un partido de tenis.\nCantidad de senadores que votan en contra de una ley.\nNúmero de ventas anuales en Amazon.\n\nSupongamos un recorrido \\(R_X = \\{x_1, x_2, x_3, \\cdots\\}\\) a lo sumo numerable. Para cada resultado posible \\(x_i\\) puede asociarse un número \\(p(x_i) = P(X = x_i)\\). Esta función es denominada función de probabilidad puntual de \\(X\\).\nLa función \\(p(x)\\) verifica dos propiedades importantes:\n\n\\(p(x) &gt; 0 \\quad \\forall \\quad x \\in R_X\\) (condición de positividad)\n\\(\\sum_{x \\in R_X} p(x) = 1\\) (condición de cierre)\n\n\n\nEjemplo 1\n\nSe arrojan 3 monedas equilibradas al aire y se registra para cada una si el resultado es cara o cruz. Sea \\(X\\) la variable que registra el número de cruces obtenidas. Definir su función de probabilidad.\nSolución:\n\nExperimento aleatorio: arrojar 3 monedas al aire y registrar la cara superior de cada una.\nEspacio muestral: \\(S = \\{CCC, CCX, CXC, CXX, XCC, XCX, XXC, XXX\\}\\).\nEjemplo de resultado: \\(s = CCX\\).\nVariable aleatoria: \\(X\\): número de cruces obtenidas.\nRecorrido: \\(R_X = \\{0, 1, 2, 3\\} \\implies \\#R_X = 4\\) (finito).\n\nLa función de probabilidad surge de las siguientes probabilidades:\n\n\\(p(0) = P(X = 0) = P(s \\in \\{CCC\\}) = \\frac{1}{8}\\)\n\\(p(1) = P(X = 1) = P(s \\in \\{CCX, CXC, XCC\\}) = \\frac{3}{8}\\)\n\\(p(2) = P(X = 2) = P(s \\in \\{XXC, XCX, CXX\\}) = \\frac{3}{8}\\)\n\\(p(3) = P(X = 3) = P(s \\in \\{XXX\\}) = \\frac{1}{8}\\)\n\nNótese que se verifican tanto la condición de positividad como la de cierre:\n\nPositividad: \\(\\frac{3}{8} &gt; \\frac{1}{8} &gt; 0\\) (todos los resultados son positivos)\nCierre: \\(\\frac{1}{8} + \\frac{3}{8} + \\frac{3}{8} + \\frac{1}{8} = \\frac{8}{8} = 1\\)\n\n\nAl conjunto de pares \\((x, p(x))\\) se lo llama distribución de probabilidad de la v.a. \\(X\\), denotada como \\(X \\sim p(x)\\)3. Para una v.a. discreta existen tres formas de representar su distribución de probabilidad: como tabla, como gráfico o como fórmula.\n\n\n\nFigura 4.1: Las tres formas de representar la distribución de probabilidad de una variable aleatoria discreta.\n\n\n\n\nVariable aleatoria continua\nSea \\(X\\) una v.a. definida sobre un espacio muestral \\(S\\). Se dice que \\(X\\) es una variable aleatoria continua si su recorrido es un conjunto infinito no numerable.\nEjemplos de variables aleatorias continuas son los siguientes:\n\nProducto Bruto Interno.\nDuración del vuelo AR1300 (EZE-JFK), en minutos.\nValor del dólar en relación al precio argentino.\n\n\n\n\n\n\n\nNota\n\n\n\nAnte una variable aleatoria continua ya no podemos hablar de \\(x_i\\), visto que no existe un \\(i\\)-ésimo valor de la variable.\n\n\nPara toda v.a. continua \\(X\\) se tiene que \\(P(X=x) = 0\\). Es decir que las probabilidades puntuales son todas nulas. Esta característica puede ser difícil de asimilar, puesto que va en contra de la intuición: ¿cómo puede ser que un valor posible tenga una probabilidad nula de ocurrir? La explicación formal involucra matemáticas cuya complejidad exceden los contenidos de este curso; es suficiente con decir que, bajo un escenario donde los resultados posibles tienen infinitos decimales, es improbable que se obtenga exactamente un cierto número previsto de antemano.\n\n\n\n\n\n\nAdvertencia\n\n\n\nLa noción de un “número con infinitos decimales” pareciera no aplicar a varios ejemplos de la vida cotidiana. Por ejemplo: si pesamos una sandía en una balanza, obtendremos a lo sumo tres (como mucho cuatro) decimales. Sin embargo, esta es una limitación impuesta por el instrumento de medición, no por la variable en sí misma. Si tuviéramos una balanza más precisa podríamos medir aún más decimales.\nEste concepto también aplica cuando la limitación en los decimales es generada no por el instrumento de medición sino por el uso habitual o la relevancia. Por ejemplo: cuando alguien nos pregunta por nuestra altura es común que respondamos algo como “un metro setenta y dos”, es decir, usando dos decimales. Incluso si nos midiésemos con una cinta métrica que tuviera más decimales, nuestra respuesta seguiría limitándose a dos.\nEste redondeo por conveniencia aplica también a variables con decimales que cotidianamente redondeamos a números enteros. El ejemplo más claro es la edad. Tal número suele redondearse a “años cumplidos” y por lo tanto se la cuenta mediante números enteros, pero en realidad con cada segundo (incluso nanosegundo) que pasa nuestra edad va cambiando.\n\n\n¿Cómo podemos, entonces, medir probabilidades de ocurrencia sobre una variable en la cual cada valor puntual tiene probabilidad nula? En estos casos suele ser de interés la probabilidad de que la variable tome un valor dentro de un cierto intervalo. Así, se estudia la probabilidad de que \\(X\\) tome un valor en un entorno de \\(x\\), lo cual se logra con una función particular.\nSe denomina función de densidad de probabilidad de \\(X\\) a aquella función \\(f(x)\\) que verifica:\n\n\\(f(x)&gt;0 \\quad \\forall \\quad x \\in R_X\\) (condición de positividad)\n\\(\\int_{R_X} f(x) \\; dx = 1\\) (condición de cierre)\n\nEs muy importante recordar que la función \\(f(x)\\) no devuelve la probabilidad de ocurrencia del valor \\(X=x\\). Como ya se dijo, dicha probabilidad sería nula. Más aún, la función \\(f(x)\\) en ocasiones puede tomar valores mayores a 1, lo cual pone en evidencia que no mide probabilidades. Esta función es un mero intermediario para calcular una probabilidad, y para ello debe ser envuelta en una integral, como se muestra en el siguiente ejemplo.\n\n\nEjemplo 2\n\nUna empresa láctea vende sachets de yogur de un litro. La máquina que llena los envases no funciona a la perfección, por lo que el verdadero contenido de yogur puede variar entre envases. Se sabe que la variable “litros de yogur en un sachet” (llamémosla \\(X\\)) se distribuye siguiendo la función de densidad a continuación: \\[f(x) = K(4x - x^2) \\qquad \\forall \\quad 0&lt;x&lt;2\\] ¿Cuál es el valor del número real \\(K\\)?\nSolución:\n\nExperimento aleatorio: usar la máquina para llenar un sachet de yogur.\nVariable aleatoria: \\(X\\): litros de yogur en un sachet.\nRecorrido: \\(R_X = [0, 2] \\subset \\mathbb{R}\\) (infinito no numerable).\n\nPor condición de cierre: \\[\\int_0^2 K(4x-2x^2) \\; dx = K(2x^2 - \\tfrac{2}{3}x^3) |_0^2 = K(8 - \\tfrac{16}{3}) = \\tfrac{8}{3} \\implies K = \\tfrac{3}{8}\\]"
  },
  {
    "objectID": "2_va.html#función-de-distribución",
    "href": "2_va.html#función-de-distribución",
    "title": "2. Variable aleatoria",
    "section": "Función de distribución",
    "text": "Función de distribución\nSea \\(X\\) una v.a. cualquiera (discreta o continua), llamamos función de distribución acumulada de \\(X\\) a la función: \\[F(x) = P(X \\leq x) \\quad \\forall \\quad x \\in \\mathbb{R}.\\] Es decir, esta función calcula la probabilidad de que \\(X\\) tome el valor \\(x\\) o cualquier valor menor a éste. De ahí la palabra “acumulada”. En esta definición no importa si se consideran valores menores a \\(x\\) que no son posibles bajo nuestra variable aleatoria, visto que esos casos tienen probabilidad nula (o densidad nula, en variables continuas).\n\n\n\n\n\n\nNota\n\n\n\nPara una v.a. continua, al verificarse que \\(P(X=x)=0\\), se tiene que \\(F(x) = P(X \\leq x) = P(X &lt; x)\\). Esto no se cumple para variables aleatorias discretas.\n\n\nLa definición dada puede particularizarse para cada tipo de variable aleatoria:\n\nDiscreta: \\(F(x) = \\sum_{x_i \\leq x} p(x_i)\\)\nContinua: \\(F(x) = \\int_{-\\infty}^x f(t) \\; dt\\)\n\n\n\n\nFigura 4.2: Representaciones gráficas de funciones de distribución para una variable discreta (izquierda) y una continua (derecha).\n\n\nLa función de distribución acumulada goza de tres propiedades:\n\nEs monótona no decreciente: \\(x_1 &lt; x_2 \\implies F(x_1) \\leq F(x_2)\\)\nEstá acotada entre 0 y 1: \\(\\lim_{x \\to -\\infty} F(x) = 0\\) y \\(\\lim_{x \\to +\\infty} F(x) = 1\\)\nEs continua por derecha: \\(\\lim_{x \\to x_0^+} F(x) = F(x_0)\\)\n\nLa función de distribución es particularmente útil en variables continuas, porque, si se la conoce, es posible calcular la probabilidad de que \\(X\\) caiga dentro de un cierto intervalo sin necesidad de resolver una integral. Esto es porque: \\[P(a &lt; X \\leq b) = P(X \\leq b) - P(X \\leq a) = F(b) - F(a)\\]"
  },
  {
    "objectID": "2_va.html#esperanza-y-variancia",
    "href": "2_va.html#esperanza-y-variancia",
    "title": "2. Variable aleatoria",
    "section": "Esperanza y variancia",
    "text": "Esperanza y variancia\nHasta ahora hemos visto que una variable aleatoria puede definirse mediante una función de probabilidad (o densidad) o, equivalentemente, una función de distribución. Si bien esto nos da información suficiente para calcular la probabilidad de ocurrencia de cualquier evento, existen métricas que en forma sencilla reflejan características importantes sobre la variable en cuestión.\nDichas métricas son llamadas Esperanza y Variancia, simbolizadas \\(E(X)\\) y \\(V(X)\\) respectivamente. La primera nos dice alrededor de qué valor tienden a situarse los resultados posibles de la variable. La segunda indica cuán propensa es la variable a alejarse de dicho valor central, como una suerte de medida de “estabilidad” o “aleatoriedad” de la variable.\n\nEsperanza\nDefiniremos la esperanza por separado para cada tipo de variable aleatoria.\nCaso discreto: Sea \\(X\\) una v.a. discreta con función de probabilidad \\(p(x)\\), se define la esperanza (o valor esperado) de \\(X\\) como: \\[E(X) = \\sum_{x_i \\in R_X} x_i \\cdot p(x_i)\\]\nCaso continuo: Sea \\(X\\) una v.a. continua con función de densidad \\(f(x)\\), se define la esperanza de \\(X\\) como: \\[E(X) = \\int_{R_X} x \\cdot f(x) \\; dx\\]\nSe hacen las siguientes observaciones sobre la esperanza:\n\nLa esperanza puede no existir. La condición para su existencia es la convergencia de la serie (en el caso discreto) o de la integral impropia (en el caso continuo).\nSi \\(R_X\\) es finito, la esperanza de \\(X\\) se obtiene como una suma finita y por lo tanto existe .\nLa esperanza representa el “centro de gravedad” de la distribución de probabilidad.\nLa esperanza es un parámetro; no debe confundirse con el concepto de promedio o media aritmética.\n\n\n\nVariancia\nNuevamente, se establece una definición para cada tipo de variable aleatoria.\nCaso discreto: Sea \\(X\\) una v.a. discreta con función de probabilidad \\(p(x)\\), se define la variancia de \\(X\\) como: \\[V(X) = \\sum_{x_i \\in R_X} [x_i - E(X)]^2 \\cdot p(x_i)\\]\nCaso continuo: Sea \\(X\\) una v.a. continua con función de densidad \\(f(x)\\), se define la variancia de \\(X\\) como: \\[V(X) = \\int_{R_X} [x-E(X)]^2 \\cdot f(x) \\; dx\\]\nLa definición de \\(V(X)\\) es equivalente a una expresión más sencilla de calcular, que frecuentemente se utiliza en la práctica para simplificar los cálculos: la fórmula de trabajo de \\(V(X)\\). \\[V(X) = E(X^2) - [E(X)]^2 = E(X^2) - E^2(X)\\]\n\n\nEjemplo 3\n\nCalcular la Esperanza y Variancia para la variable aleatoria definida en el Ejemplo 1.\nSolución: se tiene la siguiente función de probabilidad para la variable \\(X\\).\n\n\n\n\n\n\\(x\\)\n\\(p(x)\\)\n\n\n\n\n0\n1/8\n\n\n1\n3/8\n\n\n2\n3/8\n\n\n3\n1/8\n\n\n\n\n\nPor lo tanto:\n\\[E(X) = 0 \\times \\tfrac{1}{8} + 1 \\times \\tfrac{3}{8} + 2 \\times \\tfrac{3}{8} + 3 \\times \\tfrac{1}{8} = \\tfrac{3}{8} + \\tfrac{6}{8} + \\tfrac{3}{8} = \\tfrac{12}{8} = 1,5\\]\nLuego:\n\\[E(X^2) = 0^2 \\times \\tfrac{1}{8} + 1^2 \\times \\tfrac{3}{8} + 2^2 \\times \\tfrac{3}{8} + 3^2 \\times \\tfrac{1}{8} = \\tfrac{3}{8} + \\tfrac{12}{8} + \\tfrac{9}{8} = \\tfrac{24}{8} = 3\\]\nFinalmente:\n\\[V(X) = E(X^2) - E^2(X) = 3 - (1,5)^2 = 3 - 2,25 = 0,75\\]\n\n\n\nPropiedades de E(X) y V(X)\nSe cumplen las siguientes propiedades para la Esperanza y Variancia de una variable aleatoria.\nEsperanza:\n\n\\(X=c\\) con prob. 1 \\(\\implies E(X) = c\\)\n\\(E(X+a) = E(X) + a\\)\n\\(E(c \\cdot X) = c \\cdot E(X)\\)\n\\(E(c \\cdot X + a) = c \\cdot E(X) + a\\)\n\nVariancia:\n\n\\(X=c\\) con prob. 1 \\(\\implies V(X) = 0\\)\n\\(V(X+a) = V(X)\\)\n\\(V(c \\cdot X) = c^2 \\cdot V(X)\\)\n\\(V(c \\cdot X + a) = c^2 \\cdot V(X)\\)"
  },
  {
    "objectID": "2_va.html#distribuciones-de-probabilidad",
    "href": "2_va.html#distribuciones-de-probabilidad",
    "title": "2. Variable aleatoria",
    "section": "Distribuciones de probabilidad",
    "text": "Distribuciones de probabilidad\nEn la práctica, existen variables aleatorias que se utilizan con frecuencia y que, por lo tanto, tienen una distribución conocida. Esto nos ahorra tiempo y esfuerzo porque no tenemos que calcular cosas como su función de probabilidad (o densidad), su función de distribución, su esperanza o su variancia. Más aún, calcular probabilidades bajo estas distribuciones conocidas se vuelve relativamente sencillo porque programas informáticos como R ya tienen incluidos funciones que lo hacen por nosotros.\nExisten muchísimas distribuciones de probabilidad.4 En este curso nos limitaremos a estudiar seis: tres para variables discretas y tres para variables continuas.\n\nDistribuciones discretas\n\nDistribución Binomial\nSea un experimento en el que sólo existen dos resultados posibles (los llamaremos “éxito” y “fracaso”) y donde la probabilidad de éxito es igual a \\(p\\).\nConsidérense \\(n\\) repeticiones independientes del experimento, y sea \\(X\\) una v.a. que mide el número de éxitos a través de las \\(n\\) repeticiones. Entonces \\(X\\) tiene distribución Binomial de parámetros \\(p\\) y \\(n\\), donde: \\[p(x) = _nC_x \\cdot p^x \\cdot (1-p)^{n-x} \\quad ;\\; x=0,1,\\cdots,n\\]\n\n\n\n\n\n\nAdvertencia\n\n\n\nEstablecer los valores de los parámetros es fundamental para calcular probabilidades. Una vez hecho esto, la distribución de la variable está definida de forma unívoca. Al proceso de explicitar los parámetros se lo llama parametrización.\nLa Binomial (y, en líneas generales, cualquier distribución de probabilidad) no es una sola distribución sino una familia de distribuciones. Para centrarse en una distribución particular es necesario definir familia + parámetros. Por lo tanto, si en un examen se da como ejemplo un experimento aleatorio y se pide “definir la variable aleatoria correspondiente”, es necesario especificar la variable aleatoria y sus respectivos parámetros.\n\n\nEmpleando la fórmula de esperanza y variancia sobre esta función de probabilidad, se obtiene que: \\[E(X) = n \\cdot p \\qquad V(X) = n \\cdot p \\cdot (1-p)\\]\n\n\nEjemplo 4\n\nUn examen multiple choice consta de diez preguntas, cada una de ellas con 4 respuestas posibles. Si un alumno elige una opción al azar en cada pregunta ¿cuál es la probabilidad de acertar en exactamente 7 preguntas?\nSolución: Considerando que el experimento es “adivinar la respuesta a una pregunta”, se tiene que la probabilidad de éxito es \\(p=0,25\\) (porque hay 4 respuestas posibles, de las cuales sólo una es correcta) y hay en total \\(n=10\\) repeticiones del experimento. Considerando estos valores para los parámetros, se tiene que:\n\\[p(7) = _{10}C_7 \\cdot 0,25^7 \\cdot 0,75^3 = 120 \\cdot \\tfrac{1}{16384} \\cdot \\tfrac{27}{64} = \\tfrac{405}{131072} \\approx 0,00309 = 0,309\\%\\]\nPropuesto: ¿cuál es la probabilidad de aprobar (al menos 6 correctas)?\n\n\n\nDistribución Poisson\nAl igual que la Binomial, existe otra distribución que cuenta el número de éxitos, o bien, el número de incidencias de un cierto evento. La diferencia radica en que esta nueva variable se usa en casos donde no se puede identificar una “unidad mínima” en la que sólo puede darse el éxito o el fracaso. Supóngase, por ejemplo, una variable aleatoria que cuenta el número de llamadas que ingresan a una central telefónica en el plazo de una hora. No existe una unidad de tiempo en la que sólo pueda entrar una llamada (o ninguna). En un segundo pueden entrar muchas llamadas. En una décima de segundo también. Lo mejor que podemos hacer en estos casos es definir un número esperado de incidencias dentro del plazo de tiempo considerado (en el ejemplo es una hora) y compararlo con el número de incidencias observadas al realizar el experimento.\n\n\n\n\n\n\nNota\n\n\n\nA pesar del ejemplo dado, no es necesario que las incidencias se midan a través del tiempo. También podrían medirse, por ejemplo, en el espacio. Supóngase una variable aleatoria que cuenta el número de colonias de bacterias en una placa de Petri. Nuevamente, existe una unidad de espacio limitada (la superficie de la placa de Petri) pero dentro de ella es imposible determinar cuál es la unidad mínima en la que puede presentarse sólo una colonia (o ninguna).\n\n\nSea \\(X\\) una v.a. discreta con \\(R_X = \\mathbb{N}_0\\). Decimos que \\(X\\) tiene una distribución Poisson5 si su función de probabilidad es: \\[p(x) = \\frac{e^{-\\lambda}\\lambda^x}{x!} \\quad ;\\; x \\in \\mathbb{N}_0\\]\nEl parámetro \\(\\lambda\\) representa el número medio de éxitos esperados por unidad de tiempo (o espacio).\nPara esta variable aleatoria se tiene que \\(E(X) = V(X) = \\lambda\\).\n\n\nEjemplo 5\n\nEl número de errores de imprenta en una página de un determinado libro es, en promedio, un error por página. ¿Cuál es la probabilidad de observar más de un error en una página seleccionada al azar?\nSolución: Como el promedio es de un error por página se tiene que \\(\\lambda = 1\\). Luego:\n\\[P(X&gt;1) = 1 - [p(0) + p(1)] = 1 - [\\frac{e^{-1}1^0}{0!} + \\frac{e^{-1}1^1}{1!}] = 1 - 2e^{-1} \\approx 0,264 = 26,4\\%\\]\n\n\n\nDistribución Hipergeométrica\nSea una población finita de \\(N\\) elementos, de los cuales \\(N_1\\) tienen una determinada característica (éxito) y los \\(N-N_1\\) restantes no lo tienen (fracaso).\nLa v.a. \\(X\\) que cuenta el número de éxitos en una muestra de \\(n\\) unidades seleccionadas sin reposición tiene distribución hipergeométrica de parámetros \\(N\\), \\(N_1\\) y \\(n\\):\n\\[p(x) = \\frac{_{N_1}C_x \\;\\cdot\\; _{N-N_1}C_{n-x}}{_NC_n} \\quad;\\quad x = \\max\\{0, n+N_1-N\\}, \\cdots, \\min\\{n, N_1\\}\\]\nPara esta variable aleatoria se tiene: \\[E(X) = N_1\\frac{n}{N} \\qquad V(X) = N_1\\frac{n}{N} \\left(\\frac{N-N_1}{N}\\right) \\left(\\frac{N-n}{N-1}\\right)\\]\n\n\nEjemplo 6\n\nSe reparten 5 cartas al azar (y sin reemplazo) de una baraja de 52 cartas de póker. ¿Cuál es la probabilidad de que la mano no contenga ases?\nSolución: Considerando el as como un éxito, se tiene que \\(N=52\\), \\(N_1=4\\) y \\(n=5\\). Luego:\n\\[P(X=0) = p(0) = \\frac{_4C_0 \\;\\cdot\\; _{48}C_5}{_{52}C_5} = \\frac{1 \\cdot 1.712.304}{2.598.960} \\approx 0,6584 = 65,84\\%\\]\n\n\n\n\nDistribuciones continuas\n\nDistribución Uniforme\nSea \\(X\\) una v.a. continua con recorrido acotado \\(R_X=[a;b]\\). Se dice que \\(X\\) tiene distribución uniforme de parámetros \\(a\\) y \\(b\\) si su función de densidad está dada por: \\[f(x) = \\frac{1}{b-a} \\quad ;\\; a \\leq x \\leq b\\]\n\n\n\n\n\n\nNota\n\n\n\nNótese que la función de densidad no depende del valor de \\(x\\): es constante. Esto refleja que todos los intervalos de igual amplitud son igualmente probables a lo largo de todo el recorrido de \\(X\\).\n\n\nA partir de la función de densidad se deduce: \\[F(x) = \\int_a^x \\frac{1}{b-a} = \\frac{x-a}{b-a} \\qquad E(X) = \\frac{a+b}{2} \\qquad V(X) = \\frac{(b-a)^2}{12}\\]\n\n\nEjemplo 7\n\nAl estudiar bajas cotizaciones para contratos de embarques, una empresa fabricante de computadoras encuentra que los contratos interestatales tienen bajas cotizaciones uniformemente distribuidas entre 20 y 25 (en miles de dólares). ¿Cuál es la probabilidad de que la baja cotización en el siguiente contrato interestatal esté por debajo de los $22.000?\nSolución: Se tiene que \\(a = 20\\) y \\(b = 25\\). Luego:\n\\[P(X&lt;22) = P(X\\leq 22) = F(22) = \\frac{22-20}{25-20} = \\frac{2}{5} = 0,4 = 40\\%\\]\n\n\n\nDistribución Exponencial\nSea \\(X\\) una v.a. continua con \\(R_X = \\mathbb{R}_0^+\\) (es decir, los reales positivos incluyendo el cero). Se dice que \\(X\\) tiene distribución exponencial si su función de densidad es: \\[f(x) = \\lambda e^{-\\lambda x} \\quad ;\\; x \\in \\mathbb{R}_0^+\\].\nDe la función de densidad se deduce: \\[F(x) = 1 - e^{-\\lambda x} \\qquad E(X) = \\frac{1}{\\lambda} \\qquad V(X) = \\frac{1}{\\lambda^2}\\]\nEsta distribución es ampliamente utilizada en aplicaciones industriales, puesto que modela adecuadamente las variables del tipo “tiempo hasta la ocurrencia de un evento”.\n\n\nEjemplo 8\n\nLa magnitud de temblores registrados en una región de Norteamérica (medidos en escala de Richter) sigue una distribución exponencial con parámetro \\(\\lambda = \\tfrac{5}{12}\\). ¿Cuál es la probabilidad de que un temblor en esa región supere los 3 puntos en la escala de Richter?\nSolución:\n\\[P(X&gt;3) = 1-P(X\\leq 3) = 1- F(3) = 1 - [1 - e^{-\\frac{5}{12}\\cdot 3}] = e^{-\\frac{15}{12}} \\approx 0,2865 = 28,65\\%\\]\n\n\n\nDistribución Normal\nSea \\(X\\) una v.a. continua con \\(R_X = \\mathbb{R}\\) (todos los reales). Se dice que \\(X\\) sigue una distribución Normal si su función de densidad viene dada por \\[f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2} \\quad ;\\; x \\in \\mathbb{R}\\]\nLos parámetros \\(\\mu\\) y \\(\\sigma\\) representan la media y el desvío estándar de la distribución, respectivamente. De hecho, se verifica que \\(E(X) = \\mu\\) y \\(V(X) = \\sigma^2\\).\nLa función de densidad normal presenta una particularidad: no puede integrarse. Por lo tanto no existe una expresión analítica (exacta) para \\(F(x)\\). Es por ello que solemos utilizar osftware estadístico para realizar cálculos sobre esta distribución. En R contamos con dos funciones de gran utilidad: pnorm y qnorm.\n\nLa función pnorm(q, mean = 0, sd = 1) calcula \\(F(q) = P(X \\leq q)\\) para \\(X \\sim N(mean, sd)\\).\nLa función qnorm(p, mean = 0, sd = 1) calcula el valor que acumula un \\(100p\\%\\) de probabilidad en una distribución \\(N(mean, sd)\\).\n\n\n\nEjemplo 9\n\nLa cantidad semanal de dinero gastado por una compañía en mantenimiento y reparaciones está normalmente distribuida con una media de $400 y un desvío estándar de $20. Si están presupuestados $450 para la semana próxima, ¿cuál es la probabilidad de que los costos reales superen dicha cifra?\nSolución: Se tiene que \\(\\mu = 400\\) y \\(\\sigma = 20\\). Se quiere calcular \\(P(X &gt; 450) = 1 - F(450)\\). Así:\n1 - pnorm(450, mean = 400, sd = 20) = 0,0062 = 0,62%"
  },
  {
    "objectID": "2_va.html#footnotes",
    "href": "2_va.html#footnotes",
    "title": "2. Variable aleatoria",
    "section": "",
    "text": "Algunos conjuntos infinitos permiten enumerar todos sus elementos, como sucede por ejemplo para el caso de los números naturales: \\(\\mathbb{N} = \\{1, 2, 3, \\cdots\\}\\). Estos son ejemplos de infinitos numerables. Existen otros conjuntos infinitos, sin embargo, que no permiten tal enumeración. Un claro ejemplo son los números reales (\\(\\mathbb{R}\\)). ¿Cuál es el primer número real? Incluso si comenzáramos en uno arbitrario (por ejemplo, 0) ¿cuál sería el siguiente? No existe una forma satisfactoria de enumerar los números reales, y por eso se los denomina “no numerables”.↩︎\nPor comodidad, en ocasiones adoptamos esta forma de abreviar “variable aleatoria”.↩︎\nSe lee “\\(X\\) se distribuye como una \\(p(x)\\)”.↩︎\nhttps://en.wikipedia.org/wiki/List_of_probability_distributions↩︎\nSe pronuncia “Puasón”.↩︎"
  },
  {
    "objectID": "3_infer.html#introducción",
    "href": "3_infer.html#introducción",
    "title": "3. Inferencia estadística",
    "section": "Introducción",
    "text": "Introducción\nLas decisiones que tomamos en nuestra vida cotidiana se basan en información parcial. Nunca contamos con la verdad completa. Es por eso que salimos de casa con nuestro paraguas sin saber con certeza si vamos a usarlo. O compramos cuatro empanadas aunque quizás sólo comamos tres. O compramos entradas para el Lollapalooza antes de que salga el lineup.1\nLo importante es que incluso en ese contexto de incertidumbre podemos vivir plenamente, sin preocuparnos por tener la información total. Pero eso es sólo porque podemos sacarle provecho a la información parcial de la que sí disponemos. Tómsese como ejemplo la siguiente imagen, de la cual sólo conocemos el 10% de sus píxeles, estando el 90% restante en blanco. ¿Qué logran identificar? ¿De qué se trata la imagen?\n\n\n\nFigura 5.1: Uff, ni idea.\n\n\nEs muy difícil identificar algo. Como ya dijimos, tiene un 90% de “ruido”. Pero cuidado: no es el alto porcentaje de ruido lo que trae problemas, sino el hecho de que el 10% de información está muy disperso. Si concentrásemos ese 10% en la región adecuada de la imagen, tendríamos mucha más claridad sobre el asunto.\n\n\n\nFigura 5.2: Ah, ahora sí. Jamás me hubiese dado cuenta.\n\n\nEsa es la meta de la inferencia estadística: sacarle tanto jugo como sea posible a la información parcial de la que disponemos, con el fin de recrear fielmente la “información total” que nos gustaría tener, para que nuestra toma de decisiones sea lo mejor posible."
  },
  {
    "objectID": "3_infer.html#terminología",
    "href": "3_infer.html#terminología",
    "title": "3. Inferencia estadística",
    "section": "Terminología",
    "text": "Terminología\n\nUna población es un conjunto de individuos o elementos, en un tiempo y espacio definidos, sobre los cuales nos interesaría conocer una caraterística.\nUna muestra es un subconjunto de esa población, al cual tenemos acceso para obtener “información parcial”.\nUna unidad es un elemento del (sub)conjunto: una persona, una institución, un vehículo, etcétera.\nLa variable en estudio (si bien podría haber más de una) es la característica de interés que se mide a cada unidad, y se utiliza en el cálculo de los valores poblacionales de interés.\n\nLa estadística inferencial es la rama de la Estadística que, a partir de la información empírica proporcionada por una muestra, intenta predecir el comportamiento de una población.\nDicha descripción estará siempre sujeta a un riesgo de cometer un cierto error por estar trabajando con los datos de una muestra y no de toda la población. Este error será medible o establecido en términos de probabilidades.\n\nUn parámetro es un valor que describe o resume una característica de interés acerca de una población. Los parámetros son valores que nos interesan pero que desconocemos.\nUn estadístico, en cambio, es una función de variables aleatorias, la cual no depende de valores desconocidos (parámetros).\nUn estimador es un estadístico utilizado para representar un parámetro de interés en una población.\n\n\n\n\n\n\n\nNota\n\n\n\nTodos los estimadores son estadísticos, pero no todos los estadísticos son estimadores. Sólo aquellos estadísticos que utilicemos para “representar” a nivel muestral el valor de un parámetro poblacional serán llamados estimadores."
  },
  {
    "objectID": "3_infer.html#estimación-puntual",
    "href": "3_infer.html#estimación-puntual",
    "title": "3. Inferencia estadística",
    "section": "Estimación puntual",
    "text": "Estimación puntual\nSean \\(X_1, X_2, \\cdots, X_n\\) variables aleatorias de una población \\(X\\) cuya función de distribución conjunta es \\[g(x_1, x_2, \\cdots, x_n) = f(x_1) \\times f(x_2) \\times \\cdots \\times f(x_n) = \\prod_{i=1}^n f(x_i)\\] donde cada \\(f(x_i)\\) representa la función de densidad asociada a la variable \\(X_i\\), entonces decimos que \\(X_1, X_2, \\cdots, X_n\\) es una muestra aleatoria de tamaño \\(n\\) de la población con densidad \\(f(x)\\). Una muestra aleatoria de tamaño \\(n\\) tiene variables aleatorias independientes e igualmente distribuidas (iid).\nUna muestra aleatoria es siempre extraída de una población \\(X\\), la cual viene representada por una función de densidad \\(f(x, \\theta)\\) donde \\(\\theta\\) es un parámetro desconocido. Lo que nos interesa es estimar ese parámetro \\(\\theta\\).\nUn estimador puntual \\(\\hat{\\theta}\\) es una función de \\(X_1, X_2, \\cdots, X_n\\) que estima al parámetro \\(\\theta\\).\nDicho de otro modo, un estadístico es calculado a partir de información muestral para estimar un parámetro poblacional de interés.\n\n\n\n\n\n\nNota\n\n\n\nUn estimador es aleatorio: puede tomar distintos valores dependiendo de cuáles elementos de la población sean seleccionados para formar parte de la muestra. Por lo tanto, puede definirse una distribución de probabilidad que defina la probabilidad de que el estimador tome cada uno de sus posibles valores.\nEn otras palabras, un estimador es una variable aleatoria.\n\n\nAlgunos de los estimadores más populares son:\n\nMedia muestral: \\(\\overline{X} = \\frac{1}{n} \\sum_{i=1}^n x_i\\)\nVariancia muestral: \\(S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\overline{X})^2\\)\nProporción muestral: \\(\\hat{p} = \\frac{1}{n} \\sum_{i=1}^n z_i\\) (siendo \\(z\\) una variable binaria)"
  },
  {
    "objectID": "3_infer.html#propiedades-de-estimadores",
    "href": "3_infer.html#propiedades-de-estimadores",
    "title": "3. Inferencia estadística",
    "section": "Propiedades de estimadores",
    "text": "Propiedades de estimadores\nSupóngase que ya tenemos una población de interés y un parámetro cuyo valor quisiéramos conocer: por ejemplo, la media. Teniendo una muestra, existen muchas formas de estimar la media poblacional. ¿Cuál de todos los posibles estimadores es mejor? Para compararlos entre ellos existen propiedades estadísticas de las que podemos valernos.\n\nInsesgamiento\nSea \\(X_1, X_2, \\cdots, X_n\\) una muestra aleatoria de tamaño \\(n\\) de una población \\(X\\), cuya distribución viene dada por \\(f(x,\\theta)\\), con \\(\\theta\\) un parámetro desconocido. Decimos que \\(\\hat{\\theta}\\) es un estimador insesgado de \\(\\theta\\) si \\[E(\\hat{\\theta}) = \\theta\\] para todos los posibles valores de \\(\\theta\\). En caso contrario, decimos que \\(\\hat{\\theta}\\) es un estimador sesgado de \\(\\theta\\).\nEl sesgo de un estimador puede calcularse como \\[b(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta\\] de modo que:\n\n\\(b(\\hat{\\theta}) &gt; 0 \\implies \\hat{\\theta}\\) sobreestima al parámetro \\(\\theta\\).\n\\(b(\\hat{\\theta}) &lt; 0 \\implies \\hat{\\theta}\\) subestima al parámetro \\(\\theta\\).\n\\(b(\\hat{\\theta}) = 0 \\implies \\hat{\\theta}\\) es insesgado del parámetro \\(\\theta\\).\n\n\n\nEjemplo 1\n\nSea \\(X\\) una v.a. con distribución exponencial. Demuestre que la media muestral es un estimador insesgado de la media poblacional \\(\\frac{1}{\\lambda}\\).\nSolución: Si \\(X \\sim \\text{exp}\\), luego \\(f(x) = \\lambda e^{-\\lambda x}\\) y \\(E(X) = \\frac{1}{\\lambda}\\). Si obtenemos una muestra aleatoria de tamaño \\(n\\) a partir de la población y definimos \\(\\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\\), luego:\n\\[E(\\overline{X}) = E \\left( \\frac{1}{n} \\sum_{i=1}^n X_i \\right) \\stackrel{(1)}{=} \\frac{1}{n} \\sum_{i=1}^n E(X_i) \\stackrel{(2)}{=} \\frac{1}{n} \\sum_{i=1}^n \\frac{1}{\\lambda} = \\frac{1}{n} \\cdot n \\cdot \\frac{1}{\\lambda} = \\frac{1}{\\lambda}\\] donde (1) se cumple por propiedad de esperanza (de una combinación lineal) y (2) se cumple por ser una muestra aleatoria.\n\n\n\nConsistencia\nSe dice que un estimador \\(\\hat{\\theta}\\) es consistente de \\(\\theta\\) si su distribución se concentra alrededor de valores cercanos al verdadero valor del parámetro \\(\\theta\\), a medida que \\(n\\) crece.\nEn otras palabras, la probabilidad de que \\(\\hat{\\theta}\\) esté “lejos” del valor de \\(\\theta\\) tiende a 0 cuando el tamaño de la muestra aumenta.\nExiste una condición suficiente para probar si un estimador es consistente. \\[b(\\hat{\\theta}) \\stackrel{n\\rightarrow\\infty}{\\longrightarrow} 0 \\text{ y } V(\\hat{\\theta}) \\stackrel{n\\rightarrow\\infty}{\\longrightarrow} 0 \\implies \\hat{\\theta} \\text{ es consistente de } \\theta\\]\n\n\nEjemplo 2\n\nSea \\(X\\) una v.a. con distribución exponencial. Demuestre que la media muestral es un estimador consistente.\nSolución: En primer lugar, ya se probó en el ejemplo anterior que el estimador “media muestral” es insesgado de \\(\\frac{1}{\\lambda}\\), es decir, su sesgo es nulo: \\(b(\\overline{X}) = 0\\). En consecuencia, esto también significa que el sesgo tiende a cero cuando la muestra aumenta. Para evaluar la segunda condición:\n\\[V(\\overline{X}) = V \\left( \\frac{1}{n} \\sum_{i=1}^n X_i \\right) \\stackrel{(1)}{=} \\frac{1}{n^2} \\sum_{i=1}^n V(X_i) \\stackrel{(2)}{=} \\frac{1}{n^2} \\sum_{i=1}^n \\frac{1}{\\lambda^2} =\\] \\[= \\frac{1}{n^2} \\cdot n \\cdot \\frac{1}{\\lambda^2} = \\frac{1}{n \\cdot \\lambda^2} \\stackrel{n \\to \\infty}{\\longrightarrow} 0\\] donde (1) se cumple por propiedad de variancia (de una combinación lineal) y (2) se cumple por ser una muestra aleatoria.\n\n\n\nEficiencia\nDecimos que un estimador puntual insesgado \\(\\hat{\\theta}\\) es un estimador eficiente del parámetro \\(\\theta\\) si tiene la menor variancia entre todos los posibles estimadores insesgados del parámetro.\n\n\n\n\n\n\nNota\n\n\n\nA diferencia del insesgamiento y la consistencia, la eficiencia es una propiedad relativa: no es algo que pueda definirse sobre cada estimador individualmente, sino que surge de compararlos entre ellos.\n\n\n\n\nEjemplo 3\n\nSea \\(X_1, X_2, X_3\\) una muestra aleatoria de tamaño \\(n=3\\) proveniente de una población con distribución \\(N(\\mu \\,;\\, \\sigma^2)\\), con \\(\\mu\\) y \\(\\sigma^2\\) desconocidos. Se proponen dos estimadores (insesgados) de \\(\\mu\\):\n\\[\\hat{\\mu}_1 = \\frac{1}{4} X_1 + \\frac{1}{2} X_2 + \\frac{1}{4} X_3\\] \\[\\hat{\\mu}_2 = \\frac{1}{3} X_1 + \\frac{1}{3} X_2 + \\frac{1}{3} X_3\\] ¿Cuál de ellos es más eficiente?\nSolución: Calculando las variancias de cada uno:\n\\[V(\\hat{\\mu}_1) = \\frac{1}{4^2} V(X_1) + \\frac{1}{2^2} V(X_2) + \\frac{1}{4^2} V(X_3) = \\sigma^2 \\left( \\frac{1}{16} + \\frac{1}{4} + \\frac{1}{16} \\right) = \\frac{3 \\sigma^2}{8}\\] \\[V(\\hat{\\mu}_2) = \\frac{1}{3^2} V(X_1) + \\frac{1}{3^2} V(X_2) + \\frac{1}{3^2} V(X_3) = \\frac{3}{3^2} \\sigma^2 = \\frac{3 \\sigma^2}{9}\\] En conclusión, \\(\\hat{\\mu}_2\\) es más eficiente que \\(\\hat{\\mu}_1\\).\n\nEn resumen, la propiedad de insesgamiento hace referencia al centro o posición central de la distribución muestral de nuestro estimador, mientras que las propiedades de consistencia y eficiencia refieren a su variabilidad.\n\n\n\nFigura 5.3: Relación entre sesgo y variancia."
  },
  {
    "objectID": "3_infer.html#distribuciones-muestrales",
    "href": "3_infer.html#distribuciones-muestrales",
    "title": "3. Inferencia estadística",
    "section": "Distribuciones muestrales",
    "text": "Distribuciones muestrales\nComo ya se discutió, los estadísticos son variables aleatorias: bajo una segunda muestra es probable que cambie su valor, respecto a la muestra original. Por lo tanto, al igual que como hicimos con variables aleatorias en la unidad anterior, podemos usar la distribución de probabilidad de estos estadísticos para calcular la probabilidad de que tomen ciertos valores.\n\nDistribución de la media muestral (caso Normal)\nSea \\(X_1, X_2, \\cdots, X_n\\) una muestra aleatoria de tamaño \\(n\\) extraída de una población \\(N(\\mu \\,;\\, \\sigma^2)\\). Sabemos que \\(E(\\overline{X}) = \\mu\\) y \\(V(\\overline{X}) = \\frac{\\sigma^2}{n}\\). Entonces, la distribución de la media muestral es: \\[\\overline{X} \\sim N \\left( \\mu \\,;\\, \\frac{\\sigma^2}{n} \\right)\\]\nEs decir, la media muestral, cuando la muestra aleatoria proviene de una población Normal, también tiene distribución Normal, con parámetros \\(\\mu\\) y \\(\\frac{\\sigma^2}{n}\\).\n\n\nEjemplo 4\n\nSegún el envase, el tubo de papas Pringles tiene un peso neto de 124 gramos. Un día nos agarra un antojo severo y compramos 5 tubos de papas. Pero cuando llegamos a nuestro hogar sentimos que los tubos son demasiado livianos. Desconfiados, pesamos cada uno en la balanza y nos da un peso promedio de 118 gramos. ¡Nos estafaron! ¿O no?\nLlamamos a la atención al cliente de Pringles para reclamar y nos dicen que los tubos nunca tienen exactamente 124 gramos, sino que una máquina los llena siguiendo una distribución Normal con una media de 124 gramos y un desvío estándar de 8 gramos.\nEn base a lo que pesan nuestras papas, ¿cuál es la probabilidad de que la información brindada por la atención al cliente sea verdadera?\nSolución: Lo primordial es definir qué se entiende por “probabilidad de información verdadera”. Recordemos que, al estar ante una v.a. continua, no podemos simplemente calcular \\(P(\\overline{X} = 118)\\) porque dicha probabilidad es nula. Pero claramente debemos usar el 118 en algún lado. ¿Cómo?\nSea \\(\\overline{X}\\) la variable “peso promedio de los tubos de papas en la muestra”. Bajo una presunción de que la información brindada por atención al cliente es correcta, tendríamos que \\(X \\sim N(\\mu = 124 \\,\\;\\, \\sigma = 8)\\). A su vez, nuestra sospecha es que, de no ser cierta la información provista, el veradero peso promedio será menor a 124 gramos (es decir, la empresa intentará sacar ventaja). Por lo tanto, podríamos preguntarnos: si suponemos que la información provista es cierta, ¿cuál sería la probabilidad de que el peso promedio sea lo que se observó o uno aún más incriminante? Entiéndase que, en este contexto, “más incriminante” implica un menor peso, porque eso reflejaría que es más probable que la información sea falsa.\nEn términos matemáticos: \\[P(\\text{Info cierta}) = P(\\overline{X} \\leq 118 \\;|\\; X \\sim N(\\mu = 124 \\,;\\, \\sigma = 8))\\]\nLuego: \\[X \\sim N(\\mu = 124 \\,;\\, \\sigma = 8) \\implies \\overline{X} \\sim N(\\mu = 124 \\,;\\, \\sigma = \\tfrac{8}{\\sqrt{5}})\\]\nEn conclusión, queremos calcular \\(P(\\overline{X} \\leq 118 \\;|\\; \\overline{X} \\sim N(\\mu = 124 \\,;\\, \\sigma = \\tfrac{8}{\\sqrt{5}}))\\).\nEn el software estadístico R podemos calcular esta probabilidad mediante:\npnorm(118, mean = 124, sd = 8/sqrt(5)) = 0.04676626 \\(\\approx\\) 4,67%\n\n\n\nDistribución de la media muestral (caso no Normal)\nSupóngase ahora que la muestra aleatoria \\(X_1, X_2, \\cdots, X_n\\) es extraída de una población cuya distribución se desconoce: podría ser Normal como también podría no serlo. En este caso no tenemos una expresión “conocida” para la esperanza y variancia de la media muestral porque no conocemos la distribución de la variable \\(X\\). Sin embargo, existe un teorema que nos solucionará este problema.\n\n\n\n\n\n\nTeorema Central del Límite\n\n\n\nSea una población \\(X\\) con media \\(\\mu\\) y variancia \\(\\sigma^2\\). Sea \\(\\overline{X}\\) la media muestral bajo una muestra aleatoria de tamaño \\(n\\), extraída de dicha población.\nLuego, la distribución de \\(\\overline{X}\\) se aprocima a una distribución Normal a medida que aumenta el tamaño muestral \\(n\\):\n\\[\\overline{X} \\stackrel{n \\to \\infty}{\\sim} N \\left( \\mu \\,;\\, \\frac{\\sigma^2}{n} \\right)\\] Este teorema es uno de los resultados fundamentales de la Estadística. Nos dice que, si una muestra es lo suficientemente grande (\\(n&gt;30\\)), entonces la media muestral, sin importar la variable original \\(X\\) (podría ser continua o incluso discreta), seguirá aproximadamente una distribución Normal.\nEl TCL es la razón por la cual la distribución Normal es tan popular.\n\n\nVolviendo al caso no Normal, se tiene entonces una muestra \\(X_1, X_2, \\cdots, X_n\\) proveniente de una población no necesariamente Normal. El TCL asegura que, bajo una muestra lo suficientemente grande, la media muestral sigue la siguiente distribución aproximada.\n\\[\\overline{X} \\stackrel{TCL}{\\sim} N \\left( \\mu \\,;\\, \\frac{\\sigma^2}{n} \\right)\\]\nPara reiterar, aún cuando la distribución de la población no sea Normal, un tamaño muestral lo suficientemente grande garantiza que la distribución de la media muestral sea Normal.\n\n\nEjemplo 5\n\nLos sueldos en una cierta empresa multinacional conforman una variable con una alta asimetría: hay muchos empleados con sueldos relativamente bajos y unos pocos empleados (directores y gerentes) con sueldos muy elevados.\nSi bien el sueldo de cada empleado es confidencial, es de público conocimiento que el sueldo promedio ronda los $1.800.000, con un desvío estándar de $1.000.000.\nSi se obtuviera una muestra aleatoria de 100 empleados, ¿cuál sería la probabilidad de que el sueldo medio muestral sea superior a $2.000.000?\nSolución: Siendo \\(X\\) la v.a. que representa el sueldo de los empleados de la empresa (en millones de pesos), se sabe que \\(E(X) = \\mu = 1,8\\) y que \\(\\sqrt{V(X)} = \\sigma = 1\\). Sin embargo, no se conoce con exactitud la distribución de probabilidad de la variable. Más aún, difícilmente ésta sea Normal, dada la asimetría mencionada. De todos modos, por tener una muestra de gran tamaño, y por conocer la esperanza y variancia de la variable, el Teorema Central del Límite nos permite calcular la probabilidad deseada.\n\\[P(\\overline{X} &gt; 2) = 1 - P(\\overline{X} \\leq 2)\\]\nPor TCL: \\[\\overline{X} \\stackrel{n \\to \\infty}{\\sim} N \\left(\\mu = 1.8 \\,;\\, \\sigma = \\tfrac{1}{\\sqrt{100}} \\right)\\]\nPor lo tanto:\n1 - pnorm(2, mean = 1.8, sd = 1/sqrt(100)) = 0.02275013 \\(\\approx\\) 2,28%\n\n\n\nDistribución de la media muestral (caso \\(\\sigma^2\\) desconocido)\nLos casos anteriores asumen que se conocen los valores de los parámetros. Supóngase ahora que la muestra aleatoria \\(X_1, X_2, \\cdots, X_n\\) proviene de una población Normal, pero donde el valor del parámetro \\(\\sigma^2\\) es deconocido (como suele ocurrir en la práctica).\nEn este caso, la estadística \\(\\overline{X}\\) no tiene una distribución de probabilidad definida, pero sí podemos aplicarle una transformación para que la tenga.\n\\[T = \\frac{\\overline{X} - \\mu}{S / \\sqrt{n}} \\sim t_{n-1}\\]\nsiendo \\(S\\) el desvío estándar muestral y \\(t\\) la distribución t-Student.\n\n\n\n\n\n\nNota\n\n\n\nPara muestras grandes (\\(n&gt;30\\)) la distribución t-Student resulta casi idéntica a la distribución Normal, por lo que se pueden usar indistintamente. Este resultado, dado por el TCL, también aplica cuando \\(X\\) no es Normal.\nO sea, bajo una población con variancia desconocida, si ésta es Normal entonces siempre podemos hallar una distribución de probabilidad; pero si no lo es (o no lo sabemos) entonces sólo podemos trabajar con muestras grandes.\n\n\n\n\nEjemplo 6\n\nEl último álbum de Taylor Swift, el cual contiene 31 canciones, tiene una duración promedio por canción de 238 segundos, con un desvío estándar de 43 segundos.\nSi la verdadera duración promedio de todas sus canciones fuese de 250 segundos, ¿cuál sería la probabilidad de su álbum tuviera a lo sumo la duración promedio que se registró?\nSolución: lo vemos en clase. El resultado es 0,0654.\nPara pensar: ¿el último álbum cumpliría las condiciones de muestra aleatoria?\n\n\n\n\n\n\n\n\n\nDistribución de la diferencia de medias\nSupongamos ahora que tenemos dos muestras aleatorias extraídas de dos poblaciones \\(X_1\\) y \\(X_2\\) (no necesariamente Normales), de tamaños \\(n_1\\) y \\(n_2\\) respectivamente, e independientes entre sí.\nPor lo demostrado anteriormente, sabemos que si \\(n_1\\) y \\(n_2\\) son suficientemente grandes (mayores a 30), la media de cada muestra tiene distribución Normal. En consecuencia, la distribución de la diferencia de medias es:\n\\[\\overline{X}_1 - \\overline{X}_2 \\stackrel{TCL}{\\sim} N \\left( \\mu_1 - \\mu_2 \\,;\\, \\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2} \\right)\\]\nEn el caso en que las poblaciones de las que se extrae cada una de las muestras aleatorias sean Normales, la distribución de la diferencia de medias será Normal sin importar los tamaños muestrales.\n\n\nEjemplo 7\n\nEl tiempo (en segundos) que tardan atletas argentinos federados en completar la carrera de 100 metros es una variable que sigue una distribución Normal, con media 11.5 y desvío estándar 1. Por otro lado, el tiempo para un grupo de corredores rosarinos aficionados también se distribuye Normalmente, con media 13 y desvío estándar 2.\nSi se seleccionan al azar 3 personas de cada grupo, ¿cuál es la probabilidad de que el promedio de los aficionados sea menor que el de los atletas?\nSolución: Siendo \\(X_1\\) la población de atletas federados y \\(X_2\\) la población de corredores aficionados, se quiere calcular \\(P(\\overline{X}_1 &gt; \\overline{X}_2) = P(\\overline{X}_1 - \\overline{X}_2 &gt; 0) = 1 - P(\\overline{X}_1 - \\overline{X}_2 \\leq 0)\\).\nPara los datos proporcionados, \\(\\mu_1-\\mu_2 = -1.5\\) y \\(\\tfrac{\\sigma_1^2}{n_1} + \\tfrac{\\sigma_1^2}{n_1} = \\tfrac{5}{3}\\). Luego:\n1 - pnorm(0, mean = -1.5, sd = sqrt(5/3)) = 0.1226391 \\(\\approx\\) 12,26%\n\n\n\nDistribución de la proporción muestral\nSea \\(X_1, X_2, \\cdots, X_n\\) una muestra aleatoria extraída de una población \\(X\\) donde existen tan sólo dos resultados posibles: éxito y fracaso. Sabemos que una variable que mide el número de éxitos en la muestra aleatoria tiene distribución Binomial, con parámetros \\(n\\) y \\(p\\). Además sabemos que: \\[E(\\hat{p}) = p \\qquad\\qquad V(\\hat{p}) = \\frac{p(1-p)}{n}\\]\nEntonces, por TCL, la distribución de la proporción muestral será: \\[\\hat{p} \\stackrel{TCL}{\\sim} N \\left( p \\,;\\, \\frac{p(1-p)}{n} \\right)\\]\n\n\nEjemplo 8\n\nAproximadamente un cuarto de la población mundial con acceso a internet tiene una cuenta de Instagram. Si se extrae una muestra de 50 personas a partir de dicha población, ¿cuál es la probabilidad de que al menos 20 de ellas tengan una cuenta de Instagram?\nSolución: Sea \\(X\\) la variable “posesión de una cuenta de Instagram” (sólo puede tomar como valores “sí” o “no”). Luego, \\(p\\) es la verdadera proporción de éxitos (en este caso, \\(p = 0.25\\)). A su vez, \\(\\hat{p}\\) es la proporción muestral de éxitos. Se pretende calcular \\(P(\\hat{p} &gt; 0.4) = 1 - P(\\hat{p} \\leq 0.4)\\). Como la muestra extraída es grande, por TCL sabemos que \\[\\hat{p} \\stackrel{TCL}{\\sim} N \\left( 0.25 \\,;\\, \\frac{0.25 \\times 0.75}{50} \\right)\\]\nPor lo tanto:\n1 - pnorm(0.4, mean = 0.25, sd = sqrt(0.25*0.75/50)) = 0.007152939 \\(\\approx\\) 0,72%"
  },
  {
    "objectID": "3_infer.html#footnotes",
    "href": "3_infer.html#footnotes",
    "title": "3. Inferencia estadística",
    "section": "",
    "text": "No se los recomendamos.↩︎"
  },
  {
    "objectID": "4_tdh.html#introducción",
    "href": "4_tdh.html#introducción",
    "title": "4. ICs y Tests de hipótesis",
    "section": "Introducción",
    "text": "Introducción\nUn día a principios de la década de 1920, Ronald Fisher, un reconocido estadístico, se encontró en una situación peculiar: le preparó una taza de té a una compañera de trabajo y ella la rechazó por haber servido la leche antes que el té. Fisher argumentó que el orden en el que se servían los líquidos no tenía importancia, pero ella estaba fuertemente en desacuerdo: de hecho, se jactaba de poder probar una taza de té y decir si se había servido primero la leche o el té.\nMotivado por la curiosa situación y por su formación profesional, Fisher se propuso diseñar un experimento para poner a prueba la supuesta habilidad de su compañera. Preparó ocho tazas de té: cuatro donde se había servido primero la leche y cuatro donde se había servido primero el té. En orden aleatorio, le hizo probar las tazas a su compañera, una por una, mientras ella señalaba para cada una su predicción. Cuando el experimento terminó, la mujer había podido etiquetar las ocho tazas correctamente. (Wikipedia 2024)\nFisher estaba sorprendido, pero aún había un pensamiento del que no podía desprenderse: existía la posibilidad de que la mujer estuviese adivinando cómo fue preparada cada taza, con la inesperada fortuna de haber acertado en todos los casos. ¿Cuál era la probabilidad de dicho caso? Aplicando la distribución hipergeométrica, puede demostrarse que dicha probabilidad es 1,4%. En otras palabras, era poco probable que la mujer estuviese adivinando: la evidencia muestral sugería que realmente podía percibir sabores distintos entre las preparaciones.\nEste simple experimento sentó las bases para lo que hoy se conoce como “pruebas de hipótesis”.\nEl contenido de esta unidad se basa en ese concepto: cómo usar la información muestral para tomar decisiones. Veremos dos manifestaciones de esta idea: intervalos de confianza y tests de hipótesis. Luego veremos las similitudes que comparten ambas herramientas y en qué casos son equivalentes."
  },
  {
    "objectID": "4_tdh.html#intervalos-de-confianza",
    "href": "4_tdh.html#intervalos-de-confianza",
    "title": "4. ICs y Tests de hipótesis",
    "section": "Intervalos de Confianza",
    "text": "Intervalos de Confianza\nLa estimación puntual se basa en representar una característica de interés mediante los valores observados de una muestra aleatoria. Sin embargo, los estadísticos que usamos como estimadores son variables aleatorias: su valor varía de muestra en muestra. Por lo tanto, nunca tenemos certeza sobre si, para la muestra que obtuvimos, nuestra estimación está o no “cerca” del verdadero valor del parámetro de interés.\nAfortunadamente, existe otro tipo de estimación: en lugar de tener un solo número como estimador, podemos tener un rango de valores. La ventaja de este método que permite cuantificar (usando probabilidades) el grado de certeza con el que se espera que el verdadero valor del parámetro se encuentre dentro de dicho rango. Estamos hablando de los intervalos de confianza.\nFormalmente, una estimación por intervalo de confianza para un parámetro \\(\\theta\\) se construye a partir de dos funciones \\(L(\\mathbf{x})\\) y \\(U(\\mathbf{x})\\)1 y de un valor \\(\\alpha \\in (0;1)\\), y viene dado por \\[IC_{1-\\alpha}(\\theta) = [L(\\mathbf{x}) \\,;\\, U(\\mathbf{x})] \\text{ tal que } P(L(\\mathbf{x}) \\leq \\theta \\leq U(\\mathbf{x})) = 1 - \\alpha\\]\nA la hora de realizar una estimación por IC, el valor \\(1-\\alpha\\) representará la confianza de nuestro intervalo y se puede interpretar como la probabilidad de que el intervalo \\([L(\\mathbf{x}) \\,;\\, U(\\mathbf{x})]\\) incluya al verdadero valor del parámetro antes de extraer la muestra.2 Otra interpretación posible es que, si se tomaran reiteradas muestras de la población bajo estudio y consecuentemente se construyeran múltiples intervalos de confianza, es de esperar que \\(\\theta\\) esté contenido en el \\(100(1-\\alpha)\\%\\) de ellos.\nExisten varios métodos para construir intervalos de confianza. El más utilizado (y el que veremos en este curso) consiste en proponer cuantiles como valores de \\(L(\\mathbf{x})\\) y \\(U(\\mathbf{x})\\). Dichos cuantiles provienen de la distribución muestral del estadístico que estamos usando para estimar el parámetro.\nPor ejemplo, supongamos que queremos estimar la media poblacional mediante la media muestral (hasta ahora esto sería una estimación puntual, como en la unidad anterior). Sabemos que la distribución muestral de dicho estadístico es Normal (ya sea exacta o aproximadamente, dependiendo de si la variable original es Normal o si debemos recurrir al Teorema Central del Límite). La campana Normal correspondiente estaría centrada en \\(\\mu\\), pero este valor lo desconocemos. Sin embargo, si tomamos a la media muestral observada como nuestra mejor aproximación de \\(\\mu\\) (o sea, \\(\\hat{\\mu} = \\overline{x}\\)) entonces podemos concebir una curva Normal empírica centrada en este valor. Si quisiéramos constuir un intervalo con una confianza del 95%, deberíamos tomar los cuantiles 2,5% y 97,5%, de modo que el intervalo esté compuesto por el 95% central de la campana.\n\n\n\nFigura 6.1: Ilustración de un intervalo de confianza del 95% para la media poblacional.\n\n\n\n\n\n\n\n\nNota\n\n\n\nNótese cómo el uso de las distribuciones muestrales se torna casi opuesto entre la teoría (Unidad 3) y la práctica (Unidad 4). En un entorno teórico, conocemos el valor del parámetro poblacional e hipotetizamos sobre qué ocurriría cuando eventualmente tomemos una muestra, calculando la probabilidad de que nuestro estimador tome un valor dentro de un cierto intervalo: \\(P(a \\leq \\hat{\\theta} \\leq b)\\). En la práctica, sin embargo, el proceso es el inverso: el valor del estimador muestral es lo que se conoce, y se calcula la probabilidad de que el parámetro poblacional tome un valor dentro de un cierto intervalo.\n\n\n\nIC para la media de una población Normal (\\(\\mu\\))\nSea \\(X_1, X_2, \\cdots, X_n\\) una muestra aleatoria de tamaño \\(n\\) extraída de una población con distribución \\(N(\\mu,\\sigma)\\). Sabemos que la media muestral también tiene distribución Normal. Entonces podemos utilizar lo siguiente:\n\\[\\overline{X} \\sim N\\left( \\mu, \\frac{\\sigma}{\\sqrt{n}} \\right) \\implies Z = \\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)\\]\nLo anterior es fácilmente demostrable. Para empezar, cualquier combinación lineal de una variable Normal es a su vez una variable Normal. Como \\(Z\\) es una combinación lineal de \\(\\overline{X}\\) y \\(\\overline{X}\\) es Normal entonces \\(Z\\) también es una variable Normal. ¿Cómo podríamos deducir la Esperanza y Variancia de esta nueva variable aleatoria? Utilizando propiedades de \\(E(X)\\) y \\(V(X)\\) para combinaciones lineales.\n\\(E(Z) = E(\\tfrac{\\sqrt{n}}{\\sigma}[\\overline{X}-\\mu]) = \\tfrac{\\sqrt{n}}{\\sigma} E(\\overline{X}-\\mu) = \\tfrac{\\sqrt{n}}{\\sigma} [E(\\overline{X})-E(\\mu)] = \\tfrac{\\sqrt{n}}{\\sigma} [\\mu-\\mu] = 0\\)\n\\(V(Z) = V(\\tfrac{\\sqrt{n}}{\\sigma}[\\overline{X}-\\mu]) = \\tfrac{n}{\\sigma^2} V(\\overline{X}-\\mu) = \\tfrac{n}{\\sigma^2} V(\\overline{X}) = \\tfrac{n}{\\sigma^2} \\cdot \\tfrac{\\sigma^2}{n} = 1\\)\nHemos así demostrado que \\(Z \\sim N(0,1)\\). ¿De qué nos sirve esto? La distribución \\(N(0,1)\\) se conoce como distribución Normal estándar. Es útil para obtener cuantiles sobre una distribución Normal. Sea \\(Z_p\\) el cuantil que acumula un \\(100p\\%\\) del área bajo la curva Normal estándar. Bajo esta definición, resulta que \\(Z_p\\) nos dice cuántos desvíos estándares debemos movernos respecto a la media para obtener el cuantil correspondiente en nuestra variable original: \\(\\overline{X}_p\\).\nPor ejemplo, supongamos que queremos obtener un intervalo de confianza del 95% para la media poblacional. Como se mencionó anteriormente, debemos buscar los cuantiles 2,5% y 97,5%. Para esto podemos obtener \\(Z_{0.025} = -1,96\\) y \\(Z_{0.975} = 1,96\\). En otras palabras, deberemos movernos 1,96 desvíos estándares por debajo y por encima de la media para obtener el intervalo de confianza deseado.\n\n\nEjemplo 1\n\nSea \\(X\\) una v.a. Normal con media desconocida y desvío estándar igual a 10. Se extrae una muestra aleatoria de tamaño 25 y se obtiene una media muestral \\(\\overline{x} = 18\\). Construya un intervalo de confianza del 95% para la media poblacional.\nSolución: Si \\(X \\sim N(\\mu, \\sigma=10)\\), luego \\(\\overline{X} \\sim N(\\mu, \\tfrac{10}{\\sqrt{25}} = 2)\\).\nEn base a cálculos anteriores sabemos que debemos movernos \\(\\pm\\) 1,96 desvíos estándares respecto a la media muestral observada. Recordemos que esos desvíos estándares no corresponden a la variable original sino al estadístico que estamos utilizando. Por lo tanto:\n\\[IC_{95\\%}(\\mu) = [18 - 1,96 \\cdot 2 \\,;\\, 18 + 1,96 \\cdot 2] = [14,08 \\,;\\, 21,92]\\]\nEn términos del problema diríamos que: en base a la evidencia muestral, se tiene un 95% de confianza de que la verdadera media poblacional se encuentra entre 14,08 y 21,92.\n\nEn líneas generales, la fórmula es la siguiente: \\[IC_{100(1-\\alpha)\\%}(\\mu) = \\left[\\overline{x} + Z_{\\tfrac{\\alpha}{2}} \\cdot \\tfrac{\\sigma}{\\sqrt{n}} \\,;\\, \\overline{x} + Z_{1-\\tfrac{\\alpha}{2}} \\cdot \\tfrac{\\sigma}{\\sqrt{n}} \\right] = \\left[\\overline{x} - Z_{1-\\tfrac{\\alpha}{2}} \\cdot \\tfrac{\\sigma}{\\sqrt{n}} \\,;\\, \\overline{x} + Z_{1-\\tfrac{\\alpha}{2}} \\cdot \\tfrac{\\sigma}{\\sqrt{n}} \\right]\\]\n\\[IC_{100(1-\\alpha)\\%}(\\mu) =  \\overline{x} \\pm Z_{1-\\tfrac{\\alpha}{2}} \\cdot \\tfrac{\\sigma}{\\sqrt{n}}\\]\nEste intervalo está sujeto a las distribuciones muestrales estudiadas en la unidad anterior, por lo que aplican los mismos criterios: si la variable original \\(X\\) es Normal, entonces se puede usar la distribución Normal para calcular el intervalo de confianza, sin importar el tamaño muestral. Si \\(X\\) no es Normal o su distribución es desconocida, ante una muestra grande se puede construir este IC aproximado empleando el Teorema Central del Límite.\n\n\n\n\n\n\nIdea clave\n\n\n\nQuizás hayan notado, a partir de la definición anterior, que \\(Z_{\\tfrac{\\alpha}{2}} = -Z_{1-\\tfrac{\\alpha}{2}}\\). Esto se vio en el ejemplo anterior: \\(Z_{0.025} = -Z_{0.975} = -1,96\\). Esta es una propiedad que cumple la distribución Normal estándar, y una de las razones por las que resulta cómoda para calcular cuantiles: sus cuantiles son simétricos respecto al centro (el percentil 50%).\n\n\n\n\n\n\n\n\nIdea clave\n\n\n\nPara calcular percentiles de una distribución Normal estándar podemos usar una función de R: qnorm(p), donde p es el percentil de interés.\n\n\n\nMargen de error\nEl término \\(e = Z_{1-\\alpha/2} \\tfrac{\\sigma}{\\sqrt{n}}\\) es la semiamplitud del intervalo y se lo denomina margen de error. Naturalmente, un intervalo es más preciso mientras menor sea su margen de error.\n¿Cómo podemos aumentar la precisión de nuestro intervalo? O, equivalentemente, ¿cómo podemos hacer que el término \\(e\\) sea lo más pequeño posible? El margen de error se expresa en función de otros tres valores: \\(\\alpha\\), \\(\\sigma\\) y \\(n\\). Podemos hacer las siguientes observaciones:\n\n\\(\\alpha\\): representa el complemento de la confianza del intervalo. Para disminuir \\(e\\) en función de \\(\\alpha\\) habría que lograr que el factor \\(Z_{1-\\alpha/2}\\) sea lo más pequeño posible. En el caso extremo donde \\(\\alpha=1\\) se tiene que \\(1-\\alpha/2 = 0.5\\) y \\(Z_{0.5}=0\\), porque el percentil 50% de la distribución Normal estándar es el punto medio de la campana, o sea, su Esperanza. En conclusión, aumentar el valor de \\(\\alpha\\) (o reducir el valor de \\(1-\\alpha\\)) disminuye el margen de error.\n\\(\\sigma\\): representa la variabilidad de nuestra variable original \\(X\\). Este número no lo elegimos: es intrínseco a la variable. Por lo tanto, no podemos utilizarlo para reducir el margen de error.\n\\(n\\): representa el tamaño muestral. Se encuentra en el denominador del término \\(e\\), por lo que, mientras mayor sea, menor será el error.\n\nEn conclusión, para aumentar la precisión de nuestro intervalo podemos:\n\ndisminuir la confianza: \\(\\downarrow \\text{confianza} \\implies \\downarrow \\text{error} \\implies \\uparrow \\text{precisión}\\).\naumentar el tamaño muestral: \\(\\uparrow n \\implies \\downarrow \\text{error} \\implies \\uparrow \\text{precisión}\\).\n\nLa relación inversa entre confianza y precisión suele traer confusión. Una buena forma de recordarlo es la siguiente: si decimos algo como “Lionel Messi se encuentra actualmente en el continente americano”, la ambigüedad de nuestra afirmación (o, en otras palabras, la poca precisión que estamos dando) nos permite tener una alta confianza de que sea cierta. En el otro extremo, si somos altamente específicos y decimos algo como “Lionel Messi está en la esquina de Zeballos y Ayacucho”, estamos siendo muy precisos, pero la chance de que esto sea cierto es muy baja y por lo tanto nuestra confianza también lo sería.\n\n\nDeterminación del tamaño muestral\nComo el error de nuestro intervalo es función de la confianza y el tamaño muestral, podríamos a priori optar por un tamaño muestral que nos dé una amplitud deseada: por ejemplo, \\(\\pm\\) 5. ¿Cómo calculamos dicho valor de \\(n\\)? Simplemente debemos tomar la fórmula del margen de error y despejar \\(n\\).\n\\[e = Z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\implies n = \\left( Z_{1-\\alpha/2} \\frac{\\sigma}{e} \\right)^2\\]\n\n\nEjemplo 2\n\nSe pretende estimar por intervalo de confianza el tiempo medio de espera para el colectivo 103 rojo en la esquina de Paraguay e Ituzaingó. Se asume que dicha variable es Normal, con un desvío estándar de 11 minutos. Además, se pretende usar una confianza del 95%.\nPara lograr dicha estimación, nuestra muestra estará conformada por \\(n\\) personas que reclutaremos para que vayan a la esquina designada en un día y horario elegido al azar, registrando cada una de ellas el tiempo que transcurre entre que llegan a la parada y el colectivo aparece. ¿Cuántas personas debemos reclutar si pretendemos que nuestro intervalo tenga una amplitud de \\(\\pm\\) 5’?\nSolución: Aplicando la fórmula dada, tenemos que \\[n = \\left( Z_{1-\\alpha/2} \\frac{\\sigma}{e} \\right)^2 = \\left( Z_{0.975} \\cdot \\frac{11}{5} \\right)^2 = (1.96 \\times 2.2)^2 \\approx 18.59\\]\nEn conclusión, necesitamos reclutar al menos 19 personas para construir el intervalo deseado.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEn las determinaciones de tamaño de muestra siempre se debe redondear hacia arriba el valor de \\(n\\) obtenido. Por ejemplo, si usando la fórmula obtenemos \\(n=7,1\\) entonces debemos extraer una muestra de al menos 8 individuos.\n\n\n\n\n\n\n\n\nNota\n\n\n\nPor fines didácticos, los conceptos de “margen de error” y “determinación de tamaño muestral” fueron presentados para el caso de la media de una población Normal, pero en realidad aplican a todas las distribuciones muestrales que estudiamos, como las que presentamos a continuación.\n\n\nHasta ahora se presentó el caso de una población Normal con \\(\\sigma\\) conocido. ¿Qué pasa si este valor es desconocido? Podemos aplicar la distribución muestral estudiada en la unidad anterior, basada en la distribución t-Student.\n\\[IC_{100(1-\\alpha)\\%}(\\mu) =  \\overline{x} \\pm t_{(n-1)\\,;\\, 1-\\tfrac{\\alpha}{2}} \\cdot \\tfrac{s}{\\sqrt{n}}\\]\nRecordemos que el valor \\(s\\) representa el desvío estándar muestral.\nPara este caso, la función de R que utilizaremos para obtener el percentil \\(t_{(n-1)\\,;\\, p}\\) será qt(p, df = n-1) siendo n nuestro tamaño muestral.\nCuando \\(\\sigma\\) es desconocido pero la muestra es lo suficientemente grande, usar la distribución t-Student es indistinto a usar la distribución Normal, por lo que podemos plantear:\n\\[IC_{100(1-\\alpha)\\%}(\\mu) =  \\overline{x} \\pm Z_{1-\\tfrac{\\alpha}{2}} \\cdot \\tfrac{s}{\\sqrt{n}}\\]\n\n\nEjemplo 3\n\nSupongamos que la duración de las clases de Análisis Estadístico es una variable con distribución Normal. En las 17 clases que hemos tenido hasta ahora, la duración promedio fue de 97 minutos, con un desvío estándar de 16 minutos.\nCon una confianza del 90%, ¿entre qué valores se espera encontrar la verdadera duración media?\nSolución: estamos ante una variable Normal con \\(\\sigma\\) desconocido y una muestra pequeña. Por lo tanto: \\[IC_{90\\%}(\\mu) =  97 \\pm t_{16\\,;\\, 0.95} \\cdot \\tfrac{16}{\\sqrt{17}} = [90.2 \\,;\\, 103.8]\\]\nCon una confianza del 90% y en base a la evidencia muestral, se espera que la verdadera duración media de las clases de Análisis Estadístico se encuentre entre 90 y 104 minutos.\n\n\n\n\nIC para la diferencia de medias (\\(\\mu_1 - \\mu_2\\))\nPara el caso de dos poblaciones no necesariamente Normales con desvíos estándares conocidos, se tiene que \\[\\overline{X}_1 - \\overline{X}_2 \\stackrel{TCL}{\\sim} N \\left( \\mu_1 - \\mu_2 \\,;\\, \\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2} \\right)\\]\n(Nuevamente se recuerda que no es necesario obtener una muestra grande y aplicar el TCL si se sabe de antemano que ambas poblaciones son Normales.)\nEn consecuencia, el intervalo de confianza para la diferencia de medias está dado por \\[IC_{100(1-\\alpha)\\%}(\\mu_1-\\mu_2) =  (\\overline{x}_1 - \\overline{x}_2) \\pm Z_{1-\\tfrac{\\alpha}{2}} \\cdot \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\\]\nPara el caso de \\(\\sigma_1\\) y \\(\\sigma_2\\) desconocidos, nos enfocaremos sólo en el escenario donde las muestras son suficientemente grandes (\\(n_1 \\geq 30\\) y \\(n_2 \\geq 30\\)).3 En este caso, el intervalo está dado por \\[IC_{100(1-\\alpha)\\%}(\\mu_1-\\mu_2) =  (\\overline{x}_1 - \\overline{x}_2) \\pm Z_{1-\\tfrac{\\alpha}{2}} \\cdot \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\\]\n\n\nEjemplo 4\n\nUn fabricante de nafta hace pruebas para determinar el rendimiento relativo de los automóviles, empleando dos aditivos diferentes. Los promedios observados (expresados en kilómetros por litro) son 12,37 para el Aditivo 1 y 15,25 para el Aditivo 2. Los desvíos estándar muestrales fueron 1,6 y 4,8. Dichos valores fueron obtenidos de muestras de 40 y 35 automóviles, respectivamente.\nCon una confianza del 95%, ¿considera usted que, en promedio, la nafta rinde menos kilómetros con el Aditivo 1?\nSolución: No conocemos la distribución de la variable en las poblaciones, pero las muestras son grandes. Por lo tanto, \\[IC_{95\\%}(\\mu_1-\\mu_2) =  (12.37-15.25) \\pm 1.96 \\cdot \\sqrt{\\frac{1.6}{40} + \\frac{4.8}{35}} = [-3.70 \\,;\\, -2.06]\\]\nComo el límite superior del intervalo es menor a cero, sería sensato asumir, con una confianza del 95%, que el Aditivo 1 rinde menos que el Aditivo 2.\n\n\n\nIC para la proporción (\\(p\\))\nPara una variable binaria que sólo admite éxitos y fracasos, hemos visto que ante muestras grandes se tiene \\[\\hat{p} \\stackrel{TCL}{\\sim} N \\left( p \\,;\\, \\frac{p(1-p)}{n} \\right)\\]\nPor lo tanto, para una confianza del \\(100(1-\\alpha)\\%\\) se tiene que: \\[IC_{100(1-\\alpha)\\%}(p) =  \\hat{p} \\pm Z_{1-\\tfrac{\\alpha}{2}} \\cdot \\sqrt{\\frac{\\hat{p} (1 - \\hat{p})}{n}}\\]\n\n\nEjemplo 5\n\nEl sindicato que representa a los empleados de las casas de comida rápida de Rosario está considerando una propuesta de ajuste de salarios. De acuerdo con el reglamento del sindicato, por lo menos tres cuartas partes de los miembros del sindicato deben aprobar cualquier oferta para que ésta se lleve a cabo. Una muestra aleatoria de 1590 miembros actuales revela que 1283 de ellos planean aprobar la propuesta.\nDetermine el IC del 95% para la proporción de miembros a favor de la propuesta. En base a esta muestra, ¿podría concluir que la propuesta será eventualmente aprobada?\nSolución: En primer lugar, la proporción muestral de aprobación es \\(\\hat{p} = \\tfrac{1283}{1590} \\approx 0,807\\). Luego, el IC está dado por \\[IC_{95\\%}(p) =  0.807 \\pm 1.96 \\cdot \\sqrt{\\frac{0.807 \\cdot  0.193}{1590}} = 0.807 \\pm 0.019 = [0.788 \\,;\\, 0.826]\\]\nComo el límite inferior del intervalo supera las tres cuartas partes, sería sensato asumir que la propuesta será aprobada."
  },
  {
    "objectID": "4_tdh.html#tests-de-hipótesis",
    "href": "4_tdh.html#tests-de-hipótesis",
    "title": "4. ICs y Tests de hipótesis",
    "section": "Tests de Hipótesis",
    "text": "Tests de Hipótesis\n[Próximamente.]\n\n\n\n\nWikipedia. 2024. «Lady tasting tea - Wikipedia, The Free Encyclopedia». https://en.wikipedia.org/wiki/Lady_tasting_tea."
  },
  {
    "objectID": "4_tdh.html#footnotes",
    "href": "4_tdh.html#footnotes",
    "title": "4. ICs y Tests de hipótesis",
    "section": "",
    "text": "Nótese la negrita en la \\(\\mathbf{x}\\). Esto es para representar el vector de valores muestrales observados: \\(\\mathbf{x} = (x_1, x_2, \\cdots, x_n)\\).↩︎\nUna vez tomada la muestra, los extremos del intervalo ya no son variables aleatorias sino números fijos. Por lo tanto, cuando esto ocurre la proabbilidad de que el verdadero valor del parámetro esté contenido en el intervalo es 0 ó 1: el intervalo contiene al parámetro, o bien no lo contiene (aunque nunca sabremos en cuál caso nos encontramos).↩︎\nExisten distribuciones muestrales para la diferencia de medias con poblaciones Normales, variancias desconocidas y muestras pequeñas. Hemos optado por excluirlas del contenido de esta materia, visto que traen aparejadas cierta complejidad matemática y corresponden a un escenario que no suele darse con frecuencia en la práctica.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Parker, M. 2019. Humble Pi: A Comedy of Maths Errors. Penguin\nBooks Limited. https://books.google.com.ar/books?id=qYlZDwAAQBAJ.\n\n\nWikipedia. 2024a. “Lady Tasting Tea - Wikipedia, the Free\nEncyclopedia.” https://en.wikipedia.org/wiki/Lady_tasting_tea.\n\n\n———. 2024b. “Sally Clark - Wikipedia, the Free\nEncyclopedia.” https://en.wikipedia.org/wiki/Sally_Clark."
  }
]