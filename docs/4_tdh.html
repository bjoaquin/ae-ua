<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Análisis Estadístico (UA) - 4. ICs y Tests de hipótesis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./5_series.html" rel="next">
<link href="./3_infer.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./4_tdh.html"><span class="chapter-title">4. ICs y Tests de hipótesis</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Análisis Estadístico (UA)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0_conteo.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">0. Herramientas de conteo</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">1. Probabilidad</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_va.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">2. Variable aleatoria</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_infer.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">3. Inferencia estadística</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4_tdh.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">4. ICs y Tests de hipótesis</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5_series.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">5. Series de Tiempo</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#introducción" id="toc-introducción" class="nav-link active" data-scroll-target="#introducción">Introducción</a></li>
  <li><a href="#intervalos-de-confianza" id="toc-intervalos-de-confianza" class="nav-link" data-scroll-target="#intervalos-de-confianza">Intervalos de Confianza</a>
  <ul>
  <li><a href="#ic-para-la-media-de-una-población-normal-mu" id="toc-ic-para-la-media-de-una-población-normal-mu" class="nav-link" data-scroll-target="#ic-para-la-media-de-una-población-normal-mu">IC para la media de una población Normal (<span class="math inline">\(\mu\)</span>)</a>
  <ul class="collapse">
  <li><a href="#margen-de-error" id="toc-margen-de-error" class="nav-link" data-scroll-target="#margen-de-error">Margen de error</a></li>
  <li><a href="#determinación-del-tamaño-muestral" id="toc-determinación-del-tamaño-muestral" class="nav-link" data-scroll-target="#determinación-del-tamaño-muestral">Determinación del tamaño muestral</a></li>
  </ul></li>
  <li><a href="#ic-para-la-diferencia-de-medias-mu_1---mu_2" id="toc-ic-para-la-diferencia-de-medias-mu_1---mu_2" class="nav-link" data-scroll-target="#ic-para-la-diferencia-de-medias-mu_1---mu_2">IC para la diferencia de medias (<span class="math inline">\(\mu_1 - \mu_2\)</span>)</a></li>
  <li><a href="#ic-para-la-proporción-p" id="toc-ic-para-la-proporción-p" class="nav-link" data-scroll-target="#ic-para-la-proporción-p">IC para la proporción (<span class="math inline">\(p\)</span>)</a></li>
  </ul></li>
  <li><a href="#tests-de-hipótesis" id="toc-tests-de-hipótesis" class="nav-link" data-scroll-target="#tests-de-hipótesis">Tests de Hipótesis</a>
  <ul>
  <li><a href="#hipótesis" id="toc-hipótesis" class="nav-link" data-scroll-target="#hipótesis">Hipótesis</a></li>
  <li><a href="#error" id="toc-error" class="nav-link" data-scroll-target="#error">Error</a></li>
  <li><a href="#tipos-de-error" id="toc-tipos-de-error" class="nav-link" data-scroll-target="#tipos-de-error">Tipos de error</a></li>
  <li><a href="#p-value" id="toc-p-value" class="nav-link" data-scroll-target="#p-value">p-value</a></li>
  <li><a href="#tests-basados-en-observaciones-individuales" id="toc-tests-basados-en-observaciones-individuales" class="nav-link" data-scroll-target="#tests-basados-en-observaciones-individuales">Tests basados en observaciones individuales</a></li>
  <li><a href="#test-para-la-media-mu" id="toc-test-para-la-media-mu" class="nav-link" data-scroll-target="#test-para-la-media-mu">Test para la media (<span class="math inline">\(\mu\)</span>)</a></li>
  <li><a href="#test-para-la-diferencia-de-medias-mu_1---mu_2" id="toc-test-para-la-diferencia-de-medias-mu_1---mu_2" class="nav-link" data-scroll-target="#test-para-la-diferencia-de-medias-mu_1---mu_2">Test para la diferencia de medias (<span class="math inline">\(\mu_1 - \mu_2\)</span>)</a></li>
  <li><a href="#test-para-la-proporción-p" id="toc-test-para-la-proporción-p" class="nav-link" data-scroll-target="#test-para-la-proporción-p">Test para la proporción (<span class="math inline">\(p\)</span>)</a></li>
  </ul></li>
  <li><a href="#ic-test-de-hipótesis" id="toc-ic-test-de-hipótesis" class="nav-link" data-scroll-target="#ic-test-de-hipótesis">¿IC = Test de hipótesis?</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">4. ICs y Tests de hipótesis</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introducción" class="level2">
<h2 class="anchored" data-anchor-id="introducción">Introducción</h2>
<p>Un día a principios de la década de 1920, Ronald Fisher, un reconocido estadístico, se encontró en una situación peculiar: le preparó una taza de té a una compañera de trabajo y ella la rechazó por haber servido la leche antes que el té. Fisher argumentó que el orden en el que se servían los líquidos no tenía importancia, pero ella estaba fuertemente en desacuerdo: de hecho, se jactaba de poder probar una taza de té y decir si se había servido primero la leche o el té.</p>
<p>Motivado por la curiosa situación y por su formación profesional, Fisher se propuso diseñar un experimento para poner a prueba la supuesta habilidad de su compañera. Preparó ocho tazas de té: cuatro donde se había servido primero la leche y cuatro donde se había servido primero el té. En orden aleatorio, le hizo probar las tazas a su compañera, una por una, mientras ella señalaba para cada una su predicción. Cuando el experimento terminó, la mujer había podido etiquetar las ocho tazas correctamente. <span class="citation" data-cites="fisher">(<a href="references.html#ref-fisher" role="doc-biblioref">Wikipedia 2024</a>)</span></p>
<p>Fisher estaba sorprendido, pero aún había un pensamiento del que no podía desprenderse: existía la posibilidad de que la mujer estuviese adivinando cómo fue preparada cada taza, con la inesperada fortuna de haber acertado en todos los casos. ¿Cuál era la probabilidad de dicho caso? Aplicando la distribución hipergeométrica, puede demostrarse que dicha probabilidad es 1,4%. En otras palabras, era poco probable que la mujer estuviese adivinando: la evidencia muestral sugería que realmente podía percibir sabores distintos entre las preparaciones.</p>
<p>Este simple experimento sentó las bases para lo que hoy se conoce como “pruebas de hipótesis”.</p>
<p>El contenido de esta unidad se basa en ese concepto: cómo usar la información muestral para tomar decisiones. Veremos dos manifestaciones de esta idea: intervalos de confianza y tests de hipótesis. Luego veremos las similitudes que comparten ambas herramientas y en qué casos son equivalentes.</p>
</section>
<section id="intervalos-de-confianza" class="level2">
<h2 class="anchored" data-anchor-id="intervalos-de-confianza">Intervalos de Confianza</h2>
<p>La estimación puntual se basa en representar una característica de interés mediante los valores observados de una muestra aleatoria. Sin embargo, los estadísticos que usamos como estimadores son variables aleatorias: su valor varía de muestra en muestra. Por lo tanto, nunca tenemos certeza sobre si, para la muestra que obtuvimos, nuestra estimación está o no “cerca” del verdadero valor del parámetro de interés.</p>
<p>Afortunadamente, existe otro tipo de estimación: en lugar de tener un solo número como estimador, podemos tener un rango de valores. La ventaja de este método que permite cuantificar (usando probabilidades) el grado de certeza con el que se espera que el verdadero valor del parámetro se encuentre dentro de dicho rango. Estamos hablando de los <em>intervalos de confianza</em>.</p>
<p>Formalmente, una estimación por <strong>intervalo de confianza</strong> para un parámetro <span class="math inline">\(\theta\)</span> se construye a partir de dos funciones <span class="math inline">\(L(\mathbf{x})\)</span> y <span class="math inline">\(U(\mathbf{x})\)</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> y de un valor <span class="math inline">\(\alpha \in (0;1)\)</span>, y viene dado por <span class="math display">\[IC_{1-\alpha}(\theta) = [L(\mathbf{x}) \,;\, U(\mathbf{x})] \text{ tal que } P(L(\mathbf{x}) \leq \theta \leq U(\mathbf{x})) = 1 - \alpha\]</span></p>
<p>A la hora de realizar una estimación por IC, el valor <span class="math inline">\(1-\alpha\)</span> representará la <strong>confianza</strong> de nuestro intervalo y se puede interpretar como la probabilidad de que el intervalo <span class="math inline">\([L(\mathbf{x}) \,;\, U(\mathbf{x})]\)</span> incluya al verdadero valor del parámetro <em>antes de extraer la muestra</em>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Otra interpretación posible es que, si se tomaran reiteradas muestras de la población bajo estudio y consecuentemente se construyeran múltiples intervalos de confianza, es de esperar que <span class="math inline">\(\theta\)</span> esté contenido en el <span class="math inline">\(100(1-\alpha)\%\)</span> de ellos.</p>
<p>Existen varios métodos para construir intervalos de confianza. El más utilizado (y el que veremos en este curso) consiste en proponer cuantiles como valores de <span class="math inline">\(L(\mathbf{x})\)</span> y <span class="math inline">\(U(\mathbf{x})\)</span>. Dichos cuantiles provienen de la distribución muestral del estadístico que estamos usando para estimar el parámetro.</p>
<p>Por ejemplo, supongamos que queremos estimar la media poblacional mediante la media muestral (hasta ahora esto sería una estimación puntual, como en la unidad anterior). Sabemos que la distribución muestral de dicho estadístico es Normal (ya sea exacta o aproximadamente, dependiendo de si la variable original es Normal o si debemos recurrir al Teorema Central del Límite). La campana Normal correspondiente estaría centrada en <span class="math inline">\(\mu\)</span>, pero este valor lo desconocemos. Sin embargo, si tomamos a la media muestral observada como nuestra mejor aproximación de <span class="math inline">\(\mu\)</span> (o sea, <span class="math inline">\(\hat{\mu} = \overline{x}\)</span>) entonces podemos concebir una curva Normal empírica centrada en este valor. Si quisiéramos constuir un intervalo con una confianza del 95%, deberíamos tomar los cuantiles 2,5% y 97,5%, de modo que el intervalo esté compuesto por el 95% central de la campana.</p>
<div id="fig-meanci" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ci_mean.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figura&nbsp;6.1: Ilustración de un intervalo de confianza del 95% para la media poblacional.</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Nótese cómo el uso de las distribuciones muestrales se torna casi opuesto entre la teoría (Unidad 3) y la práctica (Unidad 4). En un entorno teórico, conocemos el valor del parámetro poblacional e hipotetizamos sobre qué ocurriría cuando eventualmente tomemos una muestra, calculando la probabilidad de que nuestro estimador tome un valor dentro de un cierto intervalo: <span class="math inline">\(P(a \leq \hat{\theta} \leq b)\)</span>. En la práctica, sin embargo, el proceso es el inverso: el valor del estimador muestral es lo que se conoce, y se calcula la probabilidad de que el parámetro poblacional tome un valor dentro de un cierto intervalo.</p>
</div>
</div>
<section id="ic-para-la-media-de-una-población-normal-mu" class="level3">
<h3 class="anchored" data-anchor-id="ic-para-la-media-de-una-población-normal-mu">IC para la media de una población Normal (<span class="math inline">\(\mu\)</span>)</h3>
<p>Sea <span class="math inline">\(X_1, X_2, \cdots, X_n\)</span> una muestra aleatoria de tamaño <span class="math inline">\(n\)</span> extraída de una población con distribución <span class="math inline">\(N(\mu,\sigma)\)</span>. Sabemos que la media muestral también tiene distribución Normal. Entonces podemos utilizar lo siguiente:</p>
<p><span class="math display">\[\overline{X} \sim N\left( \mu, \frac{\sigma}{\sqrt{n}} \right) \implies Z = \frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)\]</span></p>
<p>Lo anterior es fácilmente demostrable. Para empezar, cualquier combinación lineal de una variable Normal es a su vez una variable Normal. Como <span class="math inline">\(Z\)</span> es una combinación lineal de <span class="math inline">\(\overline{X}\)</span> y <span class="math inline">\(\overline{X}\)</span> es Normal entonces <span class="math inline">\(Z\)</span> también es una variable Normal. ¿Cómo podríamos deducir la Esperanza y Variancia de esta nueva variable aleatoria? Utilizando propiedades de <span class="math inline">\(E(X)\)</span> y <span class="math inline">\(V(X)\)</span> para combinaciones lineales.</p>
<p><span class="math inline">\(E(Z) = E(\tfrac{\sqrt{n}}{\sigma}[\overline{X}-\mu]) = \tfrac{\sqrt{n}}{\sigma} E(\overline{X}-\mu) = \tfrac{\sqrt{n}}{\sigma} [E(\overline{X})-E(\mu)] = \tfrac{\sqrt{n}}{\sigma} [\mu-\mu] = 0\)</span></p>
<p><span class="math inline">\(V(Z) = V(\tfrac{\sqrt{n}}{\sigma}[\overline{X}-\mu]) = \tfrac{n}{\sigma^2} V(\overline{X}-\mu) = \tfrac{n}{\sigma^2} V(\overline{X}) = \tfrac{n}{\sigma^2} \cdot \tfrac{\sigma^2}{n} = 1\)</span></p>
<p>Hemos así demostrado que <span class="math inline">\(Z \sim N(0,1)\)</span>. ¿De qué nos sirve esto? La distribución <span class="math inline">\(N(0,1)\)</span> se conoce como <strong>distribución Normal estándar</strong>. Es útil para obtener cuantiles sobre una distribución Normal. Sea <span class="math inline">\(Z_p\)</span> el cuantil que acumula un <span class="math inline">\(100p\%\)</span> del área bajo la curva Normal estándar. Bajo esta definición, resulta que <span class="math inline">\(Z_p\)</span> nos dice cuántos desvíos estándares debemos movernos respecto a la media para obtener el cuantil correspondiente en nuestra variable original: <span class="math inline">\(\overline{X}_p\)</span>.</p>
<p>Por ejemplo, supongamos que queremos obtener un intervalo de confianza del 95% para la media poblacional. Como se mencionó anteriormente, debemos buscar los cuantiles 2,5% y 97,5%. Para esto podemos obtener <span class="math inline">\(Z_{0.025} = -1,96\)</span> y <span class="math inline">\(Z_{0.975} = 1,96\)</span>. En otras palabras, deberemos movernos 1,96 desvíos estándares por debajo y por encima de la media para obtener el intervalo de confianza deseado.</p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 1</strong></p>
</div>
<p>Sea <span class="math inline">\(X\)</span> una v.a. Normal con media desconocida y desvío estándar igual a 10. Se extrae una muestra aleatoria de tamaño 25 y se obtiene una media muestral <span class="math inline">\(\overline{x} = 18\)</span>. Construya un intervalo de confianza del 95% para la media poblacional.</p>
<p><strong>Solución:</strong> Si <span class="math inline">\(X \sim N(\mu, \sigma=10)\)</span>, luego <span class="math inline">\(\overline{X} \sim N(\mu, \tfrac{10}{\sqrt{25}} = 2)\)</span>.</p>
<p>En base a cálculos anteriores sabemos que debemos movernos <span class="math inline">\(\pm\)</span> 1,96 desvíos estándares respecto a la media muestral observada. Recordemos que esos desvíos estándares no corresponden a la variable original sino al estadístico que estamos utilizando. Por lo tanto:</p>
<p><span class="math display">\[IC_{95\%}(\mu) = [18 - 1,96 \cdot 2 \,;\, 18 + 1,96 \cdot 2] = [14,08 \,;\, 21,92]\]</span></p>
<p>En términos del problema diríamos que: en base a la evidencia muestral, se tiene un 95% de confianza de que la verdadera media poblacional se encuentra entre 14,08 y 21,92.</p>
</div>
<p>En líneas generales, la fórmula es la siguiente: <span class="math display">\[IC_{100(1-\alpha)\%}(\mu) = \left[\overline{x} + Z_{\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \,;\, \overline{x} + Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \right] = \left[\overline{x} - Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \,;\, \overline{x} + Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}} \right]\]</span></p>
<p><span class="math display">\[IC_{100(1-\alpha)\%}(\mu) =  \overline{x} \pm Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{\sigma}{\sqrt{n}}\]</span></p>
<p>Este intervalo está sujeto a las distribuciones muestrales estudiadas en la unidad anterior, por lo que aplican los mismos criterios: si la variable original <span class="math inline">\(X\)</span> es Normal, entonces se puede usar la distribución Normal para calcular el intervalo de confianza, sin importar el tamaño muestral. Si <span class="math inline">\(X\)</span> no es Normal o su distribución es desconocida, ante una muestra grande se puede construir este IC <em>aproximado</em> empleando el Teorema Central del Límite.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Idea clave
</div>
</div>
<div class="callout-body-container callout-body">
<p>Quizás hayan notado, a partir de la definición anterior, que <span class="math inline">\(Z_{\tfrac{\alpha}{2}} = -Z_{1-\tfrac{\alpha}{2}}\)</span>. Esto se vio en el ejemplo anterior: <span class="math inline">\(Z_{0.025} = -Z_{0.975} = -1,96\)</span>. Esta es una propiedad que cumple la distribución Normal estándar, y una de las razones por las que resulta cómoda para calcular cuantiles: sus cuantiles son simétricos respecto al centro (el percentil 50%).</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Idea clave
</div>
</div>
<div class="callout-body-container callout-body">
<p>Para calcular percentiles de una distribución Normal estándar podemos usar una función de R: <code>qnorm(p)</code>, donde <code>p</code> es el percentil de interés.</p>
</div>
</div>
<section id="margen-de-error" class="level4">
<h4 class="anchored" data-anchor-id="margen-de-error">Margen de error</h4>
<p>El término <span class="math inline">\(e = Z_{1-\alpha/2} \tfrac{\sigma}{\sqrt{n}}\)</span> es la <em>semiamplitud</em> del intervalo y se lo denomina <strong>margen de error</strong>. Naturalmente, un intervalo es más <em>preciso</em> mientras menor sea su margen de error.</p>
<p>¿Cómo podemos aumentar la precisión de nuestro intervalo? O, equivalentemente, ¿cómo podemos hacer que el término <span class="math inline">\(e\)</span> sea lo más pequeño posible? El margen de error se expresa en función de otros tres valores: <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\sigma\)</span> y <span class="math inline">\(n\)</span>. Podemos hacer las siguientes observaciones:</p>
<ul>
<li><p><span class="math inline">\(\alpha\)</span>: representa el complemento de la confianza del intervalo. Para disminuir <span class="math inline">\(e\)</span> en función de <span class="math inline">\(\alpha\)</span> habría que lograr que el factor <span class="math inline">\(Z_{1-\alpha/2}\)</span> sea lo más pequeño posible. En el caso extremo donde <span class="math inline">\(\alpha=1\)</span> se tiene que <span class="math inline">\(1-\alpha/2 = 0.5\)</span> y <span class="math inline">\(Z_{0.5}=0\)</span>, porque el percentil 50% de la distribución Normal estándar es el punto medio de la campana, o sea, su Esperanza. En conclusión, aumentar el valor de <span class="math inline">\(\alpha\)</span> (o reducir el valor de <span class="math inline">\(1-\alpha\)</span>) disminuye el margen de error.</p></li>
<li><p><span class="math inline">\(\sigma\)</span>: representa la variabilidad de nuestra variable original <span class="math inline">\(X\)</span>. Este número no lo elegimos: es intrínseco a la variable. Por lo tanto, no podemos utilizarlo para reducir el margen de error.</p></li>
<li><p><span class="math inline">\(n\)</span>: representa el tamaño muestral. Se encuentra en el denominador del término <span class="math inline">\(e\)</span>, por lo que, mientras mayor sea, menor será el error.</p></li>
</ul>
<p>En conclusión, para aumentar la precisión de nuestro intervalo podemos:</p>
<ul>
<li>disminuir la confianza: <span class="math inline">\(\downarrow \text{confianza} \implies \downarrow \text{error} \implies \uparrow \text{precisión}\)</span>.</li>
<li>aumentar el tamaño muestral: <span class="math inline">\(\uparrow n \implies \downarrow \text{error} \implies \uparrow \text{precisión}\)</span>.</li>
</ul>
<p>La relación inversa entre confianza y precisión suele traer confusión. Una buena forma de recordarlo es la siguiente: si decimos algo como “Lionel Messi se encuentra actualmente en el continente americano”, la ambigüedad de nuestra afirmación (o, en otras palabras, la poca precisión que estamos dando) nos permite tener una alta confianza de que sea cierta. En el otro extremo, si somos altamente específicos y decimos algo como “Lionel Messi está en la esquina de Zeballos y Ayacucho”, estamos siendo muy precisos, pero la chance de que esto sea cierto es muy baja y por lo tanto nuestra confianza también lo sería.</p>
</section>
<section id="determinación-del-tamaño-muestral" class="level4">
<h4 class="anchored" data-anchor-id="determinación-del-tamaño-muestral">Determinación del tamaño muestral</h4>
<p>Como el error de nuestro intervalo es función de la confianza y el tamaño muestral, podríamos <em>a priori</em> optar por un tamaño muestral que nos dé una amplitud deseada: por ejemplo, <span class="math inline">\(\pm\)</span> 5. ¿Cómo calculamos dicho valor de <span class="math inline">\(n\)</span>? Simplemente debemos tomar la fórmula del margen de error y despejar <span class="math inline">\(n\)</span>.</p>
<p><span class="math display">\[e = Z_{1-\alpha/2} \frac{\sigma}{\sqrt{n}} \implies n = \left( Z_{1-\alpha/2} \frac{\sigma}{e} \right)^2\]</span></p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 2</strong></p>
</div>
<p>Se pretende estimar por intervalo de confianza el tiempo medio de espera para el colectivo 103 rojo en la esquina de Paraguay e Ituzaingó. Se asume que dicha variable es Normal, con un desvío estándar de 11 minutos. Además, se pretende usar una confianza del 95%.</p>
<p>Para lograr dicha estimación, nuestra muestra estará conformada por <span class="math inline">\(n\)</span> personas que reclutaremos para que vayan a la esquina designada en un día y horario elegido al azar, registrando cada una de ellas el tiempo que transcurre entre que llegan a la parada y el colectivo aparece. ¿Cuántas personas debemos reclutar si pretendemos que nuestro intervalo tenga una amplitud de <span class="math inline">\(\pm\)</span> 5’?</p>
<p><strong>Solución:</strong> Aplicando la fórmula dada, tenemos que <span class="math display">\[n = \left( Z_{1-\alpha/2} \frac{\sigma}{e} \right)^2 = \left( Z_{0.975} \cdot \frac{11}{5} \right)^2 = (1.96 \times 2.2)^2 \approx 18.59\]</span></p>
<p>En conclusión, necesitamos reclutar al menos 19 personas para construir el intervalo deseado.</p>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>En las determinaciones de tamaño de muestra siempre se debe redondear hacia arriba el valor de <span class="math inline">\(n\)</span> obtenido. Por ejemplo, si usando la fórmula obtenemos <span class="math inline">\(n=7,1\)</span> entonces debemos extraer una muestra de al menos 8 individuos.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Por fines didácticos, los conceptos de “margen de error” y “determinación de tamaño muestral” fueron presentados para el caso de la media de una población Normal, pero en realidad aplican a todas las distribuciones muestrales que estudiamos, como las que presentamos a continuación.</p>
</div>
</div>
<p>Hasta ahora se presentó el caso de una población Normal con <span class="math inline">\(\sigma\)</span> conocido. ¿Qué pasa si este valor es <strong>desconocido</strong>? Podemos aplicar la distribución muestral estudiada en la unidad anterior, basada en la distribución t-Student.</p>
<p><span class="math display">\[IC_{100(1-\alpha)\%}(\mu) =  \overline{x} \pm t_{(n-1)\,;\, 1-\tfrac{\alpha}{2}} \cdot \tfrac{s}{\sqrt{n}}\]</span></p>
<p>Recordemos que el valor <span class="math inline">\(s\)</span> representa el desvío estándar muestral.</p>
<p>Para este caso, la función de R que utilizaremos para obtener el percentil <span class="math inline">\(t_{(n-1)\,;\, p}\)</span> será <code>qt(p, df = n-1)</code> siendo <code>n</code> nuestro tamaño muestral.</p>
<p>Cuando <span class="math inline">\(\sigma\)</span> es desconocido pero la muestra es lo suficientemente grande, usar la distribución t-Student es indistinto a usar la distribución Normal, por lo que podemos plantear:</p>
<p><span class="math display">\[IC_{100(1-\alpha)\%}(\mu) =  \overline{x} \pm Z_{1-\tfrac{\alpha}{2}} \cdot \tfrac{s}{\sqrt{n}}\]</span></p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 3</strong></p>
</div>
<p>Supongamos que la duración de las clases de Análisis Estadístico es una variable con distribución Normal. En las 17 clases que hemos tenido hasta ahora, la duración promedio fue de 97 minutos, con un desvío estándar de 16 minutos.</p>
<p>Con una confianza del 90%, ¿entre qué valores se espera encontrar la verdadera duración media?</p>
<p><strong>Solución:</strong> estamos ante una variable Normal con <span class="math inline">\(\sigma\)</span> desconocido y una muestra pequeña. Por lo tanto: <span class="math display">\[IC_{90\%}(\mu) =  97 \pm t_{16\,;\, 0.95} \cdot \tfrac{16}{\sqrt{17}} = [90.2 \,;\, 103.8]\]</span></p>
<p>Con una confianza del 90% y en base a la evidencia muestral, se espera que la verdadera duración media de las clases de Análisis Estadístico se encuentre entre 90 y 104 minutos.</p>
</div>
</section>
</section>
<section id="ic-para-la-diferencia-de-medias-mu_1---mu_2" class="level3">
<h3 class="anchored" data-anchor-id="ic-para-la-diferencia-de-medias-mu_1---mu_2">IC para la diferencia de medias (<span class="math inline">\(\mu_1 - \mu_2\)</span>)</h3>
<p>Para el caso de dos poblaciones no necesariamente Normales con desvíos estándares conocidos, se tiene que <span class="math display">\[\overline{X}_1 - \overline{X}_2 \stackrel{TCL}{\sim} N \left( \mu_1 - \mu_2 \,;\, \frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2} \right)\]</span></p>
<p>(Nuevamente se recuerda que no es necesario obtener una muestra grande y aplicar el TCL si se sabe de antemano que ambas poblaciones son Normales.)</p>
<p>En consecuencia, el intervalo de confianza para la diferencia de medias está dado por <span class="math display">\[IC_{100(1-\alpha)\%}(\mu_1-\mu_2) =  (\overline{x}_1 - \overline{x}_2) \pm Z_{1-\tfrac{\alpha}{2}} \cdot \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}\]</span></p>
<p>Para el caso de <span class="math inline">\(\sigma_1\)</span> y <span class="math inline">\(\sigma_2\)</span> desconocidos, nos enfocaremos sólo en el escenario donde las muestras son suficientemente grandes (<span class="math inline">\(n_1 \geq 30\)</span> y <span class="math inline">\(n_2 \geq 30\)</span>).<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> En este caso, el intervalo está dado por <span class="math display">\[IC_{100(1-\alpha)\%}(\mu_1-\mu_2) =  (\overline{x}_1 - \overline{x}_2) \pm Z_{1-\tfrac{\alpha}{2}} \cdot \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}\]</span></p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 4</strong></p>
</div>
<p>Un fabricante de nafta hace pruebas para determinar el rendimiento relativo de los automóviles, empleando dos aditivos diferentes. Los promedios observados (expresados en kilómetros por litro) son 12,37 para el Aditivo 1 y 15,25 para el Aditivo 2. Los desvíos estándar muestrales fueron 1,6 y 4,8. Dichos valores fueron obtenidos de muestras de 40 y 35 automóviles, respectivamente.</p>
<p>Con una confianza del 95%, ¿considera usted que, en promedio, la nafta rinde menos kilómetros con el Aditivo 1?</p>
<p><strong>Solución:</strong> No conocemos la distribución de la variable en las poblaciones, pero las muestras son grandes. Por lo tanto, <span class="math display">\[IC_{95\%}(\mu_1-\mu_2) =  (12.37-15.25) \pm 1.96 \cdot \sqrt{\frac{1.6}{40} + \frac{4.8}{35}} = [-3.70 \,;\, -2.06]\]</span></p>
<p>Como el límite superior del intervalo es menor a cero, sería sensato asumir, con una confianza del 95%, que el Aditivo 1 rinde menos que el Aditivo 2.</p>
</div>
</section>
<section id="ic-para-la-proporción-p" class="level3">
<h3 class="anchored" data-anchor-id="ic-para-la-proporción-p">IC para la proporción (<span class="math inline">\(p\)</span>)</h3>
<p>Para una variable binaria que sólo admite éxitos y fracasos, hemos visto que ante muestras grandes se tiene <span class="math display">\[\hat{p} \stackrel{TCL}{\sim} N \left( p \,;\, \frac{p(1-p)}{n} \right)\]</span></p>
<p>Por lo tanto, para una confianza del <span class="math inline">\(100(1-\alpha)\%\)</span> se tiene que: <span class="math display">\[IC_{100(1-\alpha)\%}(p) =  \hat{p} \pm Z_{1-\tfrac{\alpha}{2}} \cdot \sqrt{\frac{\hat{p} (1 - \hat{p})}{n}}\]</span></p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 5</strong></p>
</div>
<p>El sindicato que representa a los empleados de las casas de comida rápida de Rosario está considerando una propuesta de ajuste de salarios. De acuerdo con el reglamento del sindicato, por lo menos tres cuartas partes de los miembros del sindicato deben aprobar cualquier oferta para que ésta se lleve a cabo. Una muestra aleatoria de 1590 miembros actuales revela que 1283 de ellos planean aprobar la propuesta.</p>
<p>Determine el IC del 95% para la proporción de miembros a favor de la propuesta. En base a esta muestra, ¿podría concluir que la propuesta será eventualmente aprobada?</p>
<p><strong>Solución:</strong> En primer lugar, la proporción muestral de aprobación es <span class="math inline">\(\hat{p} = \tfrac{1283}{1590} \approx 0,807\)</span>. Luego, el IC está dado por <span class="math display">\[IC_{95\%}(p) =  0.807 \pm 1.96 \cdot \sqrt{\frac{0.807 \cdot  0.193}{1590}} = 0.807 \pm 0.019 = [0.788 \,;\, 0.826]\]</span></p>
<p>Como el límite inferior del intervalo supera las tres cuartas partes, sería sensato asumir que la propuesta será aprobada.</p>
</div>
</section>
</section>
<section id="tests-de-hipótesis" class="level2">
<h2 class="anchored" data-anchor-id="tests-de-hipótesis">Tests de Hipótesis</h2>
<p>En la vida cotidiana es común asumir cosas. Asumimos que la moneda que tenemos en el bolsillo es equilibrada: tiene la misma probabilidad de caer en cara como en cruz. Asumimos que si ahora el cielo está despejado entonces no va a llover en la próxima hora. Asumimos que mañana la Tierra va a seguir girando alrededor del sol. Pero todo esto podría ser falso. ¿Cómo podemos evaluar la “solidez” de estas suposiciones?</p>
<section id="hipótesis" class="level3">
<h3 class="anchored" data-anchor-id="hipótesis">Hipótesis</h3>
<p>Una <strong>hipótesis</strong> es un enunciado acerca de una característica poblacional. Esta característica con frecuencia es desconocida, por lo que nuestra hipótesis puede ser verdadera o falsa. En la teoría estadística se trabaja con dos tipos de hipótesis:</p>
<ul>
<li><strong>Hipótesis nula</strong> (<span class="math inline">\(H_0\)</span>): es la creencia convencional, el <em>status quo</em>, lo que se asume por defecto.</li>
<li><strong>Hipótesis alternativa</strong> (<span class="math inline">\(H_1\)</span>): es aquel enunciado que desafía el <em>status quo</em>, planteando una realidad opuesta a la que propone la hipótesis nula.</li>
</ul>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 6</strong></p>
</div>
<p>Para cada par de hipótesis a continuación, determine cuál sería <span class="math inline">\(H_0\)</span> y cuál sería <span class="math inline">\(H_1\)</span>.</p>
<ul>
<li><p>“Los peces vuelan” versus “los peces no vuelan”.</p></li>
<li><p>“Tomar agua es bueno para la salud” versus “tomar agua es perjudicial para la salud”.</p></li>
<li><p>“El paciente está sano” versus “el paciente está enfermo”.</p></li>
</ul>
<p><strong>Solución:</strong></p>
<ul>
<li><p><span class="math inline">\(H_0) \text{ Los peces no vuelan} \qquad H_1) \text{ Los peces vuelan}\)</span></p></li>
<li><p><span class="math inline">\(H_0) \text{ Tomar agua es bueno} \qquad H_1) \text{ Tomar agua es perjudicial}\)</span></p></li>
<li><p><span class="math inline">\(H_0) \text{ El paciente está sano} \qquad H_1) \text{ El paciente está enfermo}\)</span></p></li>
</ul>
</div>
<p>En la práctica, las hipótesis suelen centrarse en un parámetro poblacional: el peso medio de las cajas de tornillos manufacturadas en cierta fábrica, la proporción de fumadores en Argentina, el tiempo medio de espera entre colectivos de la misma línea, etcétera. De este modo, las hipótesis pasan a ser redactadas con notación matemática.</p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 7</strong></p>
</div>
<p>Según el envase, el tubo de papas Pringles tiene un peso neto de 124 gramos. Sin embargo, experiencias previas nos han llevado a sospechar que dicho peso medio es falso: suponemos que en realidad es menor. ¿Cuáles son las hipótesis a probar en este caso?</p>
<p><strong>Solución:</strong> Sea <span class="math inline">\(X\)</span> el peso de un tubo de papas Pringles y <span class="math inline">\(\mu\)</span> el verdadero peso medio de los tubos (en gramos). Luego: <span class="math display">\[H_0) \; \mu \geq 124 \qquad H_1) \; \mu &lt; 124\]</span></p>
</div>
<p>¿Por qué el ejemplo anterior considera el caso <span class="math inline">\(\mu &gt; 124\)</span> como parte de <span class="math inline">\(H_0\)</span> si el envase afirma que es exactamente igual a 124 gramos? Recordemos que las hipótesis deben ser <em>exhaustivas y mutuamente excluyentes</em>; es decir, su unión debe ser el total de casos posibles y su intersección debe ser vacía. Por lo tanto, el caso <span class="math inline">\(\mu &gt; 124\)</span> debe ser parte de alguna de las dos hipótesis. Como en el ejemplo se sospecha (<span class="math inline">\(H_1\)</span>) que el peso medio es menor al estipulado, entonces el caso en cuestión no puede pertenecer a <span class="math inline">\(H_1\)</span> y debe ir a <span class="math inline">\(H_0\)</span>. En otras palabras, un peso medio superior a 124 gramos también se consideraría parte del status quo.</p>
<p>Dicho esto, hemos visto en cursos anteriores que es posible definir un test donde <span class="math inline">\(H_0\)</span> sólo incluye una igualdad, y todo lo demás está contenido en <span class="math inline">\(H_1\)</span>. Efectivamente existen situaciones prácticas que ameritan esta alternativa.</p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 8</strong></p>
</div>
<p>Se tiene una moneda que se sospecha que no es equilibrada. ¿Cómo pueden formularse hipótesis que pongan a prueba esta sospecha?</p>
<p><strong>Solución:</strong> Sea <span class="math inline">\(X\)</span> una variable binaria cuyo éxito es “la moneda cae en cruz” y cuyo fracaso es “la moneda cae en cara”. Sea <span class="math inline">\(p\)</span> la verdadera proporción de veces que la moneda cae en cruz. Una moneda equilibrada verifica <span class="math inline">\(p=0,5\)</span>. Por lo tanto: <span class="math display">\[H_0) \; p = 0,5 \qquad H_1) \; p \neq 0,5\]</span></p>
</div>
<p>Cualquiera sea el caso, debe seguirse la siguiente regla: <strong>la igualdad siempre forma parte de <span class="math inline">\(H_0\)</span></strong>.</p>
<p>Cuando existe una competencia entre estas dos teorías, porque algunas personas creen en la hipótesis nula y otras en la hipótesis alternativa, es común realizar una <strong>prueba de hipótesis</strong>: se utiliza información muestral para intentar decidir cuál es la verdadera. La estadística adopta en estos casos la <strong>presunción de inocencia</strong>: se optará por creer que la hipótesis nula es cierta, a menos que se tenga suficiente información para demostrar lo contrario. Pero ¿cómo podemos demostrar lo que ocurre en una población a través de una muestra? ¿Es infalible este método?</p>
</section>
<section id="error" class="level3">
<h3 class="anchored" data-anchor-id="error">Error</h3>
<p>Si lanzamos una moneda al aire diez veces y registramos la cara superior, obteniendo 7 caras y 3 cruces, ¿podríamos sospechar que la moneda no está equilibrada? Después de todo, si lo estuviese, sería de esperar que se obtenga “cara” el 50% de las veces, no el 70%. El problema está en que la práctica no refleja fielmente la teoría. Recordemos la definición frecuencial de probabilidad: nos dice que la frecuencia relativa de un evento aleatorio <span class="math inline">\(A\)</span> tenderá a acercarse a <span class="math inline">\(P(A)\)</span> a medida que el número de repeticiones tiende a infinito.</p>
<p>En la práctica nunca tenemos un número infinito de repeticiones o un tamaño muestral infinito. Debemos inferir mediante un número limitado de observaciones. Por lo tanto, debemos acostumbrarnos al hecho de que el valor de nuestra estimación probablemente no sea una réplica exacta del verdadero parámetro de interés.</p>
<p>La pregunta del millón es entonces: ¿qué tamaño muestral es suficientemente grande como para saber con certeza si nuestros datos avalan o refutan la hipótesis planteada inicialmente? Lamentablemente, la respuesta es “ninguno”: no hay tamaño muestral que nos dé certeza.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> Sin importar cuán fuerte parezca ser la evidencia muestral (a favor o en contra de una hipótesis), siempre existe la posibilidad de que dicha “evidencia” sea azarosa.</p>
<ul>
<li>Podemos entrevistar a mil rosarinos adultos y observar que el 80% de ellos no tiene licencia de conducir, cuando en realidad la verdadera proporción de rosarinos sin licencia de conducir podría ser 10%.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></li>
</ul>
<ul>
<li>Si de una caja opaca que contiene cinco canicas azules y una roja extraemos cien canicas con reposición, existe la posibilidad de que saquemos cien veces la canica roja y nos convenzamos de que la caja contiene sólo canicas rojas.</li>
</ul>
<p>En otras palabras, al hacer inferencia estadística siempre existe la posibilidad de cometer un <strong>error</strong>.</p>
</section>
<section id="tipos-de-error" class="level3">
<h3 class="anchored" data-anchor-id="tipos-de-error">Tipos de error</h3>
<p>Existe una dicotomía en la teoría y otra en la práctica: nuestra suposición inicial (<span class="math inline">\(H_0\)</span>) será cierta o no lo será; y nuestra información muestral respaldará la hipótesis nula o no lo hará. Hay dos posibilidades en la teoría y dos posibilidades en la práctica: en total existen cuatro escenarios posibles en los que podríamos estar parados.</p>
<div class="flexcenter">
<div class="half blackborder">
<table class="table">
<thead>
<tr class="header">
<th>Evidencia muestral</th>
<th><span class="math inline">\(H_0\)</span> cierta</th>
<th><span class="math inline">\(H_1\)</span> cierta</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Avala <span class="math inline">\(H_0\)</span></td>
<td>Ok</td>
<td>Error tipo II</td>
</tr>
<tr class="even">
<td>Avala <span class="math inline">\(H_1\)</span></td>
<td>Error tipo I</td>
<td>Ok</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li><p><strong>Error tipo I</strong> (<span class="math inline">\(e_I\)</span>): sucede cuando rechazamos la hipótesis nula (en base a la evidencia muestral) pero en realidad ésta es verdadera.</p></li>
<li><p><strong>Error tipo II</strong> (<span class="math inline">\(e_{II}\)</span>): sucede cuando no rechazamos la hipótesis nula pero en realidad deberíamos.</p></li>
</ul>
<p>Dependiendo del problema, un error puede ser más peligroso de cometer que el otro.</p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 9</strong></p>
</div>
<p>Para cada par de hipótesis a continuación, determine cuál error es más peligroso de cometer.</p>
<ul>
<li><p><span class="math inline">\(H_0) \text{ El paracaídas abre} \qquad H_1) \text{ El paracaídas no abre}\)</span></p></li>
<li><p><span class="math inline">\(H_0) \text{ El acusado es inocente} \qquad H_1) \text{ El acusado es culpable}\)</span></p></li>
<li><p><span class="math inline">\(H_0) \text{ El fármaco no tiene efectos colaterales} \quad H_1) \text{ El fármaco tiene efectos colaterales}\)</span></p></li>
<li><p><span class="math inline">\(H_0) \text{ No va a llover} \qquad H_1) \text{ Va a llover}\)</span></p></li>
</ul>
<p><strong>Solución:</strong></p>
<ul>
<li><p><span class="math inline">\(e_{II}\)</span>: decir que abre cuando en realidad no abre.</p></li>
<li><p><span class="math inline">\(e_I\)</span>: decir que es culpable cuando en realidad es inocente.</p></li>
<li><p><span class="math inline">\(e_{II}\)</span>: decir que no tiene efectos colaterales cuando en realidad los tiene.</p></li>
<li><p><span class="math inline">\(e_{II}\)</span>: decir que no va a llover cuando en realidad va a llover.</p></li>
</ul>
</div>
<p>Generalmente se desea defender el punto de vista predominante (es decir, el status quo: <span class="math inline">\(H_0\)</span>) porque introducir cambios en algún proceso suele ser una tarea costosa en tiempo, dinero y recursos. Estadísticamente, una manera de “proteger” la hipótesis nula es mediante un procedimiento que asegure una pequeña probabilidad de cometer un error tipo I: <span class="math inline">\(P(e_I)\)</span>.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>Dado que tanto <span class="math inline">\(P(e_I)\)</span> como <span class="math inline">\(P(e_{II})\)</span> representan chances de cometer errores, idealmente deseamos que ambas probabilidades sean lo más pequeñas posibles. Desafortunadamente, cuando el número de observaciones <span class="math inline">\(n\)</span> es fijo, no podemos controlar ambas probabilidades. Por eso nos centramos en <span class="math inline">\(P(e_I)\)</span>.</p>
<p>La única forma de reducir ambos errores es aumentando el tamaño muestral.</p>
</div>
</div>
<p>Sabiendo que no podemos anular la probabilidad de cometer un error, debemos definir un umbral o cota superior para <span class="math inline">\(P(e_I)\)</span>, de forma tal que estemos cómodos sabiendo que la probabilidad de cometer un error tipo I será menor o a lo sumo igual a la cota. Dicho valor se denomina <strong>nivel de significación</strong>: <span class="math inline">\(\alpha \in (0 \,;\, 1)\)</span>. Este valor es definido por el/la investigador/a <em>antes</em> de obtener los datos y llevar a cabo el análisis correspondiente. Valores usuales para <span class="math inline">\(\alpha\)</span> son 0,01; 0,05 y 0,10.</p>
<p>De esta manera se tiene: <span class="math display">\[P(e_I) = P(\text{rechazar }H_0 \;|\; H_0 \text{ cierta}) \leq \alpha\]</span></p>
<p>Una vez impuesta esa condición, existen múltiples metodologías que podrían proponerse para poner a prueba las hipótesis de interés. Los tests de hipótesis tradicionales (que estudiaremos en este curso) son aquellos que, dada la restricción anterior, maximizan la <strong>potencia del test</strong>: <span class="math inline">\(1-\beta = 1-P(e_{II})\)</span>.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
</section>
<section id="p-value" class="level3">
<h3 class="anchored" data-anchor-id="p-value">p-value</h3>
<p>Hasta ahora hemos definido las reglas teóricas bajo las cuales se construyen los tests de hipótesis que emplearemos en esta unidad. Todavía falta contestar una pregunta importante: ¿qué criterio emplear en la práctica para aceptar una hipótesis y rechazar la otra?</p>
<p>Como ya se dijo, al aplicar un test se implementa como principio la presunción de inocencia: se toma el status quo (<span class="math inline">\(H_0\)</span>) como realidad hasta que se demuestre lo contrario. Este <em>mindset</em> nos conduce a una estrategia matemática para abordar la prueba de hipótesis: si nuestra muestra resulta en un valor que sería muy improbable de observar bajo <span class="math inline">\(H_0\)</span>,<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> entonces sería sensato suponer que estamos bajo <span class="math inline">\(H_1\)</span>.</p>
<p>Podemos usar este resultado para proponer la siguiente regla de decisión:</p>
<ul>
<li><strong>Propuesta inicial:</strong> en base a la muestra, si <span class="math inline">\(P(\text{observar lo observado} \;|\; H_0 \text{ cierta}) \leq \alpha\)</span> entonces se rechaza <span class="math inline">\(H_0\)</span>.</li>
</ul>
<p>⚠️ La conclusión anterior es un paso en la dirección correcta. Pero aún presenta un problema, como se ve en el ejemplo siguiente.</p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 10</strong></p>
</div>
<p>Se tiene una moneda y se quiere probar si es equilibrada. Para ello se la arroja al aire un total de 1000 veces, cayendo 500 veces sobre cara y 500 veces sobre cruz. Suponiendo que la moneda es equilibrada, ¿cuál sería la probabilidad de observar este resultado?</p>
<p><strong>Solución:</strong> Sea <span class="math inline">\(X\)</span> el número de cruces obtenidas tras 1000 lanzamientos de la moneda. Es fácil ver que la variable sigue una distribución Binomial, con parámetro <span class="math inline">\(n=1000\)</span>. ¿Cuál es el valor del parámetro <span class="math inline">\(p\)</span>? Si suponemos que la moneda es equilibrada, entonces sería <span class="math inline">\(p=0,5\)</span>. ¿Cuál es, entonces, la probabilidad de obtener 500 cruces?</p>
<p><span class="math display">\[X \sim Bi(n=1000 \;,\; p=0,5) \implies P(X=500) = \binom{1000}{500} \left(\frac{1}{2}\right)^{1000} \approx 0,0252 = 2,52\%\]</span></p>
</div>
<p>Cuando una variable puede tomar muchos valores distintos, la probabilidad de cada uno de ellos tiende a ser baja. Esto puede llevar a un resultado que desafía la intuición: incluso teniendo una moneda equilibrada, la probabilidad de observar un resultado perfecto tras <span class="math inline">\(n=1000\)</span> réplicas es muy bajo. Para el ejemplo dado, nótese que rechazaríamos la hipótesis nula en todos los resultados posibles. ¡Incluso el que la refleja a la perfección! Para las variables continuas es incluso peor, porque se tendría <span class="math inline">\(P(X=x)=0\)</span> en todos los casos, independientemente del tamaño de la muestra y los valores observados.</p>
<p>Claramente no podemos basar nuestra decisión en la probabilidad puntual del evento observado. Algo que hemos aprendido de trabajar con variables aleatorias continuas es que a veces tiene más sentido calcular la probabilidad de un <em>intervalo</em> o conjunto de valores. Surge entonces la siguiente regla:</p>
<ul>
<li><strong>Propuesta nueva:</strong> si <span class="math inline">\(P(\text{observar lo observado o algo más extremo} \;|\; H_0 \text{ cierta}) \leq \alpha\)</span> entonces se rechaza <span class="math inline">\(H_0\)</span>.</li>
</ul>
<p>¿Qué significa “algo más extremo”? Nos referimos a cualquier resultado que, respecto a lo observado, se encuentre en dirección a la hipótesis alternativa <span class="math inline">\(H_1\)</span>. Esto depende de la <em>lateralidad</em> del test.</p>
<ul>
<li><p><span class="math inline">\(H_1) \; \theta &lt; \theta_0 \iff\)</span> test unilateral por izquierda</p></li>
<li><p><span class="math inline">\(H_1) \; \theta &gt; \theta_0 \iff\)</span> test unilateral por derecha</p></li>
<li><p><span class="math inline">\(H_1) \; \theta \neq \theta_0 \iff\)</span> test bilateral</p></li>
</ul>
<p>Entonces:</p>
<ul>
<li><p>Si el test es <strong>unilateral por izquierda</strong>, se calcula <span class="math inline">\(P(\hat{\theta} \leq \hat{\theta}_o \;|\; H_0 \text{ cierta}) = P(\hat{\theta} \leq \hat{\theta}_o \;|\; \theta = \theta_0)\)</span>.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p></li>
<li><p>Si es <strong>unilateral por derecha</strong>, se calcula <span class="math inline">\(P(\hat{\theta} \geq \hat{\theta}_o \;|\; H_0 \text{ cierta}) = P(\hat{\theta} \geq \hat{\theta}_o \;|\; \theta = \theta_0)\)</span>.</p></li>
<li><p>Si es <strong>bilateral</strong>, se calcula <span class="math inline">\(P[(|\hat{\theta} - \theta| \geq |\hat{\theta}_o - \theta|) \;|\; H_0 \text{ cierta}] = P[(|\hat{\theta} - \theta| \geq |\hat{\theta}_o - \theta|) \;|\; \theta=\theta_0]\)</span>.</p></li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>Nótese que en los tests unilaterales la probabilidad condicional se calcula asumiendo <span class="math inline">\(\theta = \theta_0\)</span> cuando en realidad la hipótesis nula plantea <span class="math inline">\(\theta \geq \theta_0\)</span> ó <span class="math inline">\(\theta \leq \theta_0\)</span> según el caso. Esto es una convención de los tests de hipótesis: se usa la igualdad para calcular la probabilidad, si bien la hipótesis original puede contemplar más valores.</p>
</div>
</div>
<p>En el siguiente ejemplo se ilustran todos estos casos en simultáneo.</p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 11</strong></p>
</div>
<p>Se arroja una moneda al aire un total de 100 veces, cayendo 63 veces sobre cara y 37 veces sobre cruz. Para cada test que podría plantearse (unilateral por izquierda, por derecha y bilateral) determine si rechazaría o no la hipótesis nula, utilizando un nivel de significación <span class="math inline">\(\alpha = 0,05\)</span>.</p>
<p><strong>Solución:</strong> Sabemos por el ejemplo anterior que la variable bajo estudio (digamos que es “número de cruces”) es Binomial. A continuación se plantea la probabilidad de observar lo observado <em>o algo más extremo</em> para cada test posible.</p>
<ul>
<li><strong>Caso 1:</strong> test unilateral por izquierda (<span class="math inline">\(H_0)\; p \geq 0,5\)</span> versus <span class="math inline">\(H_1)\; p &lt; 0,5\)</span>)</li>
</ul>
<p><span class="math display">\[P(\hat{p} \leq \tfrac{37}{100} \;|\; p = 0,5) = \sum_{x=0}^{37} \binom{100}{x} \left(\frac{1}{2}\right)^{100} \approx 0,006 &lt; \alpha \implies \text{Rechazo } H_0\]</span></p>
<ul>
<li><strong>Caso 2:</strong> test unilateral por derecha (<span class="math inline">\(H_0)\; p \leq 0,5\)</span> versus <span class="math inline">\(H_1)\; p &gt; 0,5\)</span>)</li>
</ul>
<p><span class="math display">\[P(\hat{p} \geq \tfrac{37}{100} \;|\; p = 0,5) = \sum_{x=37}^{100} \binom{100}{x} \left(\frac{1}{2}\right)^{100} \approx 0,997 &gt; \alpha \implies \text{No rechazo } H_0\]</span></p>
<ul>
<li><strong>Caso 3:</strong> test bilateral (<span class="math inline">\(H_0)\; p = 0,5\)</span> versus <span class="math inline">\(H_1)\; p \neq 0,5\)</span>)</li>
</ul>
<p><span class="math display">\[P(|\hat{p} - \tfrac{50}{100}| \geq |\tfrac{37}{100} - \tfrac{50}{100}|) = P(|X - 50| \geq 13) = P(X \leq 37) + P(X \geq 63) \approx\]</span></p>
<p><span class="math display">\[ \approx 0,006 + 0,006 = 0,012 &lt; \alpha \implies \text{Rechazo } H_0\]</span></p>
</div>
<p>La probabilidad calculada funciona como esperábamos: rechaza o acepta la hipótesis nula de forma sensata en base a la información muestral. Esta herramienta es ampliamente utilizada en Estadística y se la conoce como <strong>p-value</strong>.</p>
<p><span class="math display">\[\text{p-value} = P(\text{observar lo observado o algo más extremo} \;|\; H_0 \text{ cierta})\]</span> Así, la regla de decisión se reduce a: <span class="math inline">\(\text{p-value} \leq \alpha \implies \text{ Rechazo } H_0\)</span>.</p>
</section>
<section id="tests-basados-en-observaciones-individuales" class="level3">
<h3 class="anchored" data-anchor-id="tests-basados-en-observaciones-individuales">Tests basados en observaciones individuales</h3>
<p>Si conocemos la distribución de la variable bajo estudio podemos llevar a cabo un test de hipótesis con una sola observación, equivalente a una muestra de tamaño <span class="math inline">\(n=1\)</span>. Esto podemos aplicarlo a cualquiera de las distribuciones de probabilidad que conocemos.</p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 12</strong></p>
</div>
<p>Un hombre apareció muerto de un disparo mientras cazaba en una zona boscosa de Chubut. Se hizo pasar como un accidente, pero la policía interrogó a otro cazador que, según se supo, tuvo un altercado con la víctima. Ellos encontraron una hoja de pino en el saco del sospechoso. El acusado afirmó que estuvo cazando en Salta el día del incidente.</p>
<p>El bosque de Chubut tiene sólo pinos de la especie A y Salta sólo pinos de la especie B. Las hojas tipo aguja de la especie A tienen longitudes distribuidas Normalmente con una media de 5,4 cm y un desvío de 0,4 cm; mientras que las de la especie B también se distribuyen Normalmente pero con una media de 6,4 cm y un desvío de 0,5 cm.</p>
<p>El acusador lo contrata a usted como experto estadístico. La hoja de pino hallada en el saco del sospechoso mide 5,42 cm. En base a esto, ¿qué concluiría? Utilice <span class="math inline">\(\alpha = 0,05\)</span>.</p>
<p><strong>Solución:</strong> El primer paso es postular las hipótesis, a partir de la presunción de inocencia. Sea <span class="math inline">\(X\)</span> la longitud (en centímetros) de la hoja en el saco del sospechoso. Sabemos que la distribución de la variable es Normal, pero no sabemos si sus parámetros corresponden a la especie A o a la especie B.</p>
<p>Si el hombre fuese inocente, la hoja pertenecería a la especie B, cuyas longitudes son mayores. En cambio, si fuese culpable, la hoja pertenecería a la especie A, cuyas longitudes son menores. Por lo tanto planteamos:</p>
<p><span class="math display">\[H_0)\; \mu \geq \mu_B = 6,4 \quad\text{ versus }\quad H_1)\; \mu &lt; \mu_B = 6,4\]</span></p>
<p>Luego, bajo la hipótesis nula se tiene que: <span class="math display">\[X \sim_{H_0} N(\mu = 6,4 \;;\; \sigma = 0,5)\]</span></p>
<p>Por lo tanto: <span class="math inline">\(P(X \leq 5,42) =\)</span> <code>pnorm(5.42, mean = 6.4, sd = 0.5)</code> <span class="math inline">\(\approx 0,025 &lt; 0,05 = \alpha\)</span>.</p>
<p>En base a la evidencia muestral, y con un nivel de significación <span class="math inline">\(\alpha=0,05\)</span>, se puede concluir que la hoja encontrada en el saco del sospechoso no pertenece a la especie B.</p>
</div>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 13</strong></p>
</div>
<p>Tras escribir el borrador de nuestra primera novela, decidimos contactar a un traductor para que convierta el texto a inglés. La persona que contratamos es muy veloz pero nos advierte que suele cometer errores tipográficos, y que el número de errores por página sigue una distribución Poisson con parámetro <span class="math inline">\(\lambda = 1,5\)</span>.</p>
<p>Tras terminar la traducción, nos envía el borrador en inglés. Nosotros abrimos una página al azar y rápidamente detectamos 4 errores tipográficos. ¿Es esto evidencia suficiente para reclamar al traductor que está cometiendo más errores de los que admite? Utilice <span class="math inline">\(\alpha = 0,05\)</span>.</p>
<p><strong>Solución:</strong> Sea <span class="math inline">\(X\)</span> el número de errores tipográficos en una hoja. En base a la honestidad o no honestidad del traductor, podemos plantear:</p>
<p><span class="math display">\[H_0)\; \lambda \leq 1,5 \quad\text{ versus }\quad H_1)\; \lambda &gt; 1,5\]</span></p>
<p>Luego, bajo la hipótesis nula se tiene que: <span class="math display">\[X \sim_{H_0} Po(\lambda = 1,5)\]</span></p>
<p>Por lo tanto: <span class="math inline">\(P(X \geq 4) =\)</span> <code>1 - ppois(3, lambda = 1.5)</code> <span class="math inline">\(\approx 0,066 &gt; 0,05 = \alpha\)</span>.</p>
<p>En base a la evidencia muestral, y con un nivel de significación <span class="math inline">\(\alpha=0,05\)</span>, no se puede rechazar la hipótesis de que el traductor está siendo honesto.</p>
</div>
<p>Por otro lado, cuando contamos no con una única observación sino con una muestra, debemos hacer uso de las distribuciones muestrales.</p>
</section>
<section id="test-para-la-media-mu" class="level3">
<h3 class="anchored" data-anchor-id="test-para-la-media-mu">Test para la media (<span class="math inline">\(\mu\)</span>)</h3>
<p>En base a lo visto en la unidad anterior y en la sección sobre intervalos de confianza, hay esencialmente 3 casos distintos en los que podemos plantear un test de hipótesis para la media poblacional.</p>
<ul>
<li><strong>Caso 1 (distribución Normal, <span class="math inline">\(\sigma\)</span> conocido):</strong> lo siguiente se cumple para cualquier tamaño muestral.</li>
</ul>
<p><span class="math display">\[\overline{X} \sim N\left( \mu_0, \frac{\sigma_0}{\sqrt{n}} \right)\]</span></p>
<p>En esta notación, <span class="math inline">\(\mu_0\)</span> y <span class="math inline">\(\sigma_0\)</span> son los valores de los parámetros propuestos bajo la hipótesis nula.</p>
<ul>
<li><p><strong>Caso 2 (distribución Normal, <span class="math inline">\(\sigma\)</span> desconocido):</strong> lo siguiente se cumple para cualquier tamaño muestral. <span class="math display">\[T = \frac{\overline{X} - \mu_0}{S / \sqrt{n}} \sim t_{n-1}\]</span></p></li>
<li><p><strong>Caso 3 (distribución desconocida):</strong> lo siguiente se cumple para muestras grandes (<span class="math inline">\(n \geq 30\)</span>).<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p></li>
</ul>
<p><span class="math display">\[\overline{X} \stackrel{TCL}{\sim} N\left( \mu_0, \frac{\sigma_0}{\sqrt{n}} \right)\]</span></p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 14</strong></p>
</div>
<p>Ramón sospecha que los profesores de su escuela técnica tienen, en promedio, menos de 5 años de experiencia. Para poner a prueba su sospecha toma una muestra aleatoria de 25 profesores. La media de su muestra fue de 4 años y el desvío estándar fue de 2 años. Suponiendo que la variable en cuestión es Normal y utilizando <span class="math inline">\(\alpha=0,05\)</span>, ¿qué debería concluir?</p>
<p><strong>Solución:</strong> Se plantean las hipótesis:</p>
<p><span class="math display">\[H_0)\; \mu \geq 5 \quad\text{ versus }\quad H_1)\; \mu &lt; 5\]</span></p>
<p>Luego, bajo la hipótesis nula se tiene que: <span class="math display">\[T = \frac{\overline{X} - 5}{S / \sqrt{25}} \sim_{H_0} t_{24}\]</span></p>
<p>Por lo tanto: <span class="math inline">\(P(T \leq \tfrac{4-5}{2/5}) = P(T \leq -2,5) =\)</span> <code>pt(-2.5, df=24)</code> <span class="math inline">\(\approx 0,0098 &lt; \alpha\)</span></p>
<p>En base a la evidencia muestral, y con un nivel de significación <span class="math inline">\(\alpha=0,05\)</span>, se rechaza la hipótesis de que la experiencia media en la escuela técnica es, al menos, 5 años.</p>
</div>
</section>
<section id="test-para-la-diferencia-de-medias-mu_1---mu_2" class="level3">
<h3 class="anchored" data-anchor-id="test-para-la-diferencia-de-medias-mu_1---mu_2">Test para la diferencia de medias (<span class="math inline">\(\mu_1 - \mu_2\)</span>)</h3>
<ul>
<li><strong>Caso 1 (distribución Normal):</strong> lo siguiente se cumple para cualquier tamaño muestral.</li>
</ul>
<p><span class="math display">\[\overline{X}_1 - \overline{X}_2 \sim N \left( \mu_1 - \mu_2 \,;\, \frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2} \right)\]</span></p>
<p>Aunque no se vea reflejado en la notación, los valores de los parámetros son los propuestos bajo <span class="math inline">\(H_0\)</span>.</p>
<ul>
<li><strong>Caso 2 (distribución desconocida ó <span class="math inline">\(\sigma\)</span> desconocido):</strong> aplica para muestras grandes (<span class="math inline">\(n \geq 30\)</span>).</li>
</ul>
<p><span class="math display">\[\overline{X}_1 - \overline{X}_2 \stackrel{TCL}{\sim} N \left( \mu_1 - \mu_2 \,;\, \frac{s^2_1}{n_1} + \frac{s^2_2}{n_2} \right)\]</span></p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 15</strong></p>
</div>
<p>Carla sospecha que, mientras más ejercicio hacen las personas, mayor temperatura toma su cuerpo. Asignó aleatoriamente a unas personas para que ejercitaran durante media hora y otras durante una hora.</p>
<p>Las 54 personas que ejercitaron durante media hora tuvieron una temperatura media de 38,3 °C con un desvío estándar de 0,97 °C. Las 72 personas que entrenaron durante una hora tuvieron una temperatura media de 38,9 °C con un desvío estándar de 1,09 °C.</p>
<p>Utilizando <span class="math inline">\(\alpha=0,05\)</span>, ¿concluiría que las temperaturas difieren según el tiempo de ejercicio?</p>
<p><strong>Solución:</strong> Se plantean las hipótesis:</p>
<p><span class="math display">\[H_0)\; \mu_{30'} = \mu_{60'} \quad\text{ versus }\quad H_1)\; \mu_{30'} \neq \mu_{60'}\]</span></p>
<p>Luego, bajo la hipótesis nula se tiene que: <span class="math display">\[\overline{X}_{30'} - \overline{X}_{60'} \sim_{H_0} N \left( 0 \,;\, \sqrt{\frac{0,97^2}{54} + \frac{1,09^2}{72}} \right)\]</span></p>
<p>Por lo tanto: <span class="math inline">\(\text{p-value} = P(\overline{X}_{30'} - \overline{X}_{60'} \leq -0,6) + P(\overline{X}_{30'} - \overline{X}_{60'} \leq -0,6)\)</span>.</p>
<ul>
<li><p><span class="math inline">\(P(\overline{X}_{30'} - \overline{X}_{60'} \leq -0,6) =\)</span> <code>pnorm(-0.6, sd = sqrt(0.97**2/54 + 1.09**2/72))</code> <span class="math inline">\(\approx 0,00056\)</span></p></li>
<li><p><span class="math inline">\(P(\overline{X}_{30'} - \overline{X}_{60'} \geq 0,6) =\)</span> <code>1-pnorm(0.6, sd = sqrt(0.97**2/54 + 1.09**2/72))</code> <span class="math inline">\(\approx 0,00056\)</span></p></li>
</ul>
<p>Finalmente: <span class="math inline">\(\text{p-value} = 0,00056 + 0,00056 = 0,00112 &lt; \alpha\)</span></p>
<p>En base a la evidencia muestral, y con un nivel de significación <span class="math inline">\(\alpha=0,05\)</span>, se rechaza la hipótesis de que el tiempo de entrenamiento no afecta la temperatura corporal.</p>
</div>
</section>
<section id="test-para-la-proporción-p" class="level3">
<h3 class="anchored" data-anchor-id="test-para-la-proporción-p">Test para la proporción (<span class="math inline">\(p\)</span>)</h3>
<p>Para muestras grandes se tiene <span class="math display">\[\hat{p} \stackrel{TCL}{\sim} N \left( p_0 \,;\, \frac{p_0(1-p_0)}{n} \right)\]</span> donde <span class="math inline">\(p_0\)</span> es el valor de <span class="math inline">\(p\)</span> postulado bajo <span class="math inline">\(H_0\)</span>.</p>
<div class="examplebox">
<div class="center">
<p><strong>Ejemplo 16</strong></p>
</div>
<p>El alcalde de una ciudad leyó un artículo que afirmaba que la tasa de desempleo a nivel nacional es del 8%. Para determinar si esto también se aplica en su ciudad tomó una muestra de 200 residentes. La muestra incluyó 22 residentes desempleados. Utilizando <span class="math inline">\(\alpha=0,05\)</span>, ¿qué debería concluir?</p>
<p><strong>Solución:</strong> Se plantean las hipótesis:</p>
<p><span class="math display">\[H_0)\; p = 0,08 \quad\text{ versus }\quad H_1)\; p \neq 0,08\]</span></p>
<p>Luego, bajo la hipótesis nula se tiene que: <span class="math display">\[\hat{p} \sim_{H_0} N \left( \mu=0,08 \,;\, \sigma^2=\frac{0,08 \cdot 0,92}{200} \right)\]</span></p>
<p>El valor del estimador fue <span class="math inline">\(\hat{p}_o = 22/200 = 0,11\)</span>.</p>
<p>Por lo tanto: <span class="math inline">\(P(\hat{p} \geq 0,11) + P(\hat{p} \leq 0,05)\)</span>. Luego:</p>
<ul>
<li><p><span class="math inline">\(P(\hat{p} \geq 0,11) =\)</span> <code>1 - pnorm(0.11, mean = 0.08, sd = sqrt(0.08*0.92/200))</code> <span class="math inline">\(\approx 0,059\)</span></p></li>
<li><p><span class="math inline">\(P(\hat{p} \leq 0,05) =\)</span> <code>pnorm(0.05, mean = 0.08, sd = sqrt(0.08*0.92/200))</code> <span class="math inline">\(\approx 0,059\)</span></p></li>
</ul>
<p>Finalmente: <span class="math inline">\(\text{p-value} = 0,059 + 0,059 = 0,118 &gt; \alpha\)</span></p>
<p>En base a la evidencia muestral, y con un nivel de significación <span class="math inline">\(\alpha=0,05\)</span>, no se puede rechazar la hipótesis de que la tasa de desempleo en la ciudad es del 8%.</p>
</div>
</section>
</section>
<section id="ic-test-de-hipótesis" class="level2">
<h2 class="anchored" data-anchor-id="ic-test-de-hipótesis">¿IC = Test de hipótesis?</h2>
<p>Llegado este punto, es probable que hayan detectado muchas similitudes entre la construcción de un intervalo de confianza y la de un test de hipótesis. De hecho, la teoría detrás de cada uno es la misma: se definen a partir de las distribuciones muestrales del estimador de interés.</p>
<p>Más aún, existe una relación entre la determinación de una confianza <span class="math inline">\(1-\alpha\)</span> para un intervalo y la de un nivel de significación <span class="math inline">\(\alpha\)</span> para un test. La relación es la siguiente:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Relación entre ICs y tests de hipótesis
</div>
</div>
<div class="callout-body-container callout-body">
<p>Supóngase un test de hipótesis bilateral: <span class="math inline">\(H_0)\; \theta = \theta_0\)</span> versus <span class="math inline">\(H_1)\; \theta \neq \theta_0\)</span>. Para un cierto nivel de significación <span class="math inline">\(\alpha \in (0 \;;\; 1)\)</span>, si se construye un intervalo de confianza del <span class="math inline">\(100(1-\alpha)\%\)</span> para el parámetro <span class="math inline">\(\theta\)</span> y éste no contiene al valor <span class="math inline">\(\theta_0\)</span>, esto es equivalente a un rechazo de la hipótesis nula.</p>
<p>En otras palabras, podemos plantear un test de hipótesis <strong>bilateral</strong> mediante un intervalo de confianza.</p>
</div>
</div>
<p>Recordemos que una de las interpretaciones de “confianza” es la probabilidad de que el intervalo incluya al verdadero valor del parámetro. Por ejemplo, se tiene un 95% de confianza de que el intervalo <span class="math inline">\([a;b]\)</span> contiene al verdadero valor de <span class="math inline">\(\theta\)</span>. Si el valor <span class="math inline">\(\theta_0\)</span> postulado por la hipótesis nula no está contenido en el intervalo, esto implica que probablemente la muestra no haya provenido de una distribución con <span class="math inline">\(\theta=\theta_0\)</span>, y por lo tanto habría que rechazar esa hipótesis nula.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-fisher" class="csl-entry" role="listitem">
Wikipedia. 2024. <span>«Lady tasting tea - Wikipedia, The Free Encyclopedia»</span>. <a href="https://en.wikipedia.org/wiki/Lady_tasting_tea">https://en.wikipedia.org/wiki/Lady_tasting_tea</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Nótese la negrita en la <span class="math inline">\(\mathbf{x}\)</span>. Esto es para representar el vector de valores muestrales observados: <span class="math inline">\(\mathbf{x} = (x_1, x_2, \cdots, x_n)\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Una vez tomada la muestra, los extremos del intervalo ya no son variables aleatorias sino números fijos. Por lo tanto, cuando esto ocurre la proabbilidad de que el verdadero valor del parámetro esté contenido en el intervalo es 0 ó 1: el intervalo contiene al parámetro, o bien no lo contiene (aunque nunca sabremos en cuál caso nos encontramos).<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Existen distribuciones muestrales para la diferencia de medias con poblaciones Normales, variancias desconocidas y muestras pequeñas. Hemos optado por excluirlas del contenido de esta materia, visto que traen aparejadas cierta complejidad matemática y corresponden a un escenario que no suele darse con frecuencia en la práctica.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Acá estamos asumiendo que nuestra población es infinita. En el caso de una población finita (por ejemplo: los habitantes de Argentina) podemos tener certeza si el tamaño muestral es igual al tamaño poblacional: <span class="math inline">\(n=N\)</span>. Esto sería equivalente a un censo en el que todos los individuos responden y nadie miente al responder (dos condiciones que difícilmente se dén en la práctica).<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Esto podría darse por falta de representatividad, pero incluso con una muestra perfectamente representativa puede darse este escenario simplemente por mala suerte.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Nótese lo que implica esta definición: la potencia del test es la probabilidad de rechazar <span class="math inline">\(H_0\)</span> sin error.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>La expresión “bajo <span class="math inline">\(H_0\)</span>” denota el hecho de estar ante un escenario donde la hipótesis <span class="math inline">\(H_0\)</span> es cierta.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Se utiliza la notación <span class="math inline">\(\hat{\theta}_o\)</span> para referirse al valor observado del estimador, mientras que <span class="math inline">\(\theta_0\)</span> refiere al valor del parámetro propuesto en la hipótesis nula.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>En este caso, si se desconoce el valor de <span class="math inline">\(\sigma\)</span> se usa este mismo resultado pero reemplazando el valor por <span class="math inline">\(s\)</span>: el desvío estándar muestral.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./3_infer.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">3. Inferencia estadística</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./5_series.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-title">5. Series de Tiempo</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>