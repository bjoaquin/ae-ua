```{r}
#| echo: FALSE
#| message: FALSE

library(tidyverse)

contador_ejemplos <- 0
```

# 2. Variable aleatoria

## Introducción

Un basquetbolista tiene una tasa de encestos del 60%. Esto implica que en un tiro al aro tiene un 60% de probabilidad de encestar y un 40% de fallar. ¿Cuál es la probabilidad de que deba lanzar dos veces para eventualmente encestar? Suponiendo que los tiros son independientes entre sí, la probabilidad de fallar el primer tiro y acertar el segundo es $0,4 \times 0,6 = 0,24$. ¿Cuál es la probabilidad de que deba lanzar tres veces para finalmente encestar? Siguiendo la misma lógica obtenemos $0,4 \times 0,4 \times 0,6 = 0,096$.

Podríamos seguir este procedimiento infinitamente: para cualquier número natural $n$ es posible calcular la probabilidad de que el basquetbolista falle los primeros $n-1$ tiros y finalmente enceste el último. De hecho, definiendo la variable

$$X: \text{ número de tiros que realiza el basquetbolista hasta encestar}$$

es fácil ver que la probabilidad de encestar en el $n$-ésimo tiro está dada por

$$P(X = n) = (0,4)^{n-1} \times 0,6 \qquad \forall \quad n \in \mathbb{N}.$$

Esta ecuación comprime de forma eficiente la información necesaria para calcular la chance de ocurrencia de cualquier resultado posible. De no tenerla, tendríamos que definir un evento para cada resultado.

-   $A$: el basquetbolista encesta al primer tiro $\implies A = \{(Si)\}$
-   $B$: el basquetbolista encesta al segundo tiro $\implies B = \{(No, Si)\}$
-   $C$: el basquetbolista encesta al tercer tiro $\implies C = \{(No, No, Si)\}$

$\cdots$

Es por ello que surgen las variables aleatorias.

## Variable aleatoria

Supóngase un experimento aleatorio sobre el que se define un espacio muestral $S$. Se llama **variable aleatoria** a la función $X$ que asigna a cada uno de los elementos $s \in S$ un número real $X(s)$.

En el ejemplo introductorio, el experimento aleatorio es "lanzar al aro hasta encestar" y el espacio muestral es $S=${(Sí), (No, Sí), (No, No, Sí), $\cdots$}. Bajo la definición ya dada para la variable aleatoria $X$, esta función no hace más que contar el número de tiros en cada resultado:

$$s = (Si) \implies X(s) = 1$$ $$s = (No, Si) \implies X(s) = 2$$ $$s = (No, No, Si) \implies X(s) = 3$$

::: callout-note
#### Nota

En el ejemplo introductorio se define $X$ como el "número de tiros hasta encestar". Nótese la diferencia entre una variable aleatoria y un evento aleatorio. El *evento* suele escribirse como una afirmación, valiéndose de un verbo (por ejemplo, "el dado arrojado **resulta** en un número par"). Como tal, un evento sólo admite dos resultados posibles: ocurrir o no ocurrir. En cambio, una *variable* es un atributo, el cual puede tomar múltiples valores.
:::

::: callout-note
#### Nota

Otra convención de la que hacemos uso es la distinción entre letras mayúsculas y minúsculas. Nótese cómo hemos usado la letra $S$ para referirnos al espacio muestral y la letra $s$ para referirnos a un elemento particular perteneciente a tal conjunto. Del mismo modo, reservaremos letras mayúsculas como $X$ para definir variables aleatorias y letras minúsculas como $x$ para referirnos a valores puntuales que éstas podrían asumir.
:::

Como a cada elemento del espacio muestral le corresponde un número real, es sensato preguntarse cuáles son todos los posibles números reales que podrían obtenerse en un cierto experimento. Dicho de otro modo, podríamos preguntarnos cuáles son todos los valores que puede tomar la variable $X$. Este conjunto se conoce como **recorrido** de $X$ y se simboliza con $R_X$.

$$R_X = \{x \in \mathbb{R} : X(s) = x \;;\; s \in S\}$$

Por ejemplo, para un experimento con sólo tres resultados posibles se tiene $S=\{s_1, s_2 ,s_3\}$ y por lo tanto $R_X = \{X(s_1), X(s_2), X(s_3)\}$. En el ejemplo del basquetbolista se tiene que $R_X = \mathbb{N}$, o sea que el número de tiros hasta encestar puede ser cualquier número natural. Algo interesante de este último caso es que el conjunto tiene infinitos elementos. En general, $R_X$ puede ser un conjunto:

* finito.
* infinito numerable.[^2_va-1]
* infinito no numerable.

[^2_va-1]: Algunos conjuntos infinitos permiten enumerar todos sus elementos, como sucede por ejemplo para el caso de los números naturales: $\mathbb{N} = \{1, 2, 3, \cdots\}$. Estos son ejemplos de infinitos numerables. Existen otros conjuntos infinitos, sin embargo, que no permiten tal enumeración. Un claro ejemplo son los números reales ($\mathbb{R}$). ¿Cuál es el primer número real? Incluso si comenzáramos en uno arbitrario (por ejemplo, 0) ¿cuál sería el siguiente? No existe una forma satisfactoria de enumerar los números reales, y por eso se los denomina "no numerables".

::: callout-warning
#### Advertencia

El tamaño de $S$ no siempre es igual al tamaño de $R_X$. Tómese como ejemplo el experimento de arrojar dos monedas al aire en simultáneo. El espacio muestral tiene cuatro elementos, porque $S=\{(C,C), (C,X), (X,C), (X,X)\}$, pero si definimos una variable aletoria $X$ que cuenta el número de cruces, se tiene que $R_X = \{0, 1, 2\}$. Esto es porque se tienen dos resultados del espacio muestral que bajo la función $X$ devuelven el mismo número real.
:::

## Tipos de variable aleatoria

Según la cardinalidad del recorrido de $X$ (es decir, según si $R_X$ es un conjunto finito, infinito numerable o infinito no numerable), una variable aleatoria puede clasificarse en uno de dos tipos: discreta o continua.

### Variable aleatoria discreta

Sea $X$ una v.a.[^2_va-2] definida sobre un espacio muestral $S$. Se dice que $X$ es una **variable aleatoria discreta** si su recorrido es un conjunto finito o infinito numerable.

[^2_va-2]: Por comodidad, en ocasiones adoptamos esta forma de abreviar "variable aleatoria".

Ejemplos de variables aleatorias discretas son los siguientes:

* Demanda de un cierto producto.
* Número de aces en un partido de tenis.
* Cantidad de senadores que votan en contra de una ley.
* Número de ventas anuales en Amazon.

Supongamos un recorrido $R_X = \{x_1, x_2, x_3, \cdots\}$ a lo sumo numerable. Para cada resultado posible $x_i$ puede asociarse un número $p(x_i) = P(X = x_i)$. Esta función es denominada **función de probabilidad puntual** de $X$.

La función $p(x)$ verifica dos propiedades importantes:

  1. $p(x) > 0 \quad \forall \quad x \in R_X$ (condición de positividad)
  2. $\sum_{x \in R_X} p(x) = 1$ (condición de cierre)

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Se arrojan 3 monedas equilibradas al aire y se registra para cada una si el resultado es cara o cruz. Sea $X$ la variable que registra el número de cruces obtenidas. Definir su función de probabilidad.

**Solución:**

* **Experimento aleatorio:** arrojar 3 monedas al aire y registrar la cara superior de cada una.
* **Espacio muestral:** $S = \{CCC, CCX, CXC, CXX, XCC, XCX, XXC, XXX\}$.
* **Ejemplo de resultado:** $s = CCX$.
* **Variable aleatoria:** $X$: número de cruces obtenidas.
* **Recorrido:** $R_X = \{0, 1, 2, 3\} \implies \#R_X = 4$ (finito).

La función de probabilidad surge de las siguientes probabilidades:

* $p(0) = P(X = 0) = P(s \in \{CCC\}) = \frac{1}{8}$
* $p(1) = P(X = 1) = P(s \in \{CCX, CXC, XCC\}) = \frac{3}{8}$
* $p(2) = P(X = 2) = P(s \in \{XXC, XCX, CXX\}) = \frac{3}{8}$
* $p(3) = P(X = 3) = P(s \in \{XXX\}) = \frac{1}{8}$

Nótese que se verifican tanto la condición de positividad como la de cierre:

1. Positividad: $\frac{3}{8} > \frac{1}{8} > 0$ (todos los resultados son positivos)
2. Cierre: $\frac{1}{8} + \frac{3}{8} + \frac{3}{8} + \frac{1}{8} = \frac{8}{8} = 1$
:::

Al conjunto de pares $(x, p(x))$ se lo llama **distribución de probabilidad** de la v.a. $X$, denotada como $X \sim p(x)$[^2_va-3]. Para una v.a. discreta existen tres formas de representar su distribución de probabilidad: como tabla, como gráfico o como fórmula.

[^2_va-3]: Se lee "$X$ se distribuye como una $p(x)$".

![Las tres formas de representar la distribución de probabilidad de una variable aleatoria discreta.](img/distrib_prob.png){#fig-distrib_prob}

### Variable aleatoria continua

Sea $X$ una v.a. definida sobre un espacio muestral $S$. Se dice que $X$ es una **variable aleatoria continua** si su recorrido es un conjunto infinito no numerable.

Ejemplos de variables aleatorias continuas son los siguientes:

* Producto Bruto Interno.
* Duración del vuelo AR1300 (EZE-JFK), en minutos.
* Valor del dólar en relación al precio argentino.

::: callout-note
#### Nota

Ante una variable aleatoria continua ya no podemos hablar de $x_i$, visto que no existe un $i$-ésimo valor de la variable.
:::

Para toda v.a. continua $X$ se tiene que $P(X=x) = 0$. Es decir que las probabilidades puntuales son todas nulas. Esta característica puede ser difícil de asimilar, puesto que va en contra de la intuición: ¿cómo puede ser que un valor *posible* tenga una probabilidad *nula* de ocurrir? La explicación formal involucra matemáticas cuya complejidad exceden los contenidos de este curso; es suficiente con decir que, bajo un escenario donde los resultados posibles tienen infinitos decimales, es improbable que se obtenga *exactamente* un cierto número previsto de antemano.

::: callout-warning
#### Advertencia

La noción de un "número con infinitos decimales" pareciera no aplicar a varios ejemplos de la vida cotidiana. Por ejemplo: si pesamos una sandía en una balanza, obtendremos a lo sumo tres (como mucho cuatro) decimales. Sin embargo, esta es una limitación impuesta por el instrumento de medición, no por la variable en sí misma. Si tuviéramos una balanza más precisa podríamos medir aún más decimales.

Este concepto también aplica cuando la limitación en los decimales es generada no por el instrumento de medición sino por el uso habitual o la relevancia. Por ejemplo: cuando alguien nos pregunta por nuestra altura es común que respondamos algo como "un metro setenta y dos", es decir, usando dos decimales. Incluso si nos midiésemos con una cinta métrica que tuviera más decimales, nuestra respuesta seguiría limitándose a dos.

Este redondeo por conveniencia aplica también a variables con decimales que cotidianamente redondeamos a números enteros. El ejemplo más claro es la edad. Tal número suele redondearse a "años cumplidos" y por lo tanto se la cuenta mediante números enteros, pero en realidad con cada segundo (incluso nanosegundo) que pasa nuestra edad va cambiando.
:::

¿Cómo podemos, entonces, medir probabilidades de ocurrencia sobre una variable en la cual cada valor puntual tiene probabilidad nula? En estos casos suele ser de interés la probabilidad de que la variable tome un valor dentro de un cierto *intervalo*. Así, se estudia la probabilidad de que $X$ tome un valor en un entorno de $x$, lo cual se logra con una función particular.

Se denomina **función de densidad de probabilidad** de $X$ a aquella función $f(x)$ que verifica:

1. $f(x)>0 \quad \forall \quad x \in R_X$ (condición de positividad)
2. $\int_{R_X} f(x) \; dx = 1$ (condición de cierre)

Es muy importante recordar que la función $f(x)$ no devuelve la probabilidad de ocurrencia del valor $X=x$. Como ya se dijo, dicha probabilidad sería nula. Más aún, la función $f(x)$ en ocasiones puede tomar valores mayores a 1, lo cual pone en evidencia que no mide probabilidades. Esta función es un mero intermediario para calcular una probabilidad, y para ello debe ser envuelta en una integral, como se muestra en el siguiente ejemplo.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Una empresa láctea vende sachets de yogur de un litro. La máquina que llena los envases no funciona a la perfección, por lo que el verdadero contenido de yogur puede variar entre envases. Se sabe que la variable "litros de yogur en un sachet" (llamémosla $X$) se distribuye siguiendo la función de densidad a continuación:
$$f(x) = K(4x - x^2) \qquad \forall \quad 0<x<2$$
¿Cuál es el valor del número real $K$?

**Solución:**

* **Experimento aleatorio:** usar la máquina para llenar un sachet de yogur.
* **Variable aleatoria:** $X$: litros de yogur en un sachet.
* **Recorrido:** $R_X = [0, 2] \subset \mathbb{R}$ (infinito no numerable).

Por condición de cierre:
$$\int_0^2 K(4x-2x^2) \; dx = K(2x^2 - \tfrac{2}{3}x^3) |_0^2 = K(8 - \tfrac{16}{3}) = \tfrac{8}{3} \implies K = \tfrac{3}{8}$$
:::

## Función de distribución

Sea $X$ una v.a. cualquiera (discreta o continua), llamamos **función de distribución acumulada** de $X$ a la función: $$F(x) = P(X \leq x) \quad \forall \quad x \in \mathbb{R}.$$ Es decir, esta función calcula la probabilidad de que $X$ tome el valor $x$ o cualquier valor menor a éste. De ahí la palabra "acumulada". En esta definición no importa si se consideran valores menores a $x$ que no son posibles bajo nuestra variable aleatoria, visto que esos casos tienen probabilidad nula (o densidad nula, en variables continuas).

::: callout-note
#### Nota

Para una v.a. continua, al verificarse que $P(X=x)=0$, se tiene que $F(x) = P(X \leq x) = P(X < x)$. Esto no se cumple para variables aleatorias discretas.
:::

La definición dada puede particularizarse para cada tipo de variable aleatoria:

* Discreta: $F(x) = \sum_{x_i \leq x} p(x_i)$
* Continua: $F(x) = \int_{-\infty}^x f(t) \; dt$

![Representaciones gráficas de funciones de distribución para una variable discreta (izquierda) y una continua (derecha).](img/fc_distrib.png){#fig-fc_distrib}

La función de distribución acumulada goza de tres propiedades:

* Es monótona no decreciente: $x_1 < x_2 \implies F(x_1) \leq F(x_2)$
* Está acotada entre 0 y 1: $\lim_{x \to -\infty} F(x) = 0$ y $\lim_{x \to +\infty} F(x) = 1$
* Es continua por derecha: $\lim_{x \to x_0^+} F(x) = F(x_0)$

La función de distribución es particularmente útil en variables continuas, porque, si se la conoce, es posible calcular la probabilidad de que $X$ caiga dentro de un cierto intervalo sin necesidad de resolver una integral. Esto es porque: $$P(a < X \leq b) = P(X \leq b) - P(X \leq a) = F(b) - F(a)$$

## Esperanza y variancia

Hasta ahora hemos visto que una variable aleatoria puede definirse mediante una función de probabilidad (o densidad) o, equivalentemente, una función de distribución. Si bien esto nos da información suficiente para calcular la probabilidad de ocurrencia de cualquier evento, existen métricas que en forma sencilla reflejan características importantes sobre la variable en cuestión.

Dichas métricas son llamadas Esperanza y Variancia, simbolizadas $E(X)$ y $V(X)$ respectivamente. La primera nos dice alrededor de qué valor tienden a situarse los resultados posibles de la variable. La segunda indica cuán propensa es la variable a alejarse de dicho valor central, como una suerte de medida de "estabilidad" o "aleatoriedad" de la variable.

### Esperanza

Definiremos la esperanza por separado para cada tipo de variable aleatoria.

**Caso discreto:** Sea $X$ una v.a. discreta con función de probabilidad $p(x)$, se define la **esperanza** (o valor esperado) de $X$ como: $$E(X) = \sum_{x_i \in R_X} x_i \cdot p(x_i)$$

**Caso continuo:** Sea $X$ una v.a. continua con función de densidad $f(x)$, se define la **esperanza** de $X$ como: $$E(X) = \int_{R_X} x \cdot f(x) \; dx$$

Se hacen las siguientes observaciones sobre la esperanza:

* La esperanza puede no existir. La condición para su existencia es la convergencia de la serie (en el caso discreto) o de la integral impropia (en el caso continuo).
* Si $R_X$ es finito, la esperanza de $X$ se obtiene como una suma finita y por lo tanto existe \textit{siempre}.
* La esperanza representa el "centro de gravedad" de la distribución de probabilidad.
* La esperanza es un parámetro; no debe confundirse con el concepto de promedio o media aritmética.

### Variancia

Nuevamente, se establece una definición para cada tipo de variable aleatoria.

**Caso discreto:** Sea $X$ una v.a. discreta con función de probabilidad $p(x)$, se define la **variancia** de $X$ como: $$V(X) = \sum_{x_i \in R_X} [x_i - E(X)]^2 \cdot p(x_i)$$

**Caso continuo:** Sea $X$ una v.a. continua con función de densidad $f(x)$, se define la **variancia** de $X$ como: $$V(X) = \int_{R_X} [x-E(X)]^2 \cdot f(x) \; dx$$

La definición de $V(X)$ es equivalente a una expresión más sencilla de calcular, que frecuentemente se utiliza en la práctica para simplificar los cálculos: la *fórmula de trabajo* de $V(X)$. $$V(X) = E(X^2) - [E(X)]^2 = E(X^2) - E^2(X)$$

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Calcular la Esperanza y Variancia para la variable aleatoria definida en el Ejemplo 1.

**Solución:** se tiene la siguiente función de probabilidad para la variable $X$.

::: {.flexcenter data-latex=""}
::: {.quarter .blackborder data-latex=""}
| $x$  | $p(x)$ |
|-----:|-------:|
| 0    | 1/8    |
| 1    | 3/8    |
| 2    | 3/8    |
| 3    | 1/8    |
:::
:::

Por lo tanto:

$$E(X) = 0 \times \tfrac{1}{8} + 1 \times \tfrac{3}{8} + 2 \times \tfrac{3}{8} + 3 \times \tfrac{1}{8} = \tfrac{3}{8} + \tfrac{6}{8} + \tfrac{3}{8} = \tfrac{12}{8} = 1,5$$

Luego:

$$E(X^2) = 0^2 \times \tfrac{1}{8} + 1^2 \times \tfrac{3}{8} + 2^2 \times \tfrac{3}{8} + 3^2 \times \tfrac{1}{8} = \tfrac{3}{8} + \tfrac{12}{8} + \tfrac{9}{8} = \tfrac{24}{8} = 3$$

Finalmente:

$$V(X) = E(X^2) - E^2(X) = 3 - (1,5)^2 = 3 - 2,25 = 0,75$$
:::

### Propiedades de E(X) y V(X)

Se cumplen las siguientes propiedades para la Esperanza y Variancia de una variable aleatoria.

Esperanza:

* $X=c$ con prob. 1 $\implies E(X) = c$
* $E(X+a) = E(X) + a$
* $E(c \cdot X) = c \cdot E(X)$
* $E(c \cdot X + a) = c \cdot E(X) + a$


Variancia:

* $X=c$ con prob. 1 $\implies V(X) = 0$
* $V(X+a) = V(X)$
* $V(c \cdot X) = c^2 \cdot V(X)$
* $V(c \cdot X + a) = c^2 \cdot V(X)$

## Distribuciones de probabilidad

En la práctica, existen variables aleatorias que se utilizan con frecuencia y que, por lo tanto, tienen una distribución conocida. Esto nos ahorra tiempo y esfuerzo porque no tenemos que calcular cosas como su función de probabilidad (o densidad), su función de distribución, su esperanza o su variancia. Más aún, calcular probabilidades bajo estas distribuciones conocidas se vuelve relativamente sencillo porque programas informáticos como R ya tienen incluidos funciones que lo hacen por nosotros.

Existen muchísimas distribuciones de probabilidad.[^2_va-4] En este curso nos limitaremos a estudiar seis: tres para variables discretas y tres para variables continuas.

[^2_va-4]: <https://en.wikipedia.org/wiki/List_of_probability_distributions>

### Distribuciones discretas

#### Distribución Binomial

Sea un experimento en el que sólo existen dos resultados posibles (los llamaremos "éxito" y "fracaso") y donde la probabilidad de éxito es igual a $p$.

Considérense $n$ repeticiones *independientes* del experimento, y sea $X$ una v.a. que mide el **número de éxitos** a través de las $n$ repeticiones. Entonces $X$ tiene distribución Binomial de parámetros $p$ y $n$, donde: $$p(x) = _nC_x \cdot p^x \cdot (1-p)^{n-x} \quad ;\; x=0,1,\cdots,n$$

::: callout-warning
#### Advertencia

Establecer los valores de los parámetros es fundamental para calcular probabilidades. Una vez hecho esto, la distribución de la variable está definida de forma unívoca. Al proceso de explicitar los parámetros se lo llama **parametrización**.

La Binomial (y, en líneas generales, cualquier distribución de probabilidad) no es una sola distribución sino una *familia* de distribuciones. Para centrarse en una distribución particular es necesario definir familia + parámetros. Por lo tanto, si en un examen se da como ejemplo un experimento aleatorio y se pide "definir la variable aleatoria correspondiente", es necesario especificar la variable aleatoria *y* sus respectivos parámetros.
:::

Empleando la fórmula de esperanza y variancia sobre esta función de probabilidad, se obtiene que: $$E(X) = n \cdot p \qquad V(X) = n \cdot p \cdot (1-p)$$

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Un examen *multiple choice* consta de diez preguntas, cada una de ellas con 4 respuestas posibles. Si un alumno elige una opción al azar en cada pregunta ¿cuál es la probabilidad de acertar en exactamente 7 preguntas?

**Solución:** Considerando que el experimento es "adivinar la respuesta a una pregunta", se tiene que la probabilidad de éxito es $p=0,25$ (porque hay 4 respuestas posibles, de las cuales sólo una es correcta) y hay en total $n=10$ repeticiones del experimento. Considerando estos valores para los parámetros, se tiene que:

$$p(7) = _{10}C_7 \cdot 0,25^7 \cdot 0,75^3 = 120 \cdot \tfrac{1}{16384} \cdot \tfrac{27}{64} = \tfrac{405}{131072} \approx 0,00309 = 0,309\%$$

**Propuesto:** ¿cuál es la probabilidad de aprobar (al menos 6 correctas)?
:::

#### Distribución Poisson

Al igual que la Binomial, existe otra distribución que cuenta el número de éxitos, o bien, el número de incidencias de un cierto evento. La diferencia radica en que esta nueva variable se usa en casos donde no se puede identificar una "unidad mínima" en la que sólo puede darse el éxito o el fracaso. Supóngase, por ejemplo, una variable aleatoria que cuenta el número de llamadas que ingresan a una central telefónica en el plazo de una hora. No existe una unidad de tiempo en la que sólo pueda entrar una llamada (o ninguna). En un segundo pueden entrar muchas llamadas. En una décima de segundo también. Lo mejor que podemos hacer en estos casos es definir un número esperado de incidencias dentro del plazo de tiempo considerado (en el ejemplo es una hora) y compararlo con el número de incidencias observadas al realizar el experimento.

::: callout-note
#### Nota

A pesar del ejemplo dado, no es necesario que las incidencias se midan a través del tiempo. También podrían medirse, por ejemplo, en el espacio. Supóngase una variable aleatoria que cuenta el número de colonias de bacterias en una placa de Petri. Nuevamente, existe una unidad de espacio limitada (la superficie de la placa de Petri) pero dentro de ella es imposible determinar cuál es la unidad mínima en la que puede presentarse sólo una colonia (o ninguna).
:::

Sea $X$ una v.a. discreta con $R_X = \mathbb{N}_0$. Decimos que $X$ tiene una distribución Poisson[^2_va-5] si su función de probabilidad es: $$p(x) = \frac{e^{-\lambda}\lambda^x}{x!} \quad ;\; x \in \mathbb{N}_0$$

[^2_va-5]: Se pronuncia "Puasón".

El parámetro $\lambda$ representa el número medio de éxitos esperados por unidad de tiempo (o espacio).

Para esta variable aleatoria se tiene que $E(X) = V(X) = \lambda$.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

El número de errores de imprenta en una página de un determinado libro es, en promedio, un error por página. ¿Cuál es la probabilidad de observar más de un error en una página seleccionada al azar?

**Solución:** Como el promedio es de un error por página se tiene que $\lambda = 1$. Luego:

$$P(X>1) = 1 - [p(0) + p(1)] = 1 - [\frac{e^{-1}1^0}{0!} + \frac{e^{-1}1^1}{1!}] = 1 - 2e^{-1} \approx 0,264 = 26,4\%$$
:::

#### Distribución Hipergeométrica

Sea una población *finita* de $N$ elementos, de los cuales $N_1$ tienen una determinada característica (éxito) y los $N-N_1$ restantes no lo tienen (fracaso).

La v.a. $X$ que cuenta el **número de éxitos en una muestra de $n$ unidades seleccionadas sin reposición** tiene distribución hipergeométrica de parámetros $N$, $N_1$ y $n$:

$$p(x) = \frac{_{N_1}C_x \;\cdot\; _{N-N_1}C_{n-x}}{_NC_n} \quad;\quad x = \max\{0, n+N_1-N\}, \cdots, \min\{n, N_1\}$$

Para esta variable aleatoria se tiene: $$E(X) = N_1\frac{n}{N} \qquad V(X) = N_1\frac{n}{N} \left(\frac{N-N_1}{N}\right) \left(\frac{N-n}{N-1}\right)$$

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Se reparten 5 cartas al azar (y sin reemplazo) de una baraja de 52 cartas de póker. ¿Cuál es la probabilidad de que la mano no contenga ases?

**Solución:** Considerando el as como un éxito, se tiene que $N=52$, $N_1=4$ y $n=5$. Luego:

$$P(X=0) = p(0) = \frac{_4C_0 \;\cdot\; _{48}C_5}{_{52}C_5} = \frac{1 \cdot 1.712.304}{2.598.960} \approx 0,6584 = 65,84\%$$
:::

### Distribuciones continuas

#### Distribución Uniforme

Sea $X$ una v.a. continua con recorrido acotado $R_X=[a;b]$. Se dice que $X$ tiene distribución uniforme de parámetros $a$ y $b$ si su función de densidad está dada por: $$f(x) = \frac{1}{b-a} \quad ;\; a \leq x \leq b$$

::: callout-note
#### Nota

Nótese que la función de densidad no depende del valor de $x$: es constante. Esto refleja que todos los intervalos de igual amplitud son **igualmente probables** a lo largo de todo el recorrido de $X$.
:::

A partir de la función de densidad se deduce: $$F(x) = \int_a^x \frac{1}{b-a} = \frac{x-a}{b-a} \qquad E(X) = \frac{a+b}{2} \qquad V(X) = \frac{(b-a)^2}{12}$$

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Al estudiar bajas cotizaciones para contratos de embarques, una empresa fabricante de computadoras encuentra que los contratos interestatales tienen bajas cotizaciones uniformemente distribuidas entre 20 y 25 (en miles de dólares). ¿Cuál es la probabilidad de que la baja cotización en el siguiente contrato interestatal esté por debajo de los \$22.000?

**Solución:** Se tiene que $a = 20$ y $b = 25$. Luego:

$$P(X<22) = P(X\leq 22) = F(22) = \frac{22-20}{25-20} = \frac{2}{5} = 0,4 = 40\%$$
:::

#### Distribución Exponencial

Sea $X$ una v.a. continua con $R_X = \mathbb{R}_0^+$ (es decir, los reales positivos incluyendo el cero). Se dice que $X$ tiene distribución exponencial si su función de densidad es: $$f(x) = \lambda e^{-\lambda x} \quad ;\; x \in \mathbb{R}_0^+$$.

De la función de densidad se deduce: $$F(x) = 1 - e^{-\lambda x} \qquad E(X) = \frac{1}{\lambda} \qquad V(X) = \frac{1}{\lambda^2}$$

Esta distribución es ampliamente utilizada en aplicaciones industriales, puesto que modela adecuadamente las variables del tipo "tiempo hasta la ocurrencia de un evento".

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

La magnitud de temblores registrados en una región de Norteamérica (medidos en escala de Richter) sigue una distribución exponencial con parámetro $\lambda = \tfrac{5}{12}$. ¿Cuál es la probabilidad de que un temblor en esa región supere los 3 puntos en la escala de Richter?

**Solución:**

$$P(X>3) = 1-P(X\leq 3) = 1- F(3) = 1 - [1 - e^{-\frac{5}{12}\cdot 3}] = e^{-\frac{15}{12}} \approx 0,2865 = 28,65\%$$
:::

#### Distribución Normal

Sea $X$ una v.a. continua con $R_X = \mathbb{R}$ (todos los reales). Se dice que $X$ sigue una distribución Normal si su función de densidad viene dada por $$f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2} \quad ;\; x \in \mathbb{R}$$

Los parámetros $\mu$ y $\sigma$ representan la media y el desvío estándar de la distribución, respectivamente. De hecho, se verifica que $E(X) = \mu$ y $V(X) = \sigma^2$.

La función de densidad normal presenta una particularidad: no puede integrarse. Por lo tanto no existe una expresión analítica (exacta) para $F(x)$. Es por ello que solemos utilizar osftware estadístico para realizar cálculos sobre esta distribución. En R contamos con dos funciones de gran utilidad: `pnorm` y `qnorm`.

* La función `pnorm(q, mean = 0, sd = 1)` calcula $F(q) = P(X \leq q)$ para $X \sim N(mean, sd)$.
* La función `qnorm(p, mean = 0, sd = 1)` calcula el valor que acumula un $100p\%$ de probabilidad en una distribución $N(mean, sd)$.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

La cantidad semanal de dinero gastado por una compañía en mantenimiento y reparaciones está normalmente distribuida con una media de \$400 y un desvío estándar de \$20. Si están presupuestados \$450 para la semana próxima, ¿cuál es la probabilidad de que los costos reales superen dicha cifra?

**Solución:** Se tiene que $\mu = 400$ y $\sigma = 20$. Se quiere calcular $P(X > 450) = 1 - F(450)$. Así:

`1 - pnorm(450, mean = 400, sd = 20)` = 0,0062 = 0,62\%
:::
