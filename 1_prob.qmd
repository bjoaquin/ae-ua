```{r}
#| echo: FALSE
#| message: FALSE

library(tidyverse)

contador_ejemplos <- 0
```

# 1. Probabilidad

## Introducci칩n

Supongamos que abre una helader칤a nueva en la ciudad. Esta helader칤a s칩lo tiene ocho sabores distintos, pero se rumorea que son muy buenos. Un amigo nuestro quiere probar sus helados, por lo que propone ir a comprar un pote de un kilogramo, en el que entran cuatro sabores distintos. Nosotros accedemos con gusto. Nuestro amigo sale rumbo a la helader칤a y nosotros nos quedamos en el departamento esperando su regreso. De repente caemos en la cuenta de que nunca decidimos qu칠 sabores pedir. Sabemos que uno de los ocho sabores de la helader칤a es lim칩n, el cual nuestro amigo adora pero nosotros detestamos. Lo detestamos a tal punto que, si uno de los cuatro sabores del pote fuese lim칩n, no comer칤amos ninguno de ellos. Entonces nos hacemos una pregunta.

쮺u치l es la probabilidad de que nuestro amigo traiga helado de lim칩n?

## Definiciones importantes

Antes de calcular una probabilidad debemos generar el ambiente propicio: definir matem치ticamente los elementos b치sicos que componen la situaci칩n sobre la cual queremos obtener probabilidades. Esto se hace para evitar ambig칲edades y ordenar nuestro pensamiento.

### Experimento aleatorio

El **experimento aleatorio** es aquella situaci칩n en la que no es posible saber de antemano el resultado a obtener, incluso repiti칠ndola varias veces bajo las mismas condiciones.

En el ejemplo propuesto, el experimento aleatorio es "elegir 4 sabores de helado entre 8 posibles".

::: callout-note
#### Nota

Es costumbre definir el experimento aleatorio partiendo de un verbo en infinitivo: en este caso, "elegir". N칩tese que esto no refleja qui칠n es la persona que lleva a cabo la acci칩n. La idea es despojarse de toda informaci칩n innecesaria y centrarse en la acci칩n cuyo resultado genera incertidumbre.
:::

Los experimentos aleatorios gozan de una propiedad llamada **regularidad estad칤stica**, la cual refiere a una estabilidad a largo plazo en la frecuencia de aparici칩n de los resultados obtenidos. Por ejemplo: si arrojo muchas veces una moneda (llam칠mosle "cara" y "cruz" a sus dos lados), es de esperar que a largo plazo el porcentaje de caras obtenidas sea aproximadamente 50%.

### Espacio muestral

El **espacio muestral** es el conjunto de todos los resultados posibles e imaginables del experimento aleatorio. Se lo suele simbolizar con la letra $S$.

En el ejemplo, supongamos que los ocho sabores de la helader칤a son:

::: {.center data-latex=""}
Sabores = { Chocolate, Vainilla, Frutilla, Lim칩n, Menta, Dulce de Leche, Americana, Sambay칩n }
:::

Por lo tanto, un posible resultado del experimento ser칤a $s$ = {Menta, Vainilla, Americana, Lim칩n}.\footnote{N칩tese que usamos la letra $s$ min칰scula para referirnos a un 칰nico elemento del conjunto $S$. Si queremos nombrar m치s de un elemento podemos usar sub칤ndices; por ejemplo: $s_1$, $s_2$, $s_3$, $\cdots$}

쮺u치ntos resultados distintos existen? Para responder a esta pregunta podemos hacer uso de las herramientas de conteo estudiadas en la unidad anterior. Como no nos importa el orden y no se admite una repetici칩n de los sabores, usamos una combinaci칩n simple: $_8C_4 = 70$ posibles elecciones de 4 sabores. Este es el tama침o del conjunto $S$. En notaci칩n matem치tica se dice que $\#S = 70$.

$$S = \{ s_1, s_2, s_3, \cdots, s_{69}, s_{70} \}$$

Si quisi칠ramos definir al conjunto $S$ en forma exhaustiva [^1_prob-1], se ver칤a algo as칤 como:

[^1_prob-1]: En matem치ticas, existen dos formas de definir un conjunto: por extensi칩n y por comprensi칩n. La primera implica listar uno por uno los elementos del conjunto; por ejemplo: \{2, 4, 6, 8\}. La segunda implica usar palabras para definir el contenido; por ejemplo: \{los n칰meros pares entre 1 y 9\}.

$S$ = {

::: {.indent data-latex=""}
{Chocolate, Vainilla, Frutilla, Lim칩n},

{Chocolate, Vainilla, Frutilla, Menta},

{Chocolate, Vainilla, Frutilla, Dulce de Leche},

$\cdots$

{Menta, Dulce de Leche, Americana, Sambay칩n}
:::

}

### Suceso aleatorio

Se denomina **suceso o evento aleatorio** a cualquier subconjunto del espacio muestral.

Volviendo al ejemplo, un evento podr칤a ser "elegir chocolate". Este evento equivale a un subconjunto de $S$ que contiene todas aquellas elecciones donde uno de los 4 sabores es Chocolate, sin importar cu치les son los 3 sabores restantes. 쯈u칠 tama침o tiene este subconjunto? En total contiene $_7C_3 = 35$ elementos.

Suele usarse una letra may칰scula para definir un suceso. En este caso:

::: {.center data-latex=""}
$A$: elegir Chocolate
:::

Otros ejemplos de eventos sobre este mismo experimento podr칤an ser:

* $B$: no elegir Frutilla
* $C$: elegir Lim칩n y Chocolate
* $D$: elegir un sabor frutal
* $E$: no elegir ning칰n sabor

## Operaciones entre sucesos

Los eventos aleatorios son conjuntos matem치ticos y, por lo tanto, admiten las mismas operaciones que suelen utilizarse para manipular conjuntos.

Sean $A$ y $B$ eventos definidos sobre un espacio muestral $S$.

* **Suceso uni칩n** ($A \cup B$): elementos de $S$ que pertenecen a $A$, a $B$ o a ambos.
* **Suceso intersecci칩n** ($A \cap B$): elementos de $S$ que pertenecen a $A$ y a $B$ simult치neamente.
* **Suceso complemento** ($\overline{A}$ 칩 $A^c$): elementos de $S$ que no pertenecen a $A$.

Sobre estas definiciones se desprende que $A$ y $B$ son sucesos **mutuamente excluyentes** si y s칩lo si $A \cap B = \emptyset$ (conjunto vac칤o).

![Operaciones entre conjuntos, visualizadas mediante diagramas de Venn. (Arriba a la izquierda: uni칩n; arriba a la derecha: intersecci칩n; abajo a la izquierda: complemento; abajo a la derecha: exclusividad mutua.)](img/conjuntos.png){#fig-conjuntos}

Pensar en operaciones entre sucesos puede ser 칰til porque a veces un suceso complejo puede descomponerse en m칰ltiples sucesos simples, los cuales se conectan mediante estas operaciones. Por ejemplo, sup칩ngase el evento:

$A$: "elegir Chocolate y Menta, o bien Frutilla y Sambay칩n".

Este evento puede descomponerse como $$A = (C \cap M) \cup (F \cap S),$$ donde

* $C$: elegir Chocolate.
* $M$: elegir Menta.
* $F$: elegir Frutilla.
* $S$: elegir Sambay칩n.

### Leyes de De Morgan

Al combinar complementos con intersecciones o uniones es importante tener en cuenta las siguientes reglas, atribuidas a Augustus De Morgan:

* El complemento de una uni칩n es igual a la intersecci칩n de los complementos. $$\overline{A \cup B} = \overline{A} \cap \overline{B}$$
* El complemento de una intersecci칩n es igual a la uni칩n de los complementos. $$\overline{A \cap B} = \overline{A} \cup \overline{B}$$

Estas reglas aplican no s칩lo entre dos eventos, sino para un n칰mero arbitrario de ellos.

## Definiciones de probabilidad

### Definici칩n cl치sica (*a priori*)

Esta definici칩n establece que la probabilidad de que, al realizar un experimento, se obtenga un cierto resultado, es igual al cociente entre el n칰mero de casos favorables al resultado y el n칰mero total de casos posibles.

$$\frac{\#\text{casos favorables}}{\#\text{casos posibles}}$$

쮸 qu칠 nos referimos con casos favorables y casos posibles? Supongamos un evento aleatorio sobre el que se define un espacio muestral $S$, y sea $A$ un evento de inter칠s para el cual queremos calcular su probabilidad de ocurrencia. Usaremos las siguientes definiciones:

* **Casos favorables**: todos los elementos pertenecientes al conjunto $A$.
* **Casos posibles**: todos los elementos pertenecientes al conjunto $S$.

Siendo $A$ un subconjunto de $S$, resulta evidente que todo caso favorable es, a su vez, posible.

Bajo esta definici칩n, entonces, podemos calcular la probabilidad de $A$, simbolizada $P(A)$, como: $$P(A) = \dfrac{\#A}{\#S},$$ o sea, el tama침o del conjunto $A$ dividido por el tama침o del espacio muestral.

Esta definici칩n es la raz칩n por la que estudiamos herramientas de conteo: calcular una probabilidad implica conocer el tama침o de los conjuntos $A$ y $S$, lo cual a su vez requiere una metodolog칤a para contar sus respectivos elementos.

Habiendo definido todos estos conceptos, finalmente nos encontramos en condiciones de resolver el ejemplo introductorio.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Una helader칤a ofrece 8 sabores distintos. Si enviamos a un amigo a comprar un pote de 1kg (el cual contiene 4 sabores distintos), 쯖u치l es la probabilidad de que uno de los sabores elegidos sea lim칩n?

**Soluci칩n:** Definimos, en primer lugar, todas las nociones que componen el marco del ejercicio.

* **Experimento aleatorio:** elegir 4 sabores de helado entre 8 posibles.
* **Espacio muestral:** $S$ = {todos los subconjuntos posibles de 4 sabores distintos}.
* **Ejemplo de resultado:** $s$ = {Sambay칩n, Chocolate, Lim칩n, Menta}.
* **Casos posibles:** $\#S = _8C_4 = 70$.
* **Evento de inter칠s:** $A$: elegir Lim칩n.
* **Casos favorables:** $\#A = _7C_3 = 35$.

Por lo tanto, el resultado final es $$P(A) = \dfrac{\#A}{\#S} = \dfrac{35}{70} = \dfrac{1}{2} = 0,5 = 50\%$$
:::

Las probabilidades no son siempre intuitivas. 쮿ubieran esperado que el resultado fuese un n칰mero tan alto?

La definici칩n cl치sica de probabilidad, lamentablemente, s칩lo aplica a experimentos con un n칰mero finito de resultados posibles y donde todos ellos son equiprobables.[^1_prob-2] Cuando un experimento no cumple con estas condiciones es necesario recurrir a otra definici칩n de probabilidad.

[^1_prob-2]: Experimentos de este estilo se denominan "laplacianos", en honor a Pierre-Simon Laplace.

### Definici칩n frecuencial (*a posteriori*)

La regularidad estad칤stica de la que gozan los experimentos aleatorios permite definir a la probabilidad de un suceso como el l칤mite, cuando el n칰mero de repeticiones del experimento tiende a infinito, de la frecuencia relativa del suceso.

Supongamos que repetimos el mismo experimento un total de $n$ veces. Sea $I_n(A)$ una variable que cuenta el n칰mero de veces que el resultado del experimento cumpli칩 con lo establecido en el evento $A$. La definici칩n frecuencial establece que, aumentando arbitrariamente el n칰mero de repeticiones, la probabilidad resulta igual a:

$$P(A) = \lim_{n \to \infty} \frac{I_n(A)}{n}$$

Esta definici칩n es puramente te칩rica, en el sentido de que en la pr치ctica nunca pueden hacerse infinitas repeticiones de un experimento: deber치 bastarnos con hacer un n칰mero suficientemente grande de repeticiones y tomar el resultado final como una aproximaci칩n del verdadero resultado.

Afortunadamente, no siempre es necesario hacer una verdadera repetici칩n del experimento. Para ciertos experimentos existen teoremas y propiedades matem치ticas que permiten deducir la frecuencia relativa exacta de un suceso, sin necesidad de llevar a cabo siquiera una ejecuci칩n real del experimento. En otras ocasiones, el experimento puede ser realizado mediante simulaciones computacionales, lo cual permite repetirlos muchas veces en poco tiempo.

## Algunos ejemplos

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Se arroja un dado y se observa la cara superior. 쮺u치l es la probabilidad de obtener un n칰mero mayor a 4? 쮺u치l es la probabilidad de obtener un n칰mero mayor a 6?

**Soluci칩n:**

* **Experimento aleatorio:** arrojar un dado y observar la cara superior.
* **Espacio muestral:** $S$ = {1, 2, 3, 4, 5, 6}.
* **Ejemplo de resultado:** $s$ = 3.
* **Casos posibles:** $\#S = 6$.
* **Evento de inter칠s:**
  * $A$: obtener un n칰mero mayor a 4.
  * $B$: obtener un n칰mero mayor a 6.
* **Casos favorables:**
  * $A = \{5, 6\} \implies \#A = 2$.
  * $B = \emptyset \implies \#B = 0$.

Por lo tanto, los resultados son
$$P(A) = \dfrac{\#A}{\#S} = \dfrac{2}{6} = \dfrac{1}{3} = 0,\overline{3} = 33,\overline{3}\%$$
$$P(B) = \dfrac{\#B}{\#S} = \dfrac{0}{6} = 0 = 0\%$$
:::

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Los organizadores de un seminario de tres d칤as de duraci칩n est치n considerando qu칠 almuerzo servir en cada uno de los d칤as: pescado o carne. 쮺u치l es la probabilidad de que no sirvan el mismo almuerzo dos d칤as consecutivos?

**Soluci칩n:**

* **Experimento aleatorio:** elegir tres men칰es de almuerzos, siendo pescado y carne las opciones para cada d칤a.
* **Espacio muestral:** $S$ = {todas las ternas posibles a partir de los elementos "Pescado" y "Carne"}.
* **Ejemplo de resultado:** $s$ = (Carne, Carne, Pescado).
* **Casos posibles:** $\#S = _2P'_3 = 2^3 = 8$.
* **Evento de inter칠s:** $A$: no servir el mismo almuerzo dos d칤as consecutivos.
* **Casos favorables:** $A$ = \{(Carne, Pescado, Carne), (Pescado, Carne, Pescado)\} $\implies \#A = 2$.

Por lo tanto, el resultado final es $$P(A) = \dfrac{\#A}{\#S} = \dfrac{2}{8} = \dfrac{1}{4} = 0,25 = 25\%$$
:::

## Axiomas de probabilidad

Sea un experimento aleatorio sobre el que se define un espacio muestral $S$. La probabilidad de un evento $A$ cumple con los siguientes axiomas:

* $P(A) \geq 0$ para todo suceso $A$.
* $P(S) = 1$.
* $A$ y $B$ son m.e. $\implies P(A \cup B) = P(A) + P(B)$.

A partir de los axiomas de probabilidad se desprenden las siguientes propiedades:

* $P(\overline{A}) = 1 - P(A)$ para todo suceso $A$.
* $P(\emptyset) = 0$.
* $P(A) \leq 1$.
* $B \subseteq A \implies P(B) \leq P(A)$.
* $P(A \cup B) = P(A) + P(B) - P(A \cap B)$.

## Probabilidad condicional

Supongamos que tenemos un mazo de cartas francesas (las de p칩ker), el cual tiene 52 cartas. Lo mezclamos, lo apoyamos en la mesa boca abajo y tomamos las dos cartas superiores, de a una a la vez. 쮺u치l es la probabilidad de que la segunda carta seleccionada sea un as?

Es posible que su respuesta sea "depende", visto que la probabilidad para la segunda carta depende de cu치l fue la primera carta seleccionada. Esta apreciaci칩n es en parte correcta y en parte err칩nea: ciertamente debemos *considerar* lo que ocurri칩 con la primera carta, pero, como veremos m치s adelante, podemos obtener una probabilidad para la segunda carta sin *saber* el resultado de la primera.

Supongamos un experimento aleatorio sobre el que se definen dos eventos $A$ y $B$. M치s a칰n, sea $A$ un evento tal que $P(A) \neq 0$. Se define la **probabilidad condicional de $B$ dado $A$** como $$P(B|A) = \dfrac{P(B \cap A)}{P(A)}.$$

Como muestra la ecuaci칩n, calcular la probabilidad del evento $B$ condicionada a la ocurrencia del evento $A$ equivale a calcular la probabilidad de $B$ dentro del espacio muestral restringido por $A$.

![Representaci칩n visual de la probabilidad condicional. En el diagrama, la probabilidad condicional $P(B|A)$ tiene por numerador la parte de $B$ que est치 contenida en $A$, y por denominador la totalidad de $A$.](img/condicional.png){#fig-condicional}

Pong치moslo en pr치ctica con un ejemplo simple:

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Se arroja un dado y se observa la cara superior. Consid칠rense los siguientes eventos:

* $A$: obtener un 1.
* $B$: obtener un n칰mero par.
* $C$: obtener un n칰mero mayor a 3.

Calcular las probabilidades: $P(B|C)$, $P(C|B)$ y $P(A|C)$.

**Soluci칩n:**

* **Experimento aleatorio:** arrojar un dado y observar la cara superior.
* **Espacio muestral:** $S$ = {1, 2, 3, 4, 5, 6}.
* **Ejemplo de resultado:** $s$ = 3.

Las probabilidades a calcular son:

* $P(B|C) = \dfrac{P(B \cap C)}{P(C)} = \dfrac{\frac{\#(B \cap C)}{\#S}}{\frac{\#C}{\#S}} = \dfrac{\#(B \cap C)}{\#C}$
* $P(C|B) = \dfrac{P(B \cap C)}{P(B)} = \dfrac{\frac{\#(B \cap C)}{\#S}}{\frac{\#B}{\#S}} = \dfrac{\#(B \cap C)}{\#B}$
* $P(A|C) = \dfrac{P(A \cap C)}{P(C)} = \dfrac{\frac{\#(A \cap C)}{\#S}}{\frac{\#C}{\#S}} = \dfrac{\#(A \cap C)}{\#C}$

Por lo tanto:

* **Casos posibles:** $\#S =6$.
* **Casos de inter칠s:**

  * $B = \{2,4,6\} \implies \#B = 3$.
  * $C = \{4,5,6\} \implies \#C = 3$.
  * $B \cap C = \{4,6\} \implies \#(B \cap C) = 2$.
  * $A \cap C = \emptyset \implies \#(A \cap C) = 0$.
  
Finalmente:

* $P(B|C) = \frac{2/6}{3/6} = \frac{2}{3} = 0,\overline{6} = 66,\overline{6}\%$
* $P(C|B) = \frac{2/6}{3/6} = \frac{2}{3} = 0,\overline{6} = 66,\overline{6}\%$
* $P(A|C) = \frac{0/6}{3/6} = \frac{0}{3} = 0 = 0\%$

:::

Es importante notar que las probabilidades condicionales tambi칠n verifican los axiomas de probabilidad y las propiedades que de ellas se desprenden. Algunas que pueden resultar 칰tiles son:

* $P(\overline{B}|A) = 1 - P(B|A)$
* $P(A\cup B|C) = P(A|C) + P(B|C) - P(A \cap B|C)$

### Teorema de la multiplicaci칩n

Es una regla para el c치lculo de probabilidades que se desprende directamente de la definici칩n de probabilidad condicional.

Siendo $A$ y $B$ dos sucesos definidos sobre un experimento aleatorio, se tiene: $$P(A \cap B) = P(A|B) \cdot P(B) = P(B|A) \cdot P(A)$$

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

Se tiene un frasco lleno de canicas. No se sabe con exactitud cu치ntas tiene, pero se sabe que el 23\% de ellas son verdes, mientras que las dem치s son blancas. Adem치s, se sabe que el 15\% de las canicas verdes brilla en la oscuridad. Si se extrae una canica al azar, 쯖u치l es la probabilidad de que sea verde y brille en la oscuridad?

**Soluci칩n:**

* **Experimento aleatorio:** extraer al azar una canica del frasco.
* **Espacio muestral:** $S$ = {cada canica del frasco}.
* **Ejemplo de resultado:** $s = v^*$ (canica verde que brilla).
* **Eventos de inter칠s:**

  * $V$: se extrae una canica verde.
  * $B$: se extrae una canica que brilla.
  
As칤:
$$P(V \cap B) = P(B|V) \cdot P(V) = 0,15 \cdot 0,23 = 0,0345 = 3,45\%$$

:::

### Independencia

Siendo $A$ y $B$ dos eventos aleatorios, se dice que 칠stos son **eventos independientes** si y s칩lo si $$P(A \cap B) = P(A) \cdot P(B)$$

Por un lado, n칩tese que esta ecuaci칩n es sim칠trica respecto a $A$ y $B$; es decir, si $A$ es independiente de $B$, etnonces $B$ es a su vez independiente de $A$. Por otro lado, n칩tese que la ecuaci칩n anterior resulta en $$A \text{ y } B \text{ independientes} \iff P(A|B) = P(A)  \;\wedge\; P(B|A) = P(B).$$

::: callout-warning
#### Advertencia

La independencia no puede representarse gr치ficamente mediante un diagrama de Venn.
:::

### Teorema de Bayes

Sean dos eventos $A$ y $B$ tales que $P(A) \neq 0$. Luego:
$$P(B|A) = \dfrac{P(A|B) \cdot P(B)}{P(A)}$$

Este teorema nos provee una forma alternativa de calcular probabilidades condicionales.

::: {.examplebox data-latex=""}
```{r}
#| echo: FALSE
contador_ejemplos <- contador_ejemplos + 1
```

::: {.center data-latex=""}
**Ejemplo `r contador_ejemplos`**
:::

El 2\% de la poblaci칩n mundial est치 contagiada con una nueva enfermedad, y existen pruebas para su diagn칩stico, con una sensibilidad de 98\% y una especificidad del 95\%. Una persona sospecha estar enferma y, al hacerse el test, obtiene un resultado positivo. 쮺u치l es la probabilidad de que est칠 realmente enferma?

**Soluci칩n:** lo vemos en clase 游땔

:::

## Un caso real: el caso Sally Clark

El 23 de febrero de 1998 Sally Clark, una mujer inglesa de 33 a침os, fue arrestada bajo la sospecha de haber asesinado a sus dos hijos. [@clark]

Su primer hijo hab칤a nacido en 1996 y fallecido tres meses m치s tarde bajo un diagn칩stico de muerte s칰bita infantil. Para una familia promedio la probabilidad de este fen칩meno es de 1 en 8543, lo cual es inusual pero no lo suficientemente llamativo como para levantar sospechas. Lo que alert칩 a las autoridades fue cuando, tras ocho semanas de nacer, el segundo hijo de la familia Clark tambi칠n falleci칩 por muerte s칰bita infantil.

Sally Clark fue llevada a juicio, donde el fiscal argument칩 que, si la probabilidad de que un hijo fallezca por muerte s칰bita infantil es de 1 en 8543, entonces la probabilidad de que dos hijos sufran ese fen칩meno es de 1 en 73 millones (porque $8543 \times 8543 = 72.982.849$). Estos n칰meros fueron suficientes para convencer al jurado de que el diagn칩stico de muerte s칰bita infantil era muy poco probable. Sally Clark perdi칩 el juicio y fue condenada a prisi칩n.

En octubre de 2001, dos meses luego del juicio, la Royal Statistical Society emiti칩 un comunicado p칰blico alegando un mal uso de la estad칤stica en el juicio. El c치lculo empleado por el fiscal asum칤a que dos muertes s칰bitas infantiles dentro de una misma familia ser칤an eventos independientes, cuando en realidad esto dif칤cilmente sea cierto: dado un primer hijo fallecido por muerte s칰bita infantil, es posible que exista en la familia alguna predisposici칩n gen칠tica hacia dicha condici칩n, y por lo tanto no ser칤a raro que un segundo hijo tambi칠n la padeciera.

Desde entonces, este caso ha sido citado innumerables veces como ejemplo de los peligros que surgen de no comprender adecuadamente c칩mo funcionan las probabilidades.